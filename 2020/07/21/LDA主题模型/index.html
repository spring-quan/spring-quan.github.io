<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>LDA主题模型 | spring&#39;s Blog | 游龙当归海，海不迎我自来也。</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="主题模型,PLSA,LDA,Unigram Model">
    <meta name="description" content="LDA(Latent Dirichlet Allocation, 隐含狄利克雷分布)是一种主题模型，将文档集中每篇文档的主题以概率分布的形式给出。LDA模型是一种词袋(bag-of-words)模型，也就是把一篇文档看作是一组词的集合，而不考虑词与词之间的先后顺序关系。">
<meta name="keywords" content="主题模型,PLSA,LDA,Unigram Model">
<meta property="og:type" content="article">
<meta property="og:title" content="LDA主题模型">
<meta property="og:url" content="http://yoursite.com/2020/07/21/LDA主题模型/index.html">
<meta property="og:site_name" content="spring&#39;s Blog">
<meta property="og:description" content="LDA(Latent Dirichlet Allocation, 隐含狄利克雷分布)是一种主题模型，将文档集中每篇文档的主题以概率分布的形式给出。LDA模型是一种词袋(bag-of-words)模型，也就是把一篇文档看作是一组词的集合，而不考虑词与词之间的先后顺序关系。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/images/text_model.png">
<meta property="og:image" content="http://yoursite.com/images/unigram_model_1.png">
<meta property="og:image" content="http://yoursite.com/images/unigram_model_2.png">
<meta property="og:image" content="http://yoursite.com/images/unigram_model_3.png">
<meta property="og:image" content="http://yoursite.com/images/plsa.png">
<meta property="og:image" content="http://yoursite.com/images/LDA_1.png">
<meta property="og:image" content="http://yoursite.com/images/LDA_4.png">
<meta property="og:image" content="http://yoursite.com/images/LDA_2.png">
<meta property="og:image" content="http://yoursite.com/images/LDA_3.png">
<meta property="og:updated_time" content="2020-07-24T02:01:48.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LDA主题模型">
<meta name="twitter:description" content="LDA(Latent Dirichlet Allocation, 隐含狄利克雷分布)是一种主题模型，将文档集中每篇文档的主题以概率分布的形式给出。LDA模型是一种词袋(bag-of-words)模型，也就是把一篇文档看作是一组词的集合，而不考虑词与词之间的先后顺序关系。">
<meta name="twitter:image" content="http://yoursite.com/images/text_model.png">
    
        <link rel="alternate" type="application/atom+xml" title="spring&#39;s Blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.jpg">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">spring</h5>
          <a href="mailto:ccq1996@bupt.edu.cn" title="ccq1996@bupt.edu.cn" class="mail">ccq1996@bupt.edu.cn</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                分类
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/spring-quan" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/custom"  >
                <i class="icon icon-lg icon-link"></i>
                测试
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/links"  >
                <i class="icon icon-lg icon-users"></i>
                友链
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/collection"  >
                <i class="icon icon-lg icon-heart"></i>
                收藏
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">LDA主题模型</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">LDA主题模型</h1>
        <h5 class="subtitle">
            
                <time datetime="2020-07-21T09:51:00.000Z" itemprop="datePublished" class="page-time">
  2020-07-21
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/nlp/">nlp</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#数学知识"><span class="post-toc-number">1.</span> <span class="post-toc-text">数学知识</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#文本建模"><span class="post-toc-number">2.</span> <span class="post-toc-text">文本建模</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#Unigram-Model"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">Unigram Model</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-6"><a class="post-toc-link" href="#文本生成"><span class="post-toc-number">2.1.1.</span> <span class="post-toc-text">文本生成</span></a></li><li class="post-toc-item post-toc-level-6"><a class="post-toc-link" href="#参数估计"><span class="post-toc-number">2.1.2.</span> <span class="post-toc-text">参数估计</span></a></li></ol></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#贝叶斯观点下的Unigram-Model"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">贝叶斯观点下的Unigram Model</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-6"><a class="post-toc-link" href="#文本生成-1"><span class="post-toc-number">2.2.1.</span> <span class="post-toc-text">文本生成</span></a></li><li class="post-toc-item post-toc-level-6"><a class="post-toc-link" href="#参数估计-1"><span class="post-toc-number">2.2.2.</span> <span class="post-toc-text">参数估计</span></a></li></ol></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#PLSA主题模型"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">PLSA主题模型</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-6"><a class="post-toc-link" href="#文本生成-2"><span class="post-toc-number">2.3.1.</span> <span class="post-toc-text">文本生成</span></a></li><li class="post-toc-item post-toc-level-6"><a class="post-toc-link" href="#参数估计-2"><span class="post-toc-number">2.3.2.</span> <span class="post-toc-text">参数估计</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#LDA主题模型"><span class="post-toc-number">3.</span> <span class="post-toc-text">LDA主题模型</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#文本生成-3"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">文本生成</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#参数估计-3"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">参数估计</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#参考链接"><span class="post-toc-number">4.</span> <span class="post-toc-text">参考链接</span></a></li></ol>
        </nav>
    </aside>


<article id="post-LDA主题模型"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">LDA主题模型</h1>
        <div class="post-meta">
            <time class="post-time" title="2020-07-21 17:51:00" datetime="2020-07-21T09:51:00.000Z"  itemprop="datePublished">2020-07-21</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/nlp/">nlp</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>LDA(Latent Dirichlet Allocation, 隐含狄利克雷分布)是一种主题模型，将文档集中每篇文档的主题以概率分布的形式给出。LDA模型是一种词袋(bag-of-words)模型，也就是把一篇文档看作是一组词的集合，而不考虑词与词之间的先后顺序关系。</p>
<a id="more"></a>
<h4 id="数学知识"><a href="#数学知识" class="headerlink" title="数学知识"></a>数学知识</h4><ul>
<li><a href="https://zh.wikipedia.org/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83" target="_blank" rel="noopener">贝努利分布</a>， 又称两点分布，0-1分布, 看作抛一次硬币的贝努利试验得到的离散概率分布。</li>
<li><a href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E4%BD%88" target="_blank" rel="noopener">二项分布</a>: 独立地进行$n$次贝努利试验的离散概率分布。</li>
<li><a href="https://en.wikipedia.org/wiki/Multinomial_distribution" target="_blank" rel="noopener">多项分布</a>：是二项分布的推广，每次试验变成抛一个有$K$个面的骰子。</li>
<li><a href="https://en.wikipedia.org/wiki/Beta_distribution" target="_blank" rel="noopener">Beta分布</a>: 是二项分布的共轭先验。</li>
<li><a href="https://en.wikipedia.org/wiki/Dirichlet_distribution" target="_blank" rel="noopener">Derichlet分布</a>: 是多项分布的共轭先验。</li>
<li><a href="https://en.wikipedia.org/wiki/Conjugate_prior" target="_blank" rel="noopener">共轭先验</a></li>
<li><a href="https://en.wikipedia.org/wiki/Beta-binomial_distribution" target="_blank" rel="noopener">Beta-binomial共轭</a></li>
<li><a href="https://en.wikipedia.org/wiki/Dirichlet-multinomial_distribution" target="_blank" rel="noopener">Dirichlet-multinomial共轭</a></li>
</ul>
<h4 id="文本建模"><a href="#文本建模" class="headerlink" title="文本建模"></a>文本建模</h4><p>日常生活中有大量的文档，文档可以表示为有序的词的序列：$document = \lbrace{w_1, w_2, …, w_n}\rbrace$。</p>
<div align="center"><img src="/images/text_model.png" width="50%" height="50%"></div>  
<div align="center"><font color="grey" size="2">Fig.1 包含m篇文档的语料库 src: LDA数学八卦</font></div>

<p>统计文本建模的目的是追问 文档中的词序列是如何生成的。文本可以看作是 上帝抛掷骰子生成的，我们要做的是猜测 上帝是如何抛掷骰子来生成文本的。这里的核心问题有两个：</p>
<ol>
<li>上帝有什么样的骰子。</li>
<li>上帝是如何抛掷这些骰子的。</li>
</ol>
<p>第一个问题是表示模型中有哪些参数，骰子每一面的概率对应于模型的参数。第二个问题表示了游戏规则是什么，上帝可能有各种不同种类的骰子，按照一定的规则来抛掷这些骰子来生成词序列。<br>接下来，我们讨论几种猜测如何生成词序列文本的模型。</p>
<h5 id="Unigram-Model"><a href="#Unigram-Model" class="headerlink" title="Unigram Model"></a>Unigram Model</h5><h6 id="文本生成"><a href="#文本生成" class="headerlink" title="文本生成"></a>文本生成</h6><p>假设词表中有$V$个词$v_1, v_2, …, v_V$，那么最简单的Unigram Model认为上帝是按照以下的规则来抛掷骰子的。</p>
<ol>
<li>上帝只有一个骰子，这个骰子有$V$面，每面对应一个词，每个面的概率是不同的。<font color="#0000dd">但每个面的概率是固定的。</font></li>
<li>每抛一次骰子，抛出的面对应生成一个词。如果一篇文档有$n$个词，那么依次独立地抛$n$次骰子，就生成了这$n$个词的序列。</li>
</ol>
<div align="center"><img src="/images/unigram_model_1.png" width="50%" height="50%"></div>  
<div align="center"><font color="grey" size="2">Fig.2 上帝抛掷V个面的骰子 src: LDA数学八卦</font></div>
在这个模型中，模型的参数为各个面的概率$\vec{p} = (p_1, p_2, ..., p_V)$。独立地抛n次$V$个面的骰子，服从多项分布，记作$w \backsim Mult(w|\vec{p})$.
那么生成一篇文档$d = \vec{w} = \lbrace{w_1, w_2, ..., w_n}\rbrace$的概率为 $$p(\vec{w}) = p(w1,w_2,...,w_n) = p(w_1)p(w_2)\cdots p(w_n)$$ 如果语料中有多篇文档$W = \lbrace{\vec{w_1}, \vec{w_2}, ..., \vec{w_m}}\rbrace$，那么语料的概率为: $$p(W) = p(\vec{w_1})p(\vec{w_2})\cdots p(\vec{w_m})$$

<h6 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h6><p>参数估计就是估计模型中的参数$\vec{p}$，也就是要估计骰子每一面的概率是多少。采用统计学中 频率派的观点，采用极大似然估计，最大化语料概率$P(W)$，于是参数$p_i$的估计值为$$p_i = \frac{n_i}{N}$$其中$N$是语料中总的词数，$n_i$是词$v_i$在语料中出现的次数。</p>
<h5 id="贝叶斯观点下的Unigram-Model"><a href="#贝叶斯观点下的Unigram-Model" class="headerlink" title="贝叶斯观点下的Unigram Model"></a>贝叶斯观点下的Unigram Model</h5><h6 id="文本生成-1"><a href="#文本生成-1" class="headerlink" title="文本生成"></a>文本生成</h6><p>对于Unigram Model, 贝叶斯统计学派认为上帝只有唯一一个固定的骰子是不合理的。在贝叶斯学派看来，一切参数都是随机变量，Unigram Model中的骰子$\vec{p}$不是唯一固定的，它也是一个随机变量。按照贝叶斯学派的观点，上帝抛掷骰子的游戏规则，也就是文本生成的过程如下：</p>
<ol>
<li>上帝有一个装着无穷多个骰子的坛子，每个骰子有$V$个面。<font color="#0000dd">每个骰子各个面的概率是固定的，不同骰子间每个面的概率是不同的。</font></li>
<li>上帝先从坛子中抽一个骰子出来，然后用这个骰子抛掷$n$次，就生成了有$n$个词的序列。</li>
</ol>
<div align="center"><img src="/images/unigram_model_2.png" width="50%" height="50%"></div>  
<div align="center"><font color="grey" size="2">Fig.3 Dirichlet先验下的Unigram Model. src: LDA数学八卦</font></div>
<div align="center"><img src="/images/unigram_model_3.png" width="30%" height="30%"></div>  
<div align="center"><font color="grey" size="2">Fig.4 Dirichlet先验下的概率图模型. src: LDA数学八卦</font></div>
坛子中有无穷多个骰子，骰子$\vec{p}是一个随机变量，$从概率分布的角度来看，骰子$\vec{p}$服从一个概率分布$p(\vec{p})$，这个分布称为参数$\vec{p}$的先验分布。

<p>这个先验分布$p(\vec{p})$有很多中选择，我们采用多项分布的共轭分布：Dirichlet分布，有$\vec{p} \backsim Dir(\vec{p}|\vec{\alpha})$,其中$\vec{\alpha} = \lbrace{\alpha_1,\alpha_2, …, \alpha_V}\rbrace$是Dirichlet分布的参数。<br>多项分布及其共轭分布 Dirichlet分布有以下性质：$$Dirichlet先验分布 + 多项分布的数据 \to 后验分布为Dirichlet分布$$ <strong>加了贝叶斯观点后的区别</strong><br>原Unigram Model中，只有唯一一个骰子，骰子每个面的概率$\vec{p}$是固定不变的。而贝叶斯观点下，骰子$\vec{p}$不是固定不变的，而应该是一个随机变量，也就是骰子有无穷多个。$\vec{p}$服从一个概率分布，称为$\vec{p}$的先验分布。贝叶斯观点下，多了一个随机变量$\vec{p}$的先验分布。</p>
<h6 id="参数估计-1"><a href="#参数估计-1" class="headerlink" title="参数估计"></a>参数估计</h6><p>贝叶斯观点下Unigram Model的参数估计可以参见<a href="https://bloglxm.oss-cn-beijing.aliyuncs.com/lda-LDA%E6%95%B0%E5%AD%A6%E5%85%AB%E5%8D%A6.pdf" target="_blank" rel="noopener">LDA数学八卦</a>。</p>
<h5 id="PLSA主题模型"><a href="#PLSA主题模型" class="headerlink" title="PLSA主题模型"></a>PLSA主题模型</h5><p>Unigram Model过于简单。一篇文章通常是由多个主题构成的，比如：一篇nlp相关的文章，可能30%谈论语言学，30%谈论概率统计，20%谈论神经网络，20%谈论计算机。<br>主题模型中的主题指的是什么呢？一个主题可以用该主题相关的频率最高的一些词来描述。PLSA(Probalilistic Latent Senmantic Analysis)模型认为，一篇文档由多个主题(topics)混合而成，每个topic是在词汇上的概率分布，文章中的每个词都是由一个固定的topic生成的。</p>
<h6 id="文本生成-2"><a href="#文本生成-2" class="headerlink" title="文本生成"></a>文本生成</h6><p>再回到上帝抛掷骰子上来，PLSA模型认为上帝是按照以下的游戏规则来生成文本的。</p>
<ol>
<li>上帝有两个类型的骰子，一类是doc-topic骰子，每个doc-topic骰子有$K$个面，每个面对应一个topic；一类骰子是topic-word骰子，每个topic-word骰子有$V$个面，每个面对应一个词。</li>
<li>上帝一共有$K$个topic-word骰子，每个topic-word骰子对应一个topic。</li>
<li>在生成每篇文档前，上帝先为这篇文档制造一个特定的doc-topic骰子。然后重复以下过程生成文档中的词：<ul>
<li>抛掷这个doc-topic骰子，得到一个topic；</li>
<li>选择这个topic对应topic-word骰子，抛掷这个topic-word骰子，得到一个词。</li>
</ul>
</li>
</ol>
<p>PLSA模型文本生成的过程可以图形化地表示为：</p>
<div align="center"><img src="/images/plsa.png" width="50%" height="50%"></div>  
<div align="center"><font color="grey" size="2">Fig.5 PLSA模型的文本生成过程. src: LDA数学八卦</font></div>

<h6 id="参数估计-2"><a href="#参数估计-2" class="headerlink" title="参数估计"></a>参数估计</h6><p>PLSA模型有两类参数，也就是doc-topic骰子每个面的概率$p(topic_k|doc_i)$，和$K$个topic-word骰子每个面的概率$p(word_j|topic_k)$。对于包含$M$篇文档的语料$C = ({d_1, d_2, …, d_M})$，每篇文档对应一个特定的doc-topic骰子，所有对应的骰子记为$(\vec{\theta_1}, \vec{\theta_2}, …, \vec{\theta_M})$; 游戏中总共有$K$个topic-word骰子，记为$(\vec{\varphi_1}, \vec{\varphi_2}, …, \vec{\varphi_K})$。</p>
<p>可以使用著名的<a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" target="_blank" rel="noopener">EM算法</a>来估计PLSA模型的参数。参数估计的求解参见：<a href="https://blog.csdn.net/v_july_v/article/details/41209515#t15" target="_blank" rel="noopener">通俗理解LDA主题模型-CSDN</a><br>估计模型参数的过程，实际上就是：根据文档中的词序列来反推其主题分布的过程。doc-topic骰子每个面的概率$p(topic_k|doc_i)$表征了文档的主题分布，topic-word骰子每个面的概率$p(word_j|topic_k)$表征了主题的词分布（PLSA模型认为 topic是在词汇上的概率分布）。</p>
<h4 id="LDA主题模型"><a href="#LDA主题模型" class="headerlink" title="LDA主题模型"></a>LDA主题模型</h4><p>对于上述的PLSA模型，doc-topic骰子$\theta_m$和topic-word骰子$\varphi_k$都是模型中的参数，贝叶斯学派认为 参数都是随机变量。类似于Unigram Model的贝叶斯改造，在两个骰子参数前加上先验分布，从而将PLSA的抛骰子游戏过程改造成一个贝叶斯的游戏过程。由于$\varphi_k$和$\theta_m$都对应多项分布，因此先验分布采用Dirichlet分布，于是就得到了LDA(Latent Dirichlet Allocation)模型。总的来说，LDA模型是对PLSA模型的贝叶斯版本。</p>
<h5 id="文本生成-3"><a href="#文本生成-3" class="headerlink" title="文本生成"></a>文本生成</h5><p>在LDA模型中，上帝是按照以下的规则来玩文档生成的游戏的：</p>
<ol>
<li>上帝有两大坛子的骰子，第一个坛子里装了无穷多个doc-topic骰子，第二个坛子里装了无穷多个topic-word骰子。</li>
<li>上帝随机从第二个坛子里独立地抽取$K$个topic-word骰子，标号$1-K$。</li>
<li>每次生成一篇文档前，上帝先从第一个坛子里随机抽取一个doc-topic骰子。然后重复以下过程生成文档中的词：<ul>
<li>先抛掷这个doc-topic骰子，得到一个topic编号$z$；</li>
<li>从$K$个topic-word骰子中选择编号为$z$的那个，抛掷这个骰子，生成一个词。</li>
</ul>
</li>
</ol>
<p><strong>PLSA模型与LDA模型的区别</strong></p>
<ul>
<li>PLSA模型中，doc-topic骰子和topic-word骰子是唯一确定的，也就是虽然doc-topic骰子$\vec{\theta_m}$和topic-word骰子$\vec{\varphi_k}$是未知的，但是确定的固定不变的。</li>
<li>LDA模型中，doc-topic骰子$\vec{\theta_m}$和topic-word骰子$\vec{\varphi_k}$是未知的，而且是随机变量，不是唯一确定的。这两类随机变量$\vec{\theta_m}$和$\vec{\varphi_k}$服从某个概率分布，我们采用与多项分布的共轭分布：Dirichlet分布。</li>
</ul>
<div align="center"><img src="/images/LDA_1.png" width="60%" height="60%"></div>  
<div align="center"><font color="grey" size="2">Fig.6 LDA模型. src: LDA数学八卦</font></div>

<p><strong>物理过程分解</strong><br>LDA模型的概率图表示如下图所示：</p>
<div align="center"><img src="/images/LDA_4.png" width="45%" height="45%"></div>  
<div align="center"><font color="grey" size="2">Fig.7 LDA模型概率图表示. src: LDA数学八卦</font></div>

<p>这个概率图可以分解为两个主要的物理过程：</p>
<ol>
<li>$\vec{\alpha} \to \vec{\theta_m} \to z_{m,n}$: 这个过程表示在生成第$m$篇文档时，先从第一个坛子中抽取一个doc-topic骰子$\vec{\theta_m}$, 再抛掷这个骰子生成文档中的第$n$个词的topic编号$z_{m,n}$。</li>
<li>$\vec{\beta} \to \vec{\varphi_k} \to w_{m,n}|k = z_{m,n}$: 这个过程表示生成第$m$篇文档的第$n$个词时，从第二个坛子中抽取$K$个topic-word骰子$\vec{\varphi} = (\varphi_1, \varphi_2, …, \varphi_K)$，挑选编号为$k = z_{m,n}$的骰子进行抛掷，生成第$n$个词$w_{m,n}$。</li>
</ol>
<p>换一个角度来解释这两个物理过程：</p>
<div align="center"><img src="/images/LDA_2.png" width="60%" height="60%"></div>  
<div align="center"><font color="grey" size="2">Fig.8 第一个物理过程. src: LDA数学八卦</font></div>

<ol>
<li><p>$\vec{\alpha} \to \vec{\theta_m} \to z_{m,n}$表示生成文档中所有词对应的主题。$\vec{\alpha} \to \vec{\theta_m}$对应Dirichlet分布，$\vec{\theta_m} \to z_{m,n}$对应Multinomial分布，整体是一个Dirichlet-Multinomial共轭结构。第一步：从参数为$\vec{\alpha}$的Dirichlet先验分布中采样得到文档的主题分布$\vec{\theta_m}$，这是一个多项式分布；第二步：从参数为$\vec{theta_m}$的多项式分布中采样一个主题$z_{m,n}$。</p>
<div align="center"><img src="/images/LDA_3.png" width="60%" height="60%"></div>  
<div align="center"><font color="grey" size="2">Fig.9 第二个物理过程. src: LDA数学八卦</font></div>
</li>
<li><p>$\vec{\beta} \to \vec{\varphi_k} \to w_{m,n}|k = z_{m,n}$表示生成文档中的词。$\vec{\beta} \to \vec{\varphi_k}$对应Dirichlet分布，$\vec{\varphi_k} \to w_{m,n}$对应多项式分布，整体是一个Dirichlet-Multinomial共轭结构。第一步：从参数为$\vec{\beta}$的Dirichlet先验分布中采样得到主题的词分布$\vec{\varphi_k}$，这是一个多项式分布；第二步：在这个参数为$\vec{\varphi_k}$的词分布中抽样一个词$w_k$。</p>
</li>
</ol>
<h5 id="参数估计-3"><a href="#参数估计-3" class="headerlink" title="参数估计"></a>参数估计</h5><p>接下来的问题是，LDA模型怎么由文档来反推每一篇文档的主题分布和每一个主题的词分布呢？一般有两种方法：<a href="http://www.cnblogs.com/pinard/p/6867828.html" target="_blank" rel="noopener">Gibbs采样算法</a>和<a href="http://www.cnblogs.com/pinard/p/6873703.html" target="_blank" rel="noopener">变分推断EM算法</a>。详见：<a href="https://bloglxm.oss-cn-beijing.aliyuncs.com/lda-LDA%E6%95%B0%E5%AD%A6%E5%85%AB%E5%8D%A6.pdf" target="_blank" rel="noopener">LDA数学八卦</a></p>
<h4 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h4><ul>
<li><a href="https://bloglxm.oss-cn-beijing.aliyuncs.com/lda-LDA%E6%95%B0%E5%AD%A6%E5%85%AB%E5%8D%A6.pdf" target="_blank" rel="noopener">LDA数学八卦</a></li>
<li><a href="https://blog.csdn.net/v_july_v/article/details/41209515" target="_blank" rel="noopener">通俗理解LDA主题模型-CSDN</a></li>
<li><a href="https://www.cnblogs.com/pinard/p/6831308.html" target="_blank" rel="noopener">文本主题模型之LDA-博客园刘建平</a></li>
</ul>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2020-07-24T02:01:48.000Z" itemprop="dateUpdated">2020-07-24 10:01:48</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/avatar.jpg" alt="spring">
            spring
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LDA/">LDA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PLSA/">PLSA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Unigram-Model/">Unigram Model</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/主题模型/">主题模型</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2020/07/21/LDA主题模型/&title=《LDA主题模型》 — spring's Blog&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2020/07/21/LDA主题模型/&title=《LDA主题模型》 — spring's Blog&source=LDA(Latent Dirichlet Allocation, 隐含狄利克雷分布)是一种主题模型，将文档集中每篇文档的主题以概率分布的形式给出。LDA模..." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2020/07/21/LDA主题模型/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《LDA主题模型》 — spring's Blog&url=http://yoursite.com/2020/07/21/LDA主题模型/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2020/07/21/LDA主题模型/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2020/07/20/NLP中的文本表示与词向量/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">NLP中的文本表示与词向量</h4>
      </a>
    </div>
  
</nav>



    


<section class="comments" id="comments">
    <div id="disqus_thread"></div>
    <script>
    var disqus_shortname = 'true';
    lazyScripts.push('//' + disqus_shortname + '.disqus.com/embed.js')
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>










    <!-- Valine Comments -->
    <div class="comments vcomment" id="comments"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
    <!-- Valine Comments script -->
    <script>
        var GUEST_INFO = ['nick','mail','link'];
        var guest_info = 'nick,mail,link'.split(',').filter(function(item){
          return GUEST_INFO.indexOf(item) > -1
        });
        new Valine({
            el: '#comments',
            notify: 'false' == 'true',
            verify: 'false' == 'true',
            appId: "",
            appKey: "",
            avatar: "mm",
            placeholder: "Just go go",
            guest_info: guest_info.length == 0 ? GUEST_INFO : guest_info,
            pageSize: "10"
        })
    </script>
    <!-- Valine Comments end -->










</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        感谢支持~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/images/wechatpay.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/images/wechatpay.jpg" data-alipay="/images/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>spring &copy; 2018 - 2020</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2020/07/21/LDA主题模型/&title=《LDA主题模型》 — spring's Blog&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2020/07/21/LDA主题模型/&title=《LDA主题模型》 — spring's Blog&source=LDA(Latent Dirichlet Allocation, 隐含狄利克雷分布)是一种主题模型，将文档集中每篇文档的主题以概率分布的形式给出。LDA模..." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2020/07/21/LDA主题模型/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《LDA主题模型》 — spring's Blog&url=http://yoursite.com/2020/07/21/LDA主题模型/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2020/07/21/LDA主题模型/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=http://yoursite.com/2020/07/21/LDA主题模型/" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'spring's Blog';
            clearTimeout(titleTime);
        } else {
            document.title = 'spring's Blog';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
