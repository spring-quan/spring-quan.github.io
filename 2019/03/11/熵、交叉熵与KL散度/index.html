<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>熵、交叉熵与KL散度 | spring&#39;s Blog | 游龙当归海，海不迎我自来也。</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="交叉熵,相对熵">
    <meta name="description" content="介绍交叉熵和KL散度。">
<meta name="keywords" content="交叉熵,相对熵">
<meta property="og:type" content="article">
<meta property="og:title" content="熵、交叉熵与KL散度">
<meta property="og:url" content="http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/index.html">
<meta property="og:site_name" content="spring&#39;s Blog">
<meta property="og:description" content="介绍交叉熵和KL散度。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-07-22T00:57:32.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="熵、交叉熵与KL散度">
<meta name="twitter:description" content="介绍交叉熵和KL散度。">
    
        <link rel="alternate" type="application/atom+xml" title="spring&#39;s Blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.jpg">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">spring</h5>
          <a href="mailto:ccq1996@bupt.edu.cn" title="ccq1996@bupt.edu.cn" class="mail">ccq1996@bupt.edu.cn</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                分类
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/spring-quan" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/custom"  >
                <i class="icon icon-lg icon-link"></i>
                测试
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">熵、交叉熵与KL散度</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">熵、交叉熵与KL散度</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-03-11T06:31:33.000Z" itemprop="datePublished" class="page-time">
  2019-03-11
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/机器学习/">机器学习</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#从信息量到信源熵"><span class="post-toc-number">1.</span> <span class="post-toc-text">从信息量到信源熵</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#交叉熵"><span class="post-toc-number">2.</span> <span class="post-toc-text">交叉熵</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#相对熵"><span class="post-toc-number">3.</span> <span class="post-toc-text">相对熵</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#tensorflow用交叉熵做损失函数"><span class="post-toc-number">4.</span> <span class="post-toc-text">tensorflow用交叉熵做损失函数</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#pytorch中交叉熵损失函数的实现"><span class="post-toc-number">5.</span> <span class="post-toc-text">pytorch中交叉熵损失函数的实现</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#torch-nn-functional-log-softmax-与class-torch-nn-NLLLoss"><span class="post-toc-number">5.1.</span> <span class="post-toc-text">torch.nn.functional.log_softmax()与class torch.nn.NLLLoss()</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#class-torch-nn-CrossEntropyLoss-weight-None"><span class="post-toc-number">5.2.</span> <span class="post-toc-text">class torch.nn.CrossEntropyLoss(weight = None)</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#参考链接"><span class="post-toc-number">6.</span> <span class="post-toc-text">参考链接</span></a></li></ol>
        </nav>
    </aside>


<article id="post-熵、交叉熵与KL散度"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">熵、交叉熵与KL散度</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-03-11 14:31:33" datetime="2019-03-11T06:31:33.000Z"  itemprop="datePublished">2019-03-11</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/机器学习/">机器学习</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>介绍交叉熵和KL散度。</p>
<a id="more"></a> 
<h2 id="从信息量到信源熵"><a href="#从信息量到信源熵" class="headerlink" title="从信息量到信源熵"></a>从信息量到信源熵</h2><ol>
<li>信息量是通信专业的名词。一个变量的主要特征就是不确定性，也就是发生的概率。信息量用来衡量不确定性的大小。一个事情发生的概率越小，使人越感到意外，则这件事的信息量越大；反之，概率越大，越不意外，信息量越小。举个例子，有一架波音747飞机失事，发生的概率很小，让人很意外，带给人的信息量很大。<br> 信息量函数应满足两个特性：1）随着概率的增大而减小，即是概率的减函数；2）信息量函数满足可加性，即两个统计独立的消息提供的信息量等于他们分别提供的信息量之和。同时满足递减性和可加性的函数是对数函数，即<br> $$ I[p(x_i)] = log \frac{1}{p(x_i)} = -log p(x_i)$$</li>
<li>信源熵定义为信源输出的平均信息量，即信息量的数学期望。$$ H(X) = E(I[p(x_i)]) = E(-log p(x_i)) = - \sum_{i=1}^{n}p(x_i)log p(x_i)$$信源实际上是一个概率分布，信源熵可以解释为表示这个概率分布至少需要的信息量。</li>
</ol>
<h2 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h2><p>对于一个随机事件，真实概率分布是$p(x_i)$ 是未知的，从数据中得到概率分布为$q(x_i)$。我们用概率分布$q(x_i)$来近似和逼近真实的概率分布$p(x_i)$ 。交叉熵定义为：$$H(p,q) = \sum_{i=1}^{n}p(x_i) I[q(x_i)] =- \sum_{i=1}^{n}p(x_i)log(x_i) $$交叉熵$H(p,q)$是用概率分布$q(x_i)$来近似真实概率分布$p(x_i)$需要的信息量。上面我们说过，信源熵$H(X)$是表示真实概率分布$p(x_i)$需要的最小信息量。可以得到结论：$$H(p,q) \ge H(p)$$由吉布斯不等式可以证明，当且仅当分布$p(x_i)$与$q(x_i)$完全一致时，等号才成立。这个不等式的意义是：用概率分布$q(x_i)$来近似真实概率分布$p(x_i)$需要的信息量一定大于等于概率分布$p(x_i)$本身的信源熵。交叉熵比信源熵多出来的这部分，就是冗余信息量，我们称为KL散度（相对熵）。<br>$$KL(p||q)= H(p,q) - H(p) \ge 0$$容易看出交叉熵并不是一个对称量，即$ H(p,q) \not=H(q,p)$。同样的,KL散度也不是一个对称量，即$KL(p||q) \not =KL(q||p) $<br>给定概率分布$p(x_i)$,信源熵$H(p)$就是固定不变的。在机器学习中，交叉熵常用作分类问题的损失函数。交叉熵刻画了预测概率分布$q(x_i)$与真实概率分布$p(x_i)$之间的距离。通过减小交叉熵$H(p,q)$,我们可以使得预测概率分布$q(x_i)$不断逼近真实概率分布$p(x_i)$</p>
<h2 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h2><p>真实的概率分布为$p(x_i)$，我们用预测概率分布$q(x_i)$对它进行建模和近似。我们需要的平均附加量，也就是冗余量是：<br>$$KL(p,q) = H(p,q) - H(q) = -\sum_{i=1}^{n}p(x_i)logq(x_i) - \biggl(-\sum_{i=1}^{n}p(x_i)logp(x_i)\biggr) = -\sum_{i=1}^{n}p(x_i)log{\frac{q(x_i)}{p(x_i)}}$$KL散度有以下几个特性：</p>
<ul>
<li>KL散度不是一个对称量，即$KL(p||q) \not =KL(q||p) $</li>
<li>$KL(p||q)\ge 0$，当且仅当分布$p(x_i)$与$q(x_i)$完全一致时，等号才成立。</li>
<li>KL散度可以看做两个分布之间不相似程度的度量。KL散度越小，两个分布的不相似程度越小，分布$q(x_i)$越适合来近似$p(x_i)$。</li>
</ul>
<h2 id="tensorflow用交叉熵做损失函数"><a href="#tensorflow用交叉熵做损失函数" class="headerlink" title="tensorflow用交叉熵做损失函数"></a>tensorflow用交叉熵做损失函数</h2><p>在机器学习中交叉熵常常用作分类问题的损失函数。这里有个问题，交叉熵用于概率分布，但神经网络的输出并不一定是一个概率分布。<br>概率分布应满足2个条件:<br>1) $0 \le p(X =x) \le 1$<br>2) $\sum_{x}{} p(X=x) = 1$<br>如何把神经网络的输出变成概率分布呢？这里就要用到softmax回归。假设输出层的输出为$y_0,y_1,y_2 \dots y_n$,则softmax函数的形式为：$$softmax(y_i) = \frac{exp(y_i)}{\sum_{j}exp(y_j)}$$由于交叉熵一般会与softmax回归一起使用，TensorFlow对这两个功能进行了统一，可以直接用函数<a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3.html" target="_blank" rel="noopener">tf.nn.softmax_cross_entropy_with_logits</a>来计算softmax后的交叉熵函数。对于只有一个正确答案的分类问题，可以用函数<a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3.html" target="_blank" rel="noopener">tf.nn.sparse_nn.softmax_cross_entropy_with_logits</a>来加速计算过程。</p>
<h2 id="pytorch中交叉熵损失函数的实现"><a href="#pytorch中交叉熵损失函数的实现" class="headerlink" title="pytorch中交叉熵损失函数的实现"></a>pytorch中交叉熵损失函数的实现</h2><p>在多分类问题中，实际概率分布是 $y = [y_0,y_1,…,y_{C-1}]$,其中C为类别数;y是样本标签的one-hot表示，当样本属于第$i$类时$y_i=1$,否则$y_i=0$。预测概率分布为$p = [p_0,p_1,p_2,…,p_{C-1}]$。$c$是样本标签。此时，交叉熵损失函数为$$loss = -\sum_{i=0}^{C-1}y_i log(p_i) = - y_c \cdot log(p_c) = - log(p_c)$$<br>接下来介绍pytorch中具体实现这个数学式子的函数。</p>
<h3 id="torch-nn-functional-log-softmax-与class-torch-nn-NLLLoss"><a href="#torch-nn-functional-log-softmax-与class-torch-nn-NLLLoss" class="headerlink" title="torch.nn.functional.log_softmax()与class torch.nn.NLLLoss()"></a>torch.nn.functional.log_softmax()与class torch.nn.NLLLoss()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.log_softmax()</span><br></pre></td></tr></table></figure>

<ul>
<li>作用：先做softmax运算，再做log运算。在数学上等价于$log(softmax(x))$</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class torch.nn.NLLLoss(weight = None)</span><br></pre></td></tr></table></figure>

<ul>
<li>作用：这是neg log likelihood loss（NLLLoss），即负对数似然函数。</li>
<li>参数：   <ul>
<li>weight(tensor,optional): 一维tensor，里面的值对应类别的权重。当训练集样本分布不均匀时，使用这个参数非常重要。手动指定类别的权重，长度应为类别个数C。</li>
</ul>
</li>
<li>输入：<ul>
<li>input(N,C): C是类别个数。为<code>log_probabilities</code>形式，即概率分布再取log。可以在最后一层加<code>log_softmax</code>,这就要用到函数<code>torch.nn.functional.log_softmax()</code></li>
<li>targets(N): 是类别的索引，而不是类别的one-hot表示。比如，5个类别中的第3类，target应为<code>2</code>,而不是<code>[0,0,1,0,0]</code></li>
</ul>
</li>
</ul>
<p>loss可以表示为：$$loss(x,class) = -x[class]$$如果指定了weight，可以表示为：$$loss(x,class) = - weight[class]*x[class]$$<br>举个例子:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">log_m = torch.nn.functional.log_softmax()</span><br><span class="line">loss_function = torch.nn.NLLLoss()</span><br><span class="line">inputs = torch.randn(3,5) #batch_size * num_classes = 3 * 5</span><br><span class="line">target = torch.LongTensor([1,0,4])</span><br><span class="line">loss = loss_function(log_m(inputs),target)  # inputs要先做log_softmax，再送入loss_function</span><br><span class="line">loss.backward()</span><br></pre></td></tr></table></figure>

<h3 id="class-torch-nn-CrossEntropyLoss-weight-None"><a href="#class-torch-nn-CrossEntropyLoss-weight-None" class="headerlink" title="class torch.nn.CrossEntropyLoss(weight = None)"></a>class torch.nn.CrossEntropyLoss(weight = None)</h3><ul>
<li>作用：将函数<code>log_softmax</code>和<code>NLLLoss</code>集成到一起。在多分类问题中非常有用。</li>
<li>参数：   <ul>
<li>weight(tensor,optional): 一维tensor，里面的值对应类别的权重。当训练集样本分布不均匀时，使用这个参数非常重要。手动指定类别的权重，长度应为类别个数C。</li>
</ul>
</li>
<li>输入：<ul>
<li>input(N,C): C是类别个数。每个类别的分数，不用过softmax层。</li>
<li>targets(N): 是类别的索引，而不是类别的one-hot表示。比如，5个类别中的第3类，target应为<code>2</code>,而不是<code>[0,0,1,0,0]</code>。</li>
</ul>
</li>
</ul>
<p>loss可以表示为：$$loss(x,class) = - \text{log}\frac{e^{x[class]}}{ \sum_{j=0}^{C-1}e^{x[j]}} = -x[class] + \text{log}(\sum_{j=0}^{C-1}e^{x[j]}) $$当指定了weight时，loss计算公式为： $$ loss(x, class) = weights[class] \cdot (-x[class] + \text{log}(\sum_{j=0}^{C-1}e^{x[j]})) $$<br>参见：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/56638625" target="_blank" rel="noopener">PyTorch学习笔记——多分类交叉熵损失函数</a></li>
<li><a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#loss-functions" target="_blank" rel="noopener">pytorch官方手册</a><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2></li>
<li><a href="https://wizyoung.github.io/%E4%BF%A1%E6%81%AF%E7%86%B5%EF%BC%8C%E7%9B%B8%E5%AF%B9%E7%86%B5%EF%BC%8C%E4%BA%A4%E5%8F%89%E7%86%B5%E7%9A%84%E7%90%86%E8%A7%A3/#more" target="_blank" rel="noopener">信息熵，相对熵，交叉熵的理解</a></li>
<li><a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3.html" target="_blank" rel="noopener">Tensorflow基础知识—损失函数详解</a></li>
</ul>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2019-07-22T00:57:32.000Z" itemprop="dateUpdated">2019-07-22 08:57:32</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/avatar.jpg" alt="spring">
            spring
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/交叉熵/">交叉熵</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/相对熵/">相对熵</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/&title=《熵、交叉熵与KL散度》 — spring's Blog&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/&title=《熵、交叉熵与KL散度》 — spring's Blog&source=介绍交叉熵和KL散度。" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《熵、交叉熵与KL散度》 — spring's Blog&url=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2019/03/11/sublime插件/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">sublime插件</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2019/03/10/python的一些函数/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">python的一些函数</h4>
      </a>
    </div>
  
</nav>



    




















</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        感谢支持~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/images/wechatpay.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/images/wechatpay.jpg" data-alipay="/images/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>spring &copy; 2018 - 2019</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/&title=《熵、交叉熵与KL散度》 — spring's Blog&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/&title=《熵、交叉熵与KL散度》 — spring's Blog&source=介绍交叉熵和KL散度。" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《熵、交叉熵与KL散度》 — spring's Blog&url=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'spring's Blog';
            clearTimeout(titleTime);
        } else {
            document.title = 'spring's Blog';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
