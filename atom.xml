<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>spring&#39;s Blog</title>
  
  <subtitle>游龙当归海，海不迎我自来也。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-07-24T06:19:10.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>spring</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>attention? attention!</title>
    <link href="http://yoursite.com/2019/07/23/attention-attention/"/>
    <id>http://yoursite.com/2019/07/23/attention-attention/</id>
    <published>2019-07-23T08:20:18.000Z</published>
    <updated>2019-07-24T06:19:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>读了博主lilian的文章<a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#neural-turing-machines" target="_blank" rel="noopener">attention? attention!</a>，是一篇很好的文章。打算按照这篇文章的思路，进行翻译，并添加自己的理解。<br>attention机制在深度学习中被广为使用，本文介绍attention机制的提出，不同的attention机制，及attention机制的进一步探索和应用。</p><a id="more"></a><h3 id="why-we-need-attention-从seq2seq模型谈起"><a href="#why-we-need-attention-从seq2seq模型谈起" class="headerlink" title="why we need attention?从seq2seq模型谈起"></a>why we need attention?从seq2seq模型谈起</h3><p><strong>seq2seq模型</strong>与14年提出(<a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" target="_blank" rel="noopener">Sutskever, et al. 2014</a>)，实现输入序列(source sequence)到输出序列(target sequence)的映射，这两个序列的长度都是可变的。序列到序列映射的任务包括机器翻译、问答系统、对话系统、摘要生成等。</p><p>用数学语言来定义序列到序列的任务，给定输入序列(source sequence) $X = \lbrace{ x_1,x_2,…,x_n \rbrace}$，需要生成输出序列(target sequence) $Y = \lbrace{ y_1,y_2,…,y_m \rbrace}$，其中source sequence长度为$n$,target sequence长度为$m$。</p><p><strong>seq2seq模型</strong>基于encoder-decoder框架，包括2个部分：</p><ol><li><p><strong>encoder</strong>将source sequence编码（映射）为一个固定维度的向量表示(context vector,或称为sentence embedding)，我们希望这个向量表示可以很好的表示source sequence的意思。<br> encoder可以采用卷积神经网络CNN，也可以采用循环神经网络RNN，但用的更多的效果也更好的还是RNN。通常使用<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">LSTM 或 GRU</a>。<br> encoder RNN的隐藏状态更新公式为：$$\begin{gather}h_t = f(h_{t-1},x_t)\end{gather}$$其中$h_t$为RNN在时间步t的隐藏状态，f为LSTM 或GRU.<br> 对于长度为n的source sequence，一个词接一个词地输入RNN后，可以得到n个隐藏状态$(h_1,h_2,…,h_n)$，通常将最后一个时间步最后一个词对应的隐藏状态$h_t$作为source sequence的向量表示，也就是context vector，记为$c$。</p></li><li><p><strong>decoder</strong>根据source sequence的向量表示context vector，来一个词一个词的生成target sequence。<br> decoder采用单向RNN，decoder RNN隐藏状态的更新公式为:$$\begin{gather}s_t = f(s_{t-1},y_{t-1},c)\end{gather}$$其中$s_t$为decoder在时间步t的隐藏状态，$y_{t-1}$为target sequence中的上一个词，在train阶段，$y_{n-1}$为真实target sequence中的上一个词，在infer阶段，$y_{t-1}$为预测输出的上一个词；c为context vector。<br> 时间步t，隐藏状态$s_t$再经过线性层和softmax得到在词表上的概率分布，将概率最大的词作为prediction word $y_t$。迭代循环直到输出整个target sequence。</p></li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/43.png" alt="Fig.1. seq2seq模型的框架图" title>                </div>                <div class="image-caption">Fig.1. seq2seq模型的框架图</div>            </figure><p>我们可以看到当生成不同的$y_t$时，所依据的context vector都是固定不变的。固定的context vector有一个缺点是：当encoder编码完整个source sequence时，会偏向于最近的词，而遗忘了距离更远的最开始的一些词。<a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">(Bahdanau et al., 2015)</a>提出了attention机制来解决这个问题。</p><h3 id="attention机制-born-for-Translation"><a href="#attention机制-born-for-Translation" class="headerlink" title="attention机制:born for Translation"></a>attention机制:born for Translation</h3><p>attention机制最先在机器翻译(neural machine translation,NMT)任务上提出。从解决长期依赖问题的角度，attention可以实现长距离的记忆；从注意力的角度，attention机制可以实现对齐(alignment)，用更多的注意力关注到相关的部分，而忽略或低注意力关注到不相关的部分。</p><p>上文中提到，在生成不同的$y_t$时，直接将encoder最后一个时间步的隐藏状态$h_n$作为固定context vector。不同于这种方法，attention机制将所有encoder隐藏状态$\lbrace{ h_1,h_2,…,h_n }\rbrace$的加权和作为context vector，这样在每个时间步t生成$y_t$时，所依据的context vector都是专门针对于$y_t$的。<br>一方面，context vector可以获取到所有隐藏状态，也就是整个source sequence的信息，这样就可以实现长距离的记忆。另一方面，source sequence 与target sequence之间的语义对齐(aligenment)是也是通过context vector实现的。在计算时间步t生成$y_t$对应的context vector $c_t$的计算需要三个部分的信息：</p><ul><li>所有的encoder隐藏状态： $\lbrace{ h_1,h_2,…,h_n }\rbrace$</li><li>上个时间步t-1的decoder 隐藏状态： $s_{t-1}$</li><li>source与target之间的alignment.<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/44.png" alt="Fig.2.有attention机制的encoder-decoder模型，来源:[Bahdanau et al., 2015.](https://arxiv.org/pdf/1409.0473.pdf)" title>                </div>                <div class="image-caption">Fig.2.有attention机制的encoder-decoder模型，来源:[Bahdanau et al., 2015.](https://arxiv.org/pdf/1409.0473.pdf)</div>            </figure></li></ul><h4 id="attention的数学定义"><a href="#attention的数学定义" class="headerlink" title="attention的数学定义"></a>attention的数学定义</h4><p>在计算时间步t生成$y_t$对应的context vector $c_t$时，encoder的所有隐藏状态为 $\lbrace{ h_1,h_2,…,h_n }\rbrace$，时间步t-1的decoder隐藏状态为 $s_{t-1}$，decoder RNN的隐藏状态更新公式变为：$$\begin{gather}s_t = f(s_{t-1},y_{t-1},c_t)\end{gather}$$ context vector $c_t$为encoder hidden state的加权和：<br>$$c_t = \sum_{i=1}^{n}\alpha_{t,i}h_i$$ $$\alpha_{t,i} = softmax(\beta_{t,i}) = \frac{exp(\beta_{t,i})}{\sum_{j = 1}^{n}exp(\beta_{t,j})}$$ $$\beta_{t,i} = score(s_{t-1},h_i)$$<br>其中权重$\alpha_{t,i}$是时间步t生成$y_t$与隐藏状态$h_i$之间的score，从某种意义上说，$h_i$可以看作是$x_i$的表示，也可以看作是$\lbrace{x_1,x_2,…,x_{i}}\rbrace$的表示。因此，$\alpha_{t,i}$可以看作是$y_t$与$x_i$之间联系（相关性）的score。所有权重$\lbrace{\alpha_{t,1},\alpha_{t,2},…,\alpha_{t,n}}\rbrace$衡量了生成$y_t$时应该如何关注到所有的encoder hidden state。</p><p>score()为打分函数，有多种计算方法，下文会详细介绍。在<a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">Bahdanau et al., 2015.</a>中，score()采用前馈神经网络，采用非线性激活函数$tanh()$,score()的数学形式为：$$score(s_{t},h_i) = v_a^\top tanh(W_a[s_t;h_i])$$<br>其中$v_a,W_a$是可训练参数。<br>attention权重可视化矩阵很直观地表明了source words与target words之间的关联关系:</p><div align="center"><img src="/images/45.png" width="60%" height="60%"></div><div align="center"><font color="grey" size="2">Fig.3.来源:[Bahdanau et al., 2015.](https://arxiv.org/pdf/1409.0473.pdf)</font></div><h3 id="各种attention机制"><a href="#各种attention机制" class="headerlink" title="各种attention机制"></a>各种attention机制</h3><h4 id="汇总"><a href="#汇总" class="headerlink" title="汇总"></a>汇总</h4><p>下表总结了使用比较广泛的attention机制，及其对应的alignment score function。</p><table class="table table-bordered table-striped table-condensed">   <tr>      <th width="25">名字</th>      <th>alignment score funtion</th>      <th width="25">来源</th>   </tr>   <tr>      <td>content-based attention</td>      <td>$score(s_t,h_i) = cosine(s_t,h_i)$</td>      <td><a href="https://arxiv.org/abs/1410.5401" target="_blank" rel="noopener">Graves2014</a></td>   </tr>   <tr>      <td>concat/additive</td>      <td>$score(s_{t},h_i) = v_a^\top tanh(W_a[s_t;h_i])$</td>      <td><a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">Bahdanau2015</a></td>   </tr>   <tr>      <td>location-based</td>      <td>$\alpha_{t,i} = softmax(W_as_t)$<br><font color="grey" size="2">将alignment简化为只依赖于target position</font></td>      <td><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a></td>   </tr>   <tr>      <td>general</td>      <td>$score(s_{t},h_i) = s_t^\top W_ah_i$</td>      <td><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a></td>   </tr>   <tr>      <td>dot-product</td>      <td>$score(s_{t},h_i) = s_t^\top h_i$<br><font color="grey" size="2">note:当general attention的$W_a$为单位矩阵时，就退出为dot-product attention</font></td>      <td><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a></td>   </tr>   <tr>      <td>scaled <br>dot-product(*)</td>      <td>$score(s_{t},h_i) = \frac{s_t^\top h_i}{\sqrt{n}}$<br><font color="grey" size="2">note:跟dot-product attention很像，n是encoder hidden state $h_i$的维度</font></td>      <td><a href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noopener">Vaswani2017</a></td>   </tr></table>(*)scaled dot-product attention机制添加了比例因子$/frac{1}{/sqrt{n}}$，动机是：对于softmax()函数，当输入很大时，对应的梯度很小（梯度逐渐消失），难以进行高效的优化和学习。因此，添加比例因子可以减小$score(s_t,h_i)$。<p>下表列出了更广范畴上的attention机制。</p><table class="table table-bordered table-striped table-condensed">   <tr>      <th width="25">名字</th>      <th>定义</th>      <th width="25">来源</th>   </tr>   <tr>      <td>self attention(&)</td>      <td><font color="grey" size="2">将input sequence的不同部分联系起来，只用到input sequence本身，而不用target sequence。<br>可以使用上表中的所有score function，只要将target sequence替换为input sequence即可。</font></td>      <td><a href="https://arxiv.org/pdf/1601.06733.pdf" target="_blank" rel="noopener">Cheng2016</a></td>   </tr>   <tr>      <td>global/soft attention</td>      <td><font color="grey" size="2">context vector是整个input sequence的加权和，注意到整个input sequence</font></td>      <td><a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank" rel="noopener">Xu2015</a></td>   </tr>   <tr>      <td>local/hard attention</td>      <td><font color="grey" size="2">context vector是局部input sequence的加权和，注意到局部input sequence</font></td>      <td><a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank" rel="noopener">Xu2015</a>，<br><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a></td>   </tr></table>(&)self-attention在一些论文中也被称为intra-attention.]]></content>
    
    <summary type="html">
    
      &lt;p&gt;读了博主lilian的文章&lt;a href=&quot;https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#neural-turing-machines&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;attention? attention!&lt;/a&gt;，是一篇很好的文章。打算按照这篇文章的思路，进行翻译，并添加自己的理解。&lt;br&gt;attention机制在深度学习中被广为使用，本文介绍attention机制的提出，不同的attention机制，及attention机制的进一步探索和应用。&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="rnn" scheme="http://yoursite.com/tags/rnn/"/>
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>pip安装python模块报错</title>
    <link href="http://yoursite.com/2019/07/12/pip%E5%AE%89%E8%A3%85python%E6%A8%A1%E5%9D%97%E6%8A%A5%E9%94%99/"/>
    <id>http://yoursite.com/2019/07/12/pip安装python模块报错/</id>
    <published>2019-07-12T01:51:58.000Z</published>
    <updated>2019-07-12T02:11:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>在使用<code>pip install</code>命令安装python模块时，报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cannot uninstall &apos;PyYAML&apos;. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h3><p>报错信息告诉我们：“不能卸载‘pyyaml’模块，因为这个模块是<code>distutils</code>方式安装的，不能确定哪些文件属于这个模块，因此不能完整地卸载这个模块。”</p><p><a href="https://cloud.tencent.com/developer/section/1371690" target="_blank" rel="noopener">distutils</a>是python最初的模块安装和分发系统，distutils不会保留哪些文件属于哪个安装包的信息，甚至不会保留安装包之间的依赖关系。直接使用<code>distutils</code>的方式已经被淘汰，取而代之的是<a href="https://setuptools.readthedocs.io/en/latest/" target="_blank" rel="noopener">setuptools</a>.<br>    所谓模块的分发，就是开发者打包并发布自己的模块，供其他人使用。</p><p>这样我们就知道了，因为<code>pyyaml</code>模块时通过<code>distutils</code>方式安装的，因此不能明确文件与包之间的隶属关系，不能正确卸载。</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>使用下面的命令忽略已安装的模块，强制安装和更新</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install &lt;package-name&gt; --ignore-installed &lt;pyyaml&gt; --upgrade</span><br></pre></td></tr></table></figure><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul><li><a href="https://www.jianshu.com/p/94caf01dd9a6" target="_blank" rel="noopener">强制安装和更新</a></li><li><a href="https://cloud.tencent.com/developer/ask/196670" target="_blank" rel="noopener">如何在Windows操作系统中升级/卸载distutils软件包（PyYAML）？</a></li><li><a href="https://docs.python.org/zh-cn/3/installing/index.html" target="_blank" rel="noopener">python官方手册-安装python模块</a></li><li><a href="https://cloud.tencent.com/developer/section/1371690" target="_blank" rel="noopener">setuptools与distutils</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在使用&lt;code&gt;pip install&lt;/code&gt;命令安装python模块时，报错：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Cannot uninstall &amp;apos;PyYAML&amp;apos;. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>NAACL2019-对话系统</title>
    <link href="http://yoursite.com/2019/07/10/NAACL2019-%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2019/07/10/NAACL2019-对话系统/</id>
    <published>2019-07-10T12:55:17.000Z</published>
    <updated>2019-07-21T15:03:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>记录NAACL2019对话系统相关的论文阅读笔记。包括任务型和闲聊式对话系统，对论文的思路和模型做简单介绍，值得反复精读的论文会单独开一篇博文来写。<br>NAACL2019的会议列表链接：<a href="https://naacl2019.org/program/accepted/" target="_blank" rel="noopener">https://naacl2019.org/program/accepted/</a></p><a id="more"></a><h3 id="《Evaluating-Coherence-in-Dialogue-Systems-using-Entailment》"><a href="#《Evaluating-Coherence-in-Dialogue-Systems-using-Entailment》" class="headerlink" title="《Evaluating Coherence in Dialogue Systems using Entailment》"></a>《Evaluating Coherence in Dialogue Systems using Entailment》</h3><p>【链接】<a href="https://arxiv.org/abs/1904.03371" target="_blank" rel="noopener">https://arxiv.org/abs/1904.03371</a><br>【代码】<a href="https://github.com/nouhadziri/DialogEntailment" target="_blank" rel="noopener">https://github.com/nouhadziri/DialogEntailment</a></p><p>加拿大阿尔伯塔大学发表的论文。论文提出了一种评估对话系统生成回复好坏的指标。<br>这篇论文的想法来源于：发表在ACL2019上的论文<a href="https://arxiv.org/abs/1811.00671" target="_blank" rel="noopener">《Dialogue Natural Language Inference》</a>提出利用NLI(natural language inference)任务来提高对话系统生成回复的一致性。<br>本文的作者则想到用NLI任务来评估对话系统生成回复的好坏。具体地，论文用了BERT<a href="https://arxiv.org/abs/1609.06038" target="_blank" rel="noopener">[Devlin et al., 2018]</a>和The Enhanced Sequential Inference Model(ESIM)<a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">[Chen et al., 2016]</a> 这两种方法来训练NLI模型。另外论文还公开了一个用于NLI任务的数据集。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录NAACL2019对话系统相关的论文阅读笔记。包括任务型和闲聊式对话系统，对论文的思路和模型做简单介绍，值得反复精读的论文会单独开一篇博文来写。&lt;br&gt;NAACL2019的会议列表链接：&lt;a href=&quot;https://naacl2019.org/program/accepted/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://naacl2019.org/program/accepted/&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="NAACL2019" scheme="http://yoursite.com/tags/NAACL2019/"/>
    
  </entry>
  
  <entry>
    <title>ACL2019-对话系统</title>
    <link href="http://yoursite.com/2019/07/07/ACL2019-%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2019/07/07/ACL2019-对话系统/</id>
    <published>2019-07-07T11:19:27.000Z</published>
    <updated>2019-07-21T15:01:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>记录ACL2019对话系统相关的论文阅读笔记。包括任务型和闲聊式对话系统，对论文的思路和模型做简单介绍，值得反复精读的论文会单独开一篇博文来写。<br>ACL2019的会议列表链接：<a href="http://www.acl2019.org/EN/program.xhtml" target="_blank" rel="noopener">http://www.acl2019.org/EN/program.xhtml</a></p><a id="more"></a><h3 id="《Memory-Consolidation-for-Contextual-Spoken-Language-Understanding-with-Dialogue-Logistic-Inference》"><a href="#《Memory-Consolidation-for-Contextual-Spoken-Language-Understanding-with-Dialogue-Logistic-Inference》" class="headerlink" title="《Memory Consolidation for Contextual Spoken Language Understanding with Dialogue Logistic Inference》"></a>《Memory Consolidation for Contextual Spoken Language Understanding with Dialogue Logistic Inference》</h3><p>【链接】：<a href="https://arxiv.org/abs/1906.01788" target="_blank" rel="noopener">https://arxiv.org/abs/1906.01788</a><br>【源码】：无</p><p>中科院自动化所发表的短论文。在多轮对话中，对话历史（context information）对回复（response）的生成有重要作用。任务型对话中的管道模型分为4个模块：NLU、对话状态追踪、对话策略学习 及NLG。对话状态追踪又包含任务：domain classification、intent detection和slot filling。domain classification和intent detection任务当做分类任务来处理，常采用SVM或深度神经网络的方法；slot filling任务被当做序列标注任务来处理，常采用BiLSTM+CRF模型。NLU能否充分利用context information，对这三个下游任务有很大影响。<br>为了更好的利用context information，本文提出了对话逻辑推断任务（DLI,dialog logic inference），任务定义为：将打乱顺序的多轮对话重新排序；输入之前的对话，从剩余的utterance candidates中选中下一句对话。NLU任务采用了所谓的memory network，其实就是采用多个encoder对context information进行编码，再用attention机制或别的方法得到context information总的向量化表示。本文联合训练DLI任务和NLU任务，通过两个任务共享encoder和memory retrieve模块，来让NLU任务更好地利用context information。其实是得到context information更合理的向量化表示，来作为下游domain classification、intent detection和slot filling任务的输入。</p><p>论文提出的将打乱顺序的对话重新排序的DLI任务，可以进一步深入，将句子切分为几段打乱顺序再重新排序；可以应用到闲聊式对话系统中。</p><h3 id="《Dialogue-Natural-Language-Inference》"><a href="#《Dialogue-Natural-Language-Inference》" class="headerlink" title="《Dialogue Natural Language Inference》"></a>《Dialogue Natural Language Inference》</h3><p>【链接】：<a href="https://arxiv.org/abs/1811.00671" target="_blank" rel="noopener">https://arxiv.org/abs/1811.00671</a><br>【代码】：无<br>【数据集】：<a href="https://wellecks.github.io/dialogue_nli/" target="_blank" rel="noopener">https://wellecks.github.io/dialogue_nli/</a></p><p>加利福尼亚大学、Facebook AI Lab发表的论文。核心是提出用NLI(natural language inference)任务来提高persona-based dialog system的一致性。这里就要先搞清楚NLI任务和一致性问题两个概念。</p><ul><li><p>先从问题出发，所谓对话的一致性问题。可以分为两类：</p><ul><li><p>logical contradiction，逻辑矛盾。比如同一个人的两句话:”我有一只狗”，”我没养过狗”。就是逻辑矛盾的。</p></li><li><p>比较模糊的非逻辑矛盾。同一个人不可能说出的两句话：“我从来不运动”，“我去篮球了”。就是这种非逻辑矛盾。真香警告。</p><p>至于persona一致性问题，就是回复的utterance不能与说话人的persona矛盾，也不能与之前的回复有矛盾。</p></li></ul></li><li><p>具体介绍NLI任务。这其实是一个分类问题。论文公开了一个自己标注的NLI数据集。</p><ul><li>训练阶段：训练集形式是 {$（s_1,s_2）$,label }，对应labels $\in$（一致、无关、矛盾）。</li><li>在test阶段，给定一个句子对（句子1，句子2）来判断对应的label。</li></ul></li></ul><p>论文的最终目的是通过NLI任务训练的模型来提高persona dialog system的一致性。这是如何来实现的呢？对于一个dialog system，给定对话历史$（u_1,u_2,…,u_t）$ 及说话人的persona文本描述$（p_1,p_2,…,p_n）$,从response candidates$（y_1,y_2,…,y_m）$中选择一个$u_{t+1}$（如何生成多个responses不是这篇论文要解决的）。<br>用NLI任务的模型来预测$(y_i,u_j),(y_i,p_k)其中：i\in [1,m],j\in [1,t],k \in [1,n]$对应的label，如果句子之间是矛盾的，则添加惩罚项。从而得到一致性最好的utterance作为response。</p><h3 id="《ReCoSa-Detecting-the-Relevant-Contexts-with-Self-Attention-for-Multi-turn-Dialogue-Generation》"><a href="#《ReCoSa-Detecting-the-Relevant-Contexts-with-Self-Attention-for-Multi-turn-Dialogue-Generation》" class="headerlink" title="《ReCoSa: Detecting the Relevant Contexts with Self-Attention for Multi-turn Dialogue Generation》"></a>《ReCoSa: Detecting the Relevant Contexts with Self-Attention for Multi-turn Dialogue Generation》</h3><p>【链接】：<a href="https://arxiv.org/abs/1907.05339" target="_blank" rel="noopener">https://arxiv.org/abs/1907.05339</a><br>【数据集】：<a href="https://github.com/rkadlec/ubuntu-ranking-dataset-creator" target="_blank" rel="noopener">English Ubuntu dialogue corpus</a><br>【代码】：<a href="https://github.com/zhanghainan/ReCoSa" target="_blank" rel="noopener">https://github.com/zhanghainan/ReCoSa</a></p><p>中科院发表的论文。<br>在多轮对话中，生成response时，对话历史中最相关的部分起着重要的作用。论文要解决的问题：如何更准确地找到并利用relevant context来生成response。<br>多轮对话中广泛使用的HRED模型,[<a href="https://arxiv.org/abs/1507.04808" target="_blank" rel="noopener">(Serban et al.,2016;</a>,<a href="https://arxiv.org/abs/1507.02221" target="_blank" rel="noopener">Sordoni et al., 2015</a>]无差别地利用context information，忽略了relevant context。虽然有利用relevant context的相关工作，但这些工作都有各自的问题。[<a href="https://www.aclweb.org/anthology/P17-2036" target="_blank" rel="noopener">Tian et al., 2017</a>]提出计算context 与post之间的cosine similarity来衡量context relevance，其假设是context与response之间的relevance等价于post与response之间的relevance，这个假设是站不住脚的。[<a href>Xing et al., 2018</a>]向HRED模型引入了attention机制，但attention机制定位relevant context时会产生偏差，因为基于RNN的attention机制倾向于最靠近的context（close context）。论文提出了自己的解决办法，用self-attention机制来衡量context于response之间的relevance。self-attention机制的优点是可以有效捕捉到长距离的依赖关系。</p><p>模型分为三个部分：<br>context包含N轮对话： ${s_1,s_2,…,s_N}$其中，$s_i = {x_1,x_2,…,x_M}$，M为句子长度。<br>response为$Y = {y_1,y_2,…,y_M}$</p><ol><li><strong>context representation encoder</strong>：<br> 将context encode为vector。<ol><li>word-level encoder：<br> 用LSTM对sentence编码，将LSTM最后一个时间步的hidden state作为sentence representation: $h^{s_i}$；<br> 由于self-attention机制不能区分word位置信息，还需要添加position embedding: $p^{s_i}$,<br> 把两个向量做concatenate操作，得到总得sentence representation:$(h^{s_i},p^{s_i})$。<br> 对于context中的N个句子有${(h^{s_1},p^{s_1}),…,(h^{s_N},p^{s_N})}$</li><li>context self-attention:<br> 采用multi-head self-attention机制，将${(h^{s_1},p^{s_1}),…,(h^{s_N},p^{s_N})}$经过不同的线性变换作为query、keys、values matrix,由N个sentence representation得到总的context representation $O_s$。</li></ol></li><li><strong>response representation encoder</strong><br> 同样用multi-head self-attention机制,将response的word embedding及position embedding ${(w_1,p_1),…,(w_{t-1},p_{t-1})}$经过不同的线性变换作为query、keys、values matrix，得到response representation $O_r$。<ol><li>在train阶段<br> 采用mask操作，在时间步t对于word $y_t$，mask掉${y_t,y_{t+1},…,y_M}$，只保留${y_1,y_2,…,y_{t-1}}$来计算response representation。</li><li>在infer阶段<br> 在生成response的时间步t，将生成的response ${g_1,…,g_{t-1}}$，来作为response representation。</li></ol></li><li><strong>context-response attention decoder</strong><br> 采用multi-head self-attention机制，将context attention representation $O_s$作为keys、values matrix，将response hidden representation $O_r$作为query matrix。得到输出$O_d$. <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/42.png" alt="模型框架图" title>                </div>                <div class="image-caption">模型框架图</div>            </figure></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录ACL2019对话系统相关的论文阅读笔记。包括任务型和闲聊式对话系统，对论文的思路和模型做简单介绍，值得反复精读的论文会单独开一篇博文来写。&lt;br&gt;ACL2019的会议列表链接：&lt;a href=&quot;http://www.acl2019.org/EN/program.xhtml&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.acl2019.org/EN/program.xhtml&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="论文" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="ACL2019" scheme="http://yoursite.com/tags/ACL2019/"/>
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
  </entry>
  
  <entry>
    <title>自然语言处理---会议列表</title>
    <link href="http://yoursite.com/2019/04/24/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-%E4%BC%9A%E8%AE%AE%E5%88%97%E8%A1%A8/"/>
    <id>http://yoursite.com/2019/04/24/自然语言处理-会议列表/</id>
    <published>2019-04-24T06:55:43.000Z</published>
    <updated>2019-07-07T09:00:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>记录自然语言处理方向的国际会议列表。</p><a id="more"></a><h2 id="A类会议"><a href="#A类会议" class="headerlink" title="A类会议"></a>A类会议</h2><p><a href="http://www.aaai.org/" target="_blank" rel="noopener">AAAI</a>，Association for the Advancement of Artificial Intelligence</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p><a href="https://iclr.cc/" target="_blank" rel="noopener">ICLR</a>，The International Conference on Learning Representations，国际学习表征会议<br>2013年才刚刚成立了第一届。这个一年一度的会议已经被学术研究者们广泛认可，被认为「深度学习的顶级会议」。<br>这个会议的来头不小，由位列深度学习三大巨头之二的 Yoshua Bengio 和 Yann LeCun 牵头创办。Yoshua Bengio 是蒙特利尔大学教授，深度学习三巨头之一，他领导蒙特利尔大学的人工智能实验室（MILA）进行 AI 技术的学术研究。MILA 是世界上最大的人工智能研究中心之一，与谷歌也有着密切的合作。而 Yann LeCun 就自不用提，同为深度学习三巨头之一的他现任 Facebook 人工智能研究院（FAIR）院长、纽约大学教授。作为卷积神经网络之父，他为深度学习的发展和创新作出了重要贡献。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://www.ccf.org.cn/xspj/gyml/" target="_blank" rel="noopener">中国计算机学会推荐国际学术会议和期刊目录</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录自然语言处理方向的国际会议列表。&lt;/p&gt;
    
    </summary>
    
      <category term="论文" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="会议列表" scheme="http://yoursite.com/tags/%E4%BC%9A%E8%AE%AE%E5%88%97%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>python读写csv文件</title>
    <link href="http://yoursite.com/2019/04/19/python%E8%AF%BB%E5%86%99csv%E6%96%87%E4%BB%B6/"/>
    <id>http://yoursite.com/2019/04/19/python读写csv文件/</id>
    <published>2019-04-19T10:32:22.000Z</published>
    <updated>2019-07-21T15:22:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>介绍csv文件的读写。</p><a id="more"></a><h2 id="csv模块"><a href="#csv模块" class="headerlink" title="csv模块"></a>csv模块</h2><h3 id="csv-writer-csvfile"><a href="#csv-writer-csvfile" class="headerlink" title="csv.writer(csvfile)"></a>csv.writer(csvfile)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import csv </span><br><span class="line">row = [&apos;Symbol&apos;,&apos;Price&apos;,&apos;Date&apos;,&apos;Time&apos;,&apos;Change&apos;,&apos;Volume&apos;]</span><br><span class="line">rows = [(&apos;AA&apos;, 39.48, &apos;6/11/2007&apos;, &apos;9:36am&apos;, -0.18, 181800),</span><br><span class="line">         (&apos;AIG&apos;, 71.38, &apos;6/11/2007&apos;, &apos;9:36am&apos;, -0.15, 195500),</span><br><span class="line">         (&apos;AXP&apos;, 62.58, &apos;6/11/2007&apos;, &apos;9:36am&apos;, -0.46, 935000),</span><br><span class="line">       ]</span><br><span class="line">with open(&apos;name.csv&apos;,&apos;w&apos;) as csvfile:</span><br><span class="line">    writer = csv.writer(csvfile,delimiter = &apos;\t&apos;,lineterminator = &apos;\n&apos;) #delimiter和lineterminator分别是分隔符，行结束符</span><br><span class="line">    writer.writerow(row) #写入单行</span><br><span class="line">    writer.writerows(rows) #写入多行</span><br></pre></td></tr></table></figure><h3 id="csv-reader-csvfile"><a href="#csv-reader-csvfile" class="headerlink" title="csv.reader(csvfile)"></a>csv.reader(csvfile)</h3><p>该函数接收一个可迭代对象，返回对象<code>reader</code>是一个生成器，不能直接用下标访问。可以用for循环和next()函数访问。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with open(&apos;name.csv&apos;,&apos;r&apos;) as csvfile:</span><br><span class="line">    reader = csv.reader(csvfile,delimiter = &apos;\t&apos;) #迭代器</span><br><span class="line">    rows = [row for row in reader] #用for循环访问：</span><br><span class="line">for row in rows:</span><br><span class="line">    print(row)</span><br></pre></td></tr></table></figure><p>输出结果为：<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/36.png" alt title>                </div>                <div class="image-caption"></div>            </figure>如果要读取csv文件的某列，可以看下面的例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">with open(&apos;name.csv&apos;,&apos;r&apos;) as csvfile:</span><br><span class="line">    reader = csv.reader(csvfile,delimiter = &apos;\t&apos;) #迭代器</span><br><span class="line">    column = [row[2] for row in reader] #用for循环访问：</span><br><span class="line">print(column)</span><br></pre></td></tr></table></figure><p>输出结果为：<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/37.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h3 id="csv-DictReader-csvfile"><a href="#csv-DictReader-csvfile" class="headerlink" title="csv.DictReader(csvfile)"></a>csv.DictReader(csvfile)</h3><p>与csv.reader()函数相同，接收一个可迭代对象，返回一个生成器。不同之处是，返回的每个单元格放在字典的值中，字典的键就是这个单元格的列头。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with open(&apos;./name.csv&apos;,&apos;r&apos;) as f:</span><br><span class="line">    reader = csv.DictReader(f,delimiter = &apos;\t&apos;)</span><br><span class="line">    rows = [row for row in reader]</span><br><span class="line">for row in rows:</span><br><span class="line">    print(rows)</span><br></pre></td></tr></table></figure><p>输出结果为：<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/38.png" alt title>                </div>                <div class="image-caption"></div>            </figure>如果要读取csv文件的某列，可以看下面的例子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">with open(&apos;./name.csv&apos;,&apos;r&apos;) as f:</span><br><span class="line">    reader = csv.DictReader(f,delimiter = &apos;\t&apos;)</span><br><span class="line">    column = [row[&apos;Time&apos;] for row in reader]</span><br><span class="line">print(column)</span><br></pre></td></tr></table></figure><p>输出结果为：<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/39.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h3 id="csv-DictWriter-csvfile"><a href="#csv-DictWriter-csvfile" class="headerlink" title="csv.DictWriter(csvfile)"></a>csv.DictWriter(csvfile)</h3><h2 id="pandas读写csv"><a href="#pandas读写csv" class="headerlink" title="pandas读写csv"></a>pandas读写csv</h2><p>也可以直接用pandas的函数<code>read_csv()</code>来读取csv文件的列。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">f = pd.read_csv(&apos;name.csv&apos;,delimiter = &apos;\t&apos;)</span><br><span class="line">time = f.Time</span><br><span class="line">print(time)</span><br></pre></td></tr></table></figure><p>输出结果为：<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/40.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://docs.python.org/zh-cn/3/library/csv.html" target="_blank" rel="noopener">python官方文档-csv模块</a></li><li><a href="https://python3-cookbook.readthedocs.io/zh_CN/latest/c06/p01_read_write_csv_data.html" target="_blank" rel="noopener">读写csv数据</a></li><li><a href="https://blog.csdn.net/Allyli0022/article/details/79125672" target="_blank" rel="noopener">使用python获取csv文本的某行或某列数据</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍csv文件的读写。&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="csv" scheme="http://yoursite.com/tags/csv/"/>
    
      <category term="panda" scheme="http://yoursite.com/tags/panda/"/>
    
  </entry>
  
  <entry>
    <title>torch.cuda.is_available()返回False,但nvidia-smi正常</title>
    <link href="http://yoursite.com/2019/04/16/torch-cuda-is-available-%E8%BF%94%E5%9B%9EFalse-%E4%BD%86nvidia-smi%E6%AD%A3%E5%B8%B8/"/>
    <id>http://yoursite.com/2019/04/16/torch-cuda-is-available-返回False-但nvidia-smi正常/</id>
    <published>2019-04-16T09:04:44.000Z</published>
    <updated>2019-07-22T01:27:54.000Z</updated>
    
    <content type="html"><![CDATA[<p><code>torch.cuda.is_available()</code>返回False,但nvidia-smi可以正常运行。</p><a id="more"></a><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>在pytorch用GPU来加速计算时发现。<code>torch.cuda.is_available()</code>返回False,但nvidia-smi可以正常运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; torch.cuda.is_available()</span><br><span class="line">False</span><br></pre></td></tr></table></figure><p>此时，<code>nvidia-smi</code>可以正常运行。<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/34.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="可能原因"><a href="#可能原因" class="headerlink" title="可能原因"></a>可能原因</h2><p>在<code>nvidia-smi</code>的运行结果中可以看到，driver version是<code>390.xx</code>。可能是driver version版本太低，造成了这个问题，实际上也是如此。<br>driver version的常见版本是<code>384.xx</code>,<code>390.xx</code>,<code>396.xx</code>。接下来，把driver version升级到<code>396.xx</code>看能不能解决问题。</p><h2 id="升级nvidia-driver-version"><a href="#升级nvidia-driver-version" class="headerlink" title="升级nvidia driver version"></a>升级nvidia driver version</h2><ol><li><p>卸载旧版本的NVIDIA driver </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove --purge nvidia-\*</span><br></pre></td></tr></table></figure></li><li><p>添加NVIDIA的ppa源.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</span><br></pre></td></tr></table></figure></li><li><p>安装新版本的NVIDIA driver </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install nvidia-driver-396</span><br></pre></td></tr></table></figure></li></ol><p>此时，运行<code>nvidia-smi</code>，会报以下错误。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failed to initialize NVML: Driver/library version mismatch</span><br></pre></td></tr></table></figure><p>这是更新NVIDIA driver版本后的常见问题。这个问题出现的原因是kernel mod的NVIDIA driver版本没有更新。<br>执行以下命令可以查看nvidia kernel mod的version。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/driver/nvidia/version</span><br></pre></td></tr></table></figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/32.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>可以看到已经加载的nvidia kernel mod的版本是还是旧版本<code>390.xx</code>。一般情况下，重启服务器就能解决问题。<br>如果由于某些原因不能重启，可以重新加载kernel mod。思路是先unload kernel mod，再reload kernel mod. 详见<a href="https://comzyh.com/blog/archives/967/" target="_blank" rel="noopener">解决Driver/library version mismatch</a><br><code>nvidia-smi</code>可以正常运行后，问题就解决了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; torch.cuda.is_available()</span><br><span class="line">True</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://discuss.pytorch.org/t/torch-cuda-is-available-returns-false-nvidia-smi-is-working/20614" target="_blank" rel="noopener">Torch.cuda.is_available() returns False, nvidia-smi is working</a></li><li><a href="https://askubuntu.com/questions/1063871/how-can-i-update-the-nvidia-drivers-to-version-390-77" target="_blank" rel="noopener">How can I update the NVIDIA drivers to version 390.77?</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;torch.cuda.is_available()&lt;/code&gt;返回False,但nvidia-smi可以正常运行。&lt;/p&gt;
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="nvidia-smi" scheme="http://yoursite.com/tags/nvidia-smi/"/>
    
      <category term="GPU" scheme="http://yoursite.com/tags/GPU/"/>
    
      <category term="cuda" scheme="http://yoursite.com/tags/cuda/"/>
    
  </entry>
  
  <entry>
    <title>nvidia-smi返回错误信息‘Failed to initialize NVML: Driver/library version mismatch’</title>
    <link href="http://yoursite.com/2019/03/29/nvidia-smi%E8%BF%94%E5%9B%9E%E9%94%99%E8%AF%AF%E4%BF%A1%E6%81%AF%E2%80%98Failed-to-initialize-NVML-Driver-library-version-mismatch%E2%80%99/"/>
    <id>http://yoursite.com/2019/03/29/nvidia-smi返回错误信息‘Failed-to-initialize-NVML-Driver-library-version-mismatch’/</id>
    <published>2019-03-29T11:47:03.000Z</published>
    <updated>2019-07-21T15:23:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>Ubuntu运行命令<code>nvidia-smi</code>出错。</p><a id="more"></a> <h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>在Ubuntu18.04的命令行中运行命令<code>nvidia-smi</code>，返回错误信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failed to initialize NVML: Driver/library version mismatch</span><br></pre></td></tr></table></figure><h2 id="方法1：重启解决大部分问题"><a href="#方法1：重启解决大部分问题" class="headerlink" title="方法1：重启解决大部分问题"></a>方法1：重启解决大部分问题</h2><p>博客<a href="https://comzyh.com/blog/archives/967/" target="_blank" rel="noopener">解决Driver/library version mismatch</a>讲述的很清楚，这里就不再赘述。<br>或者参考大型交友网站stack overflow的问题<a href="https://stackoverflow.com/questions/43022843/nvidia-nvml-driver-library-version-mismatch/45319156" target="_blank" rel="noopener">NVIDIA NVML Driver/library version mismatch</a></p><h2 id="方法2：重装驱动"><a href="#方法2：重装驱动" class="headerlink" title="方法2：重装驱动"></a>方法2：重装驱动</h2><p>看返回的错误信息，这个问题出现的原因是NVIDIA Driver的版本不匹配。如果重启不能解决问题，我们需要卸载重装NVIDIA driver。</p><ol><li><strong>查看驱动程序版本</strong></li></ol><ul><li><code>dpkg -l | grep nvidia</code> <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/31.png" alt title>                </div>                <div class="image-caption"></div>            </figure>可以看到驱动版本是<code>390.116</code></li><li><code>cat /proc/driver/nvidia/version</code> <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/32.png" alt title>                </div>                <div class="image-caption"></div>            </figure>这里NVRM的版本是<code>390.87</code>。错误信息就是这两个版本不匹配造成的。接下来先卸载NVIDIA driver，再重新安装。</li></ul><ol start="2"><li><p><strong>卸载旧版本的NVIDIA driver</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove --purge nvidia-\*</span><br></pre></td></tr></table></figure></li><li><p><strong>添加NVIDIA的ppa源</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</span><br></pre></td></tr></table></figure></li><li><p><strong>重新安装NVIDIA的驱动</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install nvidia-390</span><br></pre></td></tr></table></figure><p> 用你自己的版本号替换<code>390</code>。</p></li></ol><p>这时再用<code>cat /proc/driver/nvidia/version</code>查看NVIDIA driver的驱动。<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/33.png" alt title>                </div>                <div class="image-caption"></div>            </figure> 可以看到NVRM的版本是<code>390.116</code>，这时版本就匹配了。<br>再次执行<code>nvidia-smi</code>,终于看到<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/34.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p>在<a href="https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa" target="_blank" rel="noopener">nvidia driver各版本总览</a>可以看到NVIDIA driver的各个版本。</p><h2 id="额外的：update-与-upgrade"><a href="#额外的：update-与-upgrade" class="headerlink" title="额外的：update 与 upgrade"></a>额外的：update 与 upgrade</h2><p>记录下<code>sudo apt-get update</code>与<code>sudo apt-get upgrade</code>的区别。<br>在windows系统中安装软件，只需要有exe文件，双击即可安装了。Linux系统中则不同，Linux会维护一个自己的软件仓库，几乎所有软件都在这个仓库里，而且里面的软件完全安全，绝对可以安装。<br>我们自己的Ubuntu服务器上，维护一个软件源列表文件<code>/etc/apt/sources.list</code>,里面都是一些网址信息，每个网址就是一个软件源，这个地址指向的数据标识着有哪些软件可以安装使用。</p><ol><li><p>查看源列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/apt/sources.list</span><br></pre></td></tr></table></figure></li><li><p>更新软件列表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure><p> 这个命令对访问源列表里的每个网址，读取软件列表，保存到本地电脑。</p></li><li><p>更新软件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get upgrade</span><br></pre></td></tr></table></figure><p> 这个命令会把本地已安装的软件，与软件列表里对应软件做对比，如果有可更新版本就更新软件。<br>总的来说，<code>sudo apt-get update</code>是更新软件列表，<code>sudo apt-get upgrade</code>是更新软件。</p></li></ol><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://comzyh.com/blog/archives/967/" target="_blank" rel="noopener">解决Driver/library version mismatch</a></li><li><a href="https://www.cnblogs.com/yizhichun/p/6397168.html" target="_blank" rel="noopener">Ubuntu配置GPU+CUDA+CAFFE</a></li><li><a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---Tensorflow-gpu%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85.html" target="_blank" rel="noopener">ubuntu下安装安装CUDA、cuDNN和tensotflow-gpu版本流程和问题总结</a></li><li><a href="https://wiki.ubuntu.org.cn/NVIDIA#PPA.E6.BA.90" target="_blank" rel="noopener">NVIDIA的wiki</a></li><li><a href="https://www.cnblogs.com/darkknightzh/p/5638185.html" target="_blank" rel="noopener">（原）Ubuntu16中安装nvidia的显卡驱动</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Ubuntu运行命令&lt;code&gt;nvidia-smi&lt;/code&gt;出错。&lt;/p&gt;
    
    </summary>
    
      <category term="技术资料" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E8%B5%84%E6%96%99/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
      <category term="ubuntu" scheme="http://yoursite.com/tags/ubuntu/"/>
    
      <category term="nvidia-smi" scheme="http://yoursite.com/tags/nvidia-smi/"/>
    
  </entry>
  
  <entry>
    <title>条件随机场CRF</title>
    <link href="http://yoursite.com/2019/03/23/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF/"/>
    <id>http://yoursite.com/2019/03/23/条件随机场CRF/</id>
    <published>2019-03-23T05:50:20.000Z</published>
    <updated>2019-07-22T01:26:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近学习了条件随机场CRF，做下总结。主要参考<a href="https://createmomo.github.io/2017/09/12/CRF_Layer_on_the_Top_of_BiLSTM_1/" target="_blank" rel="noopener">BiLSTM+CRF模型中的CRF层</a>为主线，结合李航老师的《统计机器学习》，记录自己对CRF的理解。</p><a id="more"></a> <h2 id="从马尔科夫随机场到线性链条件随机场"><a href="#从马尔科夫随机场到线性链条件随机场" class="headerlink" title="从马尔科夫随机场到线性链条件随机场"></a>从马尔科夫随机场到线性链条件随机场</h2><ol><li><p><strong>概率图模型</strong><br> 概率图模型是用图G = (V,E)来表示概率分布。设有联合概率分布P(Y)，Y是一组随机变量。我们可以用无向图G = (V,E)来表示联合概率分布P(Y),节点$v \in V$表示随机变量$Y_v$，边$e \in E$表示随机变量之间的概率依赖关系。</p></li><li><p><strong>概率无向图模型，即马尔科夫随机场</strong><br> 设有联合概率分布P(Y),由无向图G=(V,E)表示。如果概率分布P(Y)满足<code>成对、局部、全局马尔科夫性</code>，那么称 这个联合概率分布p(Y)为概率无向图模型，或马尔科夫随机场(Markov random field)。</p><p> 成对马尔科夫性、局部马尔可夫性、全部马尔科夫性要表达的就是：在无向图中，没有边连接的节点之间没有概率依赖关系，也就是没有边连接的节点代表的随机变量之间是条件独立的。</p></li><li><p><strong>条件随机场</strong><br> 设X和Y是随机变量，P(Y|X)是给定X的条件下Y的条件概率分布。若给定X的条件下，Y构成一个马尔科夫随机场。则称条件概率分布P(Y|X)为条件随机场。<br> 我们可以看到，马尔科夫随机场是联合概率分布P(Y),而条件随机场是条件概率分布P(Y|X)。这是一点不同。</p></li><li><p><strong>线性链条件随机场</strong><br> 设$X =(X_1,X_2,…,X_n), Y =(Y_1,Y_2,…,Y_n)$是线性链表示的随机变量序列。若在给定随机变量序列X的条件下，随机变量序列Y的条件概率分布P(Y|X)构成条件随机场，即满足马尔可夫性：$$P(Y_i|X,Y_1,Y_2,…,Y_{i-1},Y_{i+1},…,Y_n) = P(Y_i|X,Y_{i-1},Y_{i+1})$$ 。则称条件概率分布p(Y|X)为线性链条件随机场。<br> <img src="/images/21.png" alt><br> 线性链条件随机场和隐马尔可夫模型都是序列模型，可以用于标注问题。这时，条件概率模型P(Y|X)中，X是输入变量序列，表示需要标注的观测序列；Y是输出变量，表示标记序列，或称状态序列。</p></li></ol><h2 id="BiLSTM-CRF模型"><a href="#BiLSTM-CRF模型" class="headerlink" title="BiLSTM+CRF模型"></a>BiLSTM+CRF模型</h2><p>BiLSTM+CRF模型是命名实体识别任务的常用模型。<br>假设我们训练集中有个由五个词组成的句子$X = (w_0,w_1,w_2,w_3,w_4)$,对应标签为$Y = [B-Person，I-Person,O,B-Organization,O]$。数据集中有五类标签： </p><table><thead><tr><th>类别</th><th align="center">B-Person</th><th align="center">I-Person</th><th align="center">B-Organization</th><th align="center">I-Organization</th><th align="center">O</th></tr></thead><tbody><tr><td>含义</td><td align="center">人名的开始部分</td><td align="center">人名的中间部分</td><td align="center">组织机构的开始部分</td><td align="center">组织机构的中间部分</td><td align="center">非实体信息</td></tr></tbody></table><p>先简单介绍下BiLSTM+CRF模型的结构。LSTM层的输入一般为每个词的Word-embedding，输出为每个词word在类别空间tag_space上的非归一化概率，也就是在单词对应每个类别的得分score。这些score作为CRF层的输入。<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/22.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="CRF的损失函数"><a href="#CRF的损失函数" class="headerlink" title="CRF的损失函数"></a>CRF的损失函数</h2><p>条件随机场中有两个重要的矩阵，转移概率矩阵和状态概率矩阵，分别对应转移特征和状态特征。</p><ul><li>状态概率矩阵。就是LSTM层的输出，作为CRF层的输入。矩阵的形状为[N,M],N为句子长度，M为可能状态数。</li><li>转移概率矩阵。矩阵形状为[M,M]，M为可能状态数。转移矩阵是模型参数，是随机初始化的，在训练过程中不断更新优化。</li></ul><p>给定转移矩阵T，随机变量序列X取值为x的条件下，随机变量序列取值为y的似然函数为：$$Likelihood(y|x,T) = \frac{ \sum_{i=0}^{n} P(x_i|y_i)T(y_i|y_{i-1})}{\sum_{y^<em>}\biggl(\sum_{i=0}^{n}P(x_i|y_i^</em>)T(y_i^<em>|y_{i-1}^</em>)\biggr)}  \cdots\cdots\cdots\cdots\cdots  (1)$$<br>上式中,</p><ul><li>$P(x_i|y_i)$表示当前状态为$y_i$时，产生观测值$x_i$的概率。对应状态分数。</li><li>$T(y_i|y_{i-1})$表示从上一个状态$y_{i-1}$转换到当前状态$y_i$的概率。对应转移分数。我们可以从转移矩阵中读出这个概率。</li><li>分子表示了单条路径y=[y_0,y_1,…,y_n]的分数score或概率。</li><li>分母表示了所有可能路径$y^*$的总分。注意计算分母时，我们要计算所有可能路径并求和。若序列长度为N,状态可能数为M,则所有可能路径数为$M^N$,这个数量是指数级的，非常大。我们的秘密武器是<code>前向后向算法</code>来高效地计算分母。</li></ul><p>进一步地，负对数似然函数为：<br>$$NegLogLikelihood(y|x,T) = \sum_{y^<em>}\biggl( \sum_{i=0}^{n} log(P(x_i|y_i^</em>)T(y^<em>_i|y^</em><em>{i-1}))\biggr) - \sum</em>{i=0}^{n}log(P(x_i|y_i)T(y_i|y_{i-1})) \cdots\cdots\cdots\cdots (2)$$</p><p>从式子(1)到式子(2)，直接对式子(1)取负对数是得到式子(2)可能比较令人费解。<br>需要留意的是：转移概率矩阵和状态概率矩阵中的概率都是对数概率（这很重要），这样计算路径概率时都是加法。对对数概率加上exp()运算我们能得到正常概率。<br>《统计学习方法》书中说，线性链条件随机场是对数线性模型，在对数空间中，对数概率可以直接相加，带来很大的方便。接下来，我们来看看：真实路径的分数和所有路径的总分是怎么计算的？</p><h3 id="真实路径分数"><a href="#真实路径分数" class="headerlink" title="真实路径分数"></a>真实路径分数</h3><p>数据集中有五类标签，再引入start和end作为序列开始和结束标志。</p><table><thead><tr><th>类别</th><th align="center">B-Person</th><th align="center">I-Person</th><th align="center">B-Organization</th><th align="center">I-Organization</th><th align="center">O</th><th align="center">start</th><th align="center">end</th></tr></thead><tbody><tr><td>索引</td><td align="center">0</td><td align="center">1</td><td align="center">2</td><td align="center">3</td><td align="center">4</td><td align="center">5</td><td align="center">6</td></tr></tbody></table><p>长度为5的序列，$X = (w_0,w_1,w_2,w_3,w_4)$,<br>对应类别为$Y = [B-Person，I-Person,O,B-Organization,O]$，<br>标注序列，也就是真实路径为为y = [0,1,4,3,4]。<br>真实路径的分数由两部分组成，状态分数和转移分数。状态矩阵就是LSTM层的输出。转移矩阵是模型参数，为$$[t_{ij}],i,j\in [0,6];i\neq 6,j\neq 5$$其中$t_ij$表示从上一状态转换到当前状态的概率。转移时，不能转移到start，不能从end转移。<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/23.png" alt title>                </div>                <div class="image-caption"></div>            </figure>则真实路径的分数 = 转移分数 + 状态分数 = $1.5+0.4+0.1+0.2+0.5+t_{51}+t_{01}+t_{14}+t_{42}+t_{24}+t_{46}$</p><h3 id="所有路径分数-前向后向算法"><a href="#所有路径分数-前向后向算法" class="headerlink" title="所有路径分数-前向后向算法"></a>所有路径分数-前向后向算法</h3><p>计算所有路径的总分面对的难题是要不要穷举所有路径。对于一个长度为N的序列，可能状态数为M，所有可能路径数为$M^N$，这是一个指数级的计算量。计算每条路径分数的计算量是$O(N)$,直接用穷举法计算所有路径总分的计算量是$O(N\cdot M^N)$。这个计算量是无法接受的。<br>《统计学习方法》p176写，前向算法是基于“路径结构”递推计算所有路径分数。前向算法高效的关键是局部计算前向概率，再递推到全局。前向算法的计算量是$O(N\cdot M^2)$，前向算法减少计算量的原因是：每一次递推计算直接利用了前一个时刻的计算结果，避免了重复计算。</p><p>对于$w_0 \to w_1$的局部路径。<br>先计算$w_0$所有状态到$w_1$单个状态0的分数之和，并更新$w_1$的状态0的状态分数。有M条局部路径，计算量是$O(M)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/24.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>用同样的方法更新$w_1$所有状态的状态分数，这就是所有局部路径的分数。要计算M个状态，计算量是$O(M^2)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/25.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>依次递推到全局。序列长度为N,总的计算量是$O(N \cdot M^2)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/26.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>从图的角度解释了前向算法，我们再从数学计算的角度来看前向算法。简化一下问题，假设句子长度为3，$X = [w_0,w_1,w_2]$,只有2个类别[1,2]<br>我们引入两个变量<code>previous</code>和<code>obs</code>。<code>previous</code>存储前一时刻的计算结果，<code>obs</code>存储当前状态分数。<br>对于$w_0$:$$obs = [x_{01},x_{02}];previous = none$$<br>对于$w_0 \to w_1:$,$$previous = [x_{01},x_{02}],obs = [x_{11},x_{12}]$$<br>先扩展<code>previous</code>和<code>obs</code>：$$previous = \begin{pmatrix} x_{01}&amp;x_{01}\x_{02}&amp;x_{02} \end{pmatrix} \quad$$$$obs = \begin{pmatrix} x_{11}&amp;x_{12}\x_{11}&amp;x_{12} \end{pmatrix} \quad$$将<code>previous</code>和<code>obs</code>和转移矩阵相加：$$score =\begin{pmatrix} x_{01}&amp;x_{01}\x_{02}&amp;x_{02} \end{pmatrix} +\begin{pmatrix} x_{11}&amp;x_{12}\x_{11}&amp;x_{12} \end{pmatrix}+\begin{pmatrix} t_{11}&amp;t_{12}\t_{21}&amp;t_{22} \end{pmatrix}$$$$  = \begin{pmatrix} x_{01}+x_{11}+t_{11}&amp;x_{01}+x_{12}+t_{12}\x_{02}+x_{11}+t_{21}&amp;x_{02}+x_{12}+t_{22} \end{pmatrix}$$<br>score同列相加，更新<code>previous</code>:$$previous = [x_{01}+x_{11}+t_{11}+x_{02}+x_{11}+t_{21},x_{01}+x_{12}+t_{12}+x_{02}+x_{12}+t_{22}]$$<br>这样第二次迭代就完成了。用图来表示到目前为止的计算：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/27.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>用同样的方法迭代递推，就可以得到所有路径的分数。</p><p>这样我们就计算出了负对数似然函数，也就是CRF模型的损失函数。<br>条件随机场的第二个基本问题是学习问题，给定训练集估计条件随机场的模型参数（转移矩阵）。我们可以通过最小化对数似然函数来求参数模型。可以用梯度下降法来实现。</p><h2 id="维特比算法解码"><a href="#维特比算法解码" class="headerlink" title="维特比算法解码"></a>维特比算法解码</h2><p>条件随机场的第三个基本问题是预测问题，给出条件随机场的模型 和 输入序列x，求条件概率最大输出序列$y^*$。 也就是找出所有路径中得分最高的那条路径作为标注路径。与计算所有路径总分一样，我们面对的难题是要不要求出所有路径的分数。当然是不用的，我们用维特比算法来解码。<br>通信专业的同学一定知道大名鼎鼎的维特比算法，卷积码的译码就是用的维特比算法。<br>对于 $w_0 \to w_1$:<br>先计算$w_0$到$w_1$的状态1五条路径的分数，找出分数最大的一条保留下来，其他全都丢弃掉。计算量为$O(M)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/28.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>同样的找出$w_1$每个状态分数最大的一条路径，要计算$w_1$的5个状态，计算量为$O(M^2)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/29.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>依次递推到全局。序列长度为N,计算量为$O(N \cdot M^2)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/30.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>比较下前向算法与维特比算法的异同：<br>相同的地方在他们都面临要不要计算所有路径分数的问题，都是基于路径结构，用局部递推到全局。<br>不同的地方在于前向算法在更新previous的单个状态时是做求和sum运算，而维特比算法是做max运算，只保留分数最大的，丢弃掉其他路径。此外，维特比算法找到分数最大的路径后，还要反向递推</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://createmomo.github.io/2017/09/12/CRF_Layer_on_the_Top_of_BiLSTM_1/" target="_blank" rel="noopener">CRF Layer on the Top of BiLSTM</a></li><li><a href="https://zhuanlan.zhihu.com/p/44042528" target="_blank" rel="noopener">最通俗易懂的BiLSTM-CRF模型中的CRF层介绍</a></li><li><a href="https://mp.weixin.qq.com/s/1KAbFAWC3jgJTE-zp5Qu6g" target="_blank" rel="noopener">如何直观地理解条件随机场，并通过PyTorch简单地实现</a></li><li><a href="http://www.cnblogs.com/pinard/p/7048333.html" target="_blank" rel="noopener">条件随机场CRF—刘建平</a></li><li>《统计学习方法》—李航</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近学习了条件随机场CRF，做下总结。主要参考&lt;a href=&quot;https://createmomo.github.io/2017/09/12/CRF_Layer_on_the_Top_of_BiLSTM_1/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;BiLSTM+CRF模型中的CRF层&lt;/a&gt;为主线，结合李航老师的《统计机器学习》，记录自己对CRF的理解。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="条件随机场" scheme="http://yoursite.com/tags/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"/>
    
      <category term="前向后向算法" scheme="http://yoursite.com/tags/%E5%89%8D%E5%90%91%E5%90%8E%E5%90%91%E7%AE%97%E6%B3%95/"/>
    
      <category term="维特比算法" scheme="http://yoursite.com/tags/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>pytorch实现基于LSTM的循环神经网络</title>
    <link href="http://yoursite.com/2019/03/20/pytorch%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2019/03/20/pytorch实现基于LSTM的循环神经网络/</id>
    <published>2019-03-20T14:41:10.000Z</published>
    <updated>2019-07-22T01:01:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>用pytorch实现基于LSTM的循环神经网络。</p><a id="more"></a> <h2 id="涉及函数详解"><a href="#涉及函数详解" class="headerlink" title="涉及函数详解"></a>涉及函数详解</h2><h3 id="class-torch-nn-LSTM-args-kwargs"><a href="#class-torch-nn-LSTM-args-kwargs" class="headerlink" title="class torch.nn.LSTM(args,*kwargs)"></a>class torch.nn.LSTM(args,*kwargs)</h3><ul><li><p>参数说明：</p><ul><li>input_size: 输入的特征维度</li><li>output_size: 输出的特征维度</li><li>num_layers: 层数（注意与时序展开区分）</li><li>bidirectional: 如果为<code>True</code>，为双向LSTM。默认为<code>False</code></li></ul></li><li><p>LSTM的输入：input,$(h_0,c_0)$</p><ul><li>input(seq_len,batch,input_size): 包含输入特征的<code>tensor</code>,注意输入是<code>tensor</code>。</li><li>$h_0$(num_layers $\cdot$ num_directions,batch,hidden_size): 保存初始化隐藏层状态的<code>tensor</code></li><li>$c_0$(num_layers $\cdot$ num_directions,batch,hidden_size): 保存初始化细胞状态的<code>tensor</code></li></ul></li><li><p>LSTM的输出： output,$(h_n,c_n)$</p><ul><li>output(seq_len, batch, hidden_size * num_directions): 保存<code>RNN</code>最后一层输出的<code>tensor</code></li><li>$h_n$(num_layers * num_directions,batch,hidden_size): 保存<code>RNN</code>最后一个时间步隐藏状态的<code>tensor</code></li><li>$c_n$(num_layers * num_directions,batch,hidden_size): 保存<code>RNN</code>最后一个时间步细胞状态的<code>tensor</code></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import torch.nn </span><br><span class="line">import torch</span><br><span class="line">lstm = nn.LSTM(embedding_dim,hidden_dim) #实例化一个LSTM单元，该单元输入维度embedding_dim,输出维度为hidden_dim</span><br><span class="line">input = Variable(torch.randn(seq_len,1,embedding_dim)) # 输入input应该是三维的，第一维度是seq-length,也就是多个词构成的一句话；第二维度为1，不用管；第三个维度是一个词的词嵌入维度，即embedding_dim</span><br><span class="line">h0 = Variable(torch.randn(1,1,hidden_dim)) </span><br><span class="line">c0 = Variable(torch.randn(1,1,hidden_dim))</span><br><span class="line">lstm_out,hidden = lstm(input,(h0,c0))</span><br></pre></td></tr></table></figure><h3 id="class-torch-nn-Linear"><a href="#class-torch-nn-Linear" class="headerlink" title="class torch.nn.Linear()"></a>class torch.nn.Linear()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class torch.nn.Linear(in_features,out_features,bias = True)</span><br></pre></td></tr></table></figure><ul><li>作用：对输入数据做线性变换。$y = Ax+b$</li><li>参数：<ul><li>in_features：每个输入样本的大小</li><li>out_features: 每个输出样本的大小</li><li>bias: 默认值为True。是否学习偏置。</li></ul></li><li>形状：<ul><li>输入： (N,in_features)</li><li>输出： (N,out_features)</li></ul></li><li>变量：<ul><li>weights: 可学习的权重，形状为(in_features,out_features)</li><li>bias: 可学习的偏置，形状为(out_features)</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">m = nn.Linear(20,30)</span><br><span class="line">input = torch.randn(128,20)</span><br><span class="line">output = m(input)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure><h2 id="先看个小例子"><a href="#先看个小例子" class="headerlink" title="先看个小例子"></a>先看个小例子</h2><p>用pytorch实现LSTM，先实例化一个LSTM单元，再给出tensor类型的输入数据inputs及初始隐藏状态hidden = $(h_0,c_0)$。值得注意的是，LSTM单元的输入inputs必须是三维的，第一维是seq-length，即一句话，元素是词。第二维是mini-batch,从来不用，设为1即可。第三维是embedding-size,即一个词向量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">import torch.nn as nn </span><br><span class="line"></span><br><span class="line">lstm = nn.LSTM(4,3) #实例化一个LSTM单元，单元输入维度是4，输出维度是3</span><br><span class="line">inputs = [torch.randn(1,5) for _ in range(5)] #产生输入inputs。为tensor序列。</span><br><span class="line">hidden = (torch.randn(1,1,3),torch.randn(1,1,3)) #初始化隐藏状态</span><br></pre></td></tr></table></figure><p>做好三步准备：实例化一个LSTM单元，准备好inputs，初始化隐藏状态hidden。我们就可以计算LSTM单元的输出了。<br>我们有两种选择，将序列一个元素一个元素地送入LSTM单元，或是将整个序列一下子全送入LSTM单元。先看看第一种：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for x in inputs:</span><br><span class="line">    lstm_out,hidden = lstm(x.view(1,1,-1),hidden) #x.view(1,1,-1)将tensor整形为三维。前面说过LSTM单元的输入必须是三维的。</span><br><span class="line">print(lstm_out,hidden)</span><br></pre></td></tr></table></figure><p>接下来，将整个序列送入LSTM单元：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.cat(inputs).view(len(inputs),1,-1) #将整个序列连接为tensor，并整形为三维。</span><br><span class="line">hidden = (torch.randn(1,1,3),torch.randn(1,1,3)) #清楚隐藏状态</span><br><span class="line">lstm_out,hidden = lstm(inputs,hidden)</span><br><span class="line">print(lstm_out,hidden)</span><br></pre></td></tr></table></figure><p>我们可以看到：</p><ul><li>lstm_out 中包含了序列所有的隐藏状态。</li><li>hidden 中包含了最后一个时间步的隐藏状态和细胞状态。可以作为下个时间步LSTM单元的输入参数，继续输入序列或反向传播。</li></ul><h2 id="用lstm做词性标注"><a href="#用lstm做词性标注" class="headerlink" title="用lstm做词性标注"></a>用lstm做词性标注</h2><p>先准备训练数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">train_data = [</span><br><span class="line">    (&quot;The dog ate the apple&quot;.split(), [&quot;DET&quot;, &quot;NN&quot;, &quot;V&quot;, &quot;DET&quot;, &quot;NN&quot;]),</span><br><span class="line">    (&quot;Everybody read that book&quot;.split(), [&quot;NN&quot;, &quot;V&quot;, &quot;DET&quot;, &quot;NN&quot;])</span><br><span class="line">]</span><br><span class="line"># 词汇表字典</span><br><span class="line">word_to_ix = &#123;&#125;</span><br><span class="line">for sent,tags in train_data:</span><br><span class="line">    for word in sent:</span><br><span class="line">        if word not in word_to_ix:</span><br><span class="line">            word_to_ix[word] = len(word_to_ix)</span><br><span class="line"># 标签集字典</span><br><span class="line">tag_to_ix = &#123;&quot;DET&quot;: 0, &quot;NN&quot;: 1, &quot;V&quot;: 2&#125;</span><br><span class="line"></span><br><span class="line">EMBEDDING_DIM = 6</span><br><span class="line">HIDDEN_DIM = 6</span><br></pre></td></tr></table></figure><p>构建LSTM模型:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">class LSTMtagger(nn.Module):</span><br><span class="line">    def __init__(self,embedding_dim,hidden_dim,vocab_size,tagset_size):</span><br><span class="line">        super(LSTMtagger,self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.word_embeddings = nn.Embedding(vocab_size,embedding_dim) #随机初始化词向量表，是神经网络的参数</span><br><span class="line">        self.lstm = nn.LSTM(embedding_dim,hidden_dim) #实例化一个LSTM单元，单元输入维度是embedding_dim，输出维度是hidden_dim</span><br><span class="line">        self.hidden2tag = torch.Linear(hidden_dim,tagset_size) #线性层从隐藏状态空间映射到标签空间</span><br><span class="line">    def forward(self,sentence):</span><br><span class="line">        embeds = self.word_embeddings(sentence) #查询句子的词向量表示。输入应该是二维tensor。</span><br><span class="line">        lstm_out,hidden = self.lstm(embeds.view(len(sentence),1,-1))</span><br><span class="line">        tag_space = self.hidden2tag(lstm_out.view(len(sentence),-1))</span><br><span class="line">        tag_scores = F.log_softmax(tag_space)</span><br></pre></td></tr></table></figure><p>训练模型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">model = LSTMtagger(EMBEDDING_DIM,HIDDEN_DIM,len(word_to_ix),len(tag_to_ix))</span><br><span class="line">loss_function = nn.NLLLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(),lr = 0.1)</span><br><span class="line"></span><br><span class="line">def prepare_sequence(seq,to_ix):</span><br><span class="line">    idxs = [to_ix[w] for w in seq]</span><br><span class="line">    return torch.tensor(idxs,dtype = torch.long)</span><br><span class="line"># 在训练模型之前，看看模型预测结果</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    inputs = prepare_sequence(train_data[0][0],word_to_ix)</span><br><span class="line">    tag_scores = model(inputs)</span><br><span class="line">    print(tag_scores)</span><br><span class="line">    predict = np.argmax(tag_scores,axis = 1)</span><br><span class="line">    print(predict)</span><br><span class="line"></span><br><span class="line">for epoch in range(300):</span><br><span class="line">    for sentence,tags in train_data:</span><br><span class="line">        # step 1:pytorch会累积梯度，要清楚所有variable的梯度。</span><br><span class="line">        model.zero_grad()</span><br><span class="line">        # step 2:准备好数据，变成tensor</span><br><span class="line">        sentence_in = prepare_sequence(sentence,word_to_ix)</span><br><span class="line">        targets = prepare_sequence(tags,tag_to_ix)</span><br><span class="line">        # step 3:得到输出</span><br><span class="line">        tag_scores = model(sentence_in)</span><br><span class="line">        # step4: 计算loss</span><br><span class="line">        loss = loss_function(tag_scores,targets)</span><br><span class="line">        # step5: 计算loss对所有variable的梯度</span><br><span class="line">        loss.backward()</span><br><span class="line">        # step6： 单步优化，根据梯度更新参数</span><br><span class="line">        optimizer.step()</span><br><span class="line"># 模型训练后，看看预测结果</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    inputs = prepare_sequence(train_data[0][0],word_to_ix)</span><br><span class="line">    tag_scores = model(inputs)</span><br><span class="line">    print(tag_scores)</span><br><span class="line">    predict = np.argmax(tag_scores,axis = 1)</span><br><span class="line">    print(predict)</span><br></pre></td></tr></table></figure><p>输出结果为：<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/19.png" alt title>                </div>                <div class="image-caption"></div>            </figure>我们可以看到，训练之后的预测序列为 [0,1,2,0,1]也就是[“DET”, “NN”, “V”, “DET”, “NN”]</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/28448135" target="_blank" rel="noopener">序列模型和基于LSTM的循环神经网络</a></li><li><a href="https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html" target="_blank" rel="noopener">Sequence Models and Long-Short Term Memory Networks-官方</a></li><li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a></li><li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;用pytorch实现基于LSTM的循环神经网络。&lt;/p&gt;
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
      <category term="循环神经网络" scheme="http://yoursite.com/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>pytorch实现Word embedding</title>
    <link href="http://yoursite.com/2019/03/20/pytorch%E5%AE%9E%E7%8E%B0Word-embedding/"/>
    <id>http://yoursite.com/2019/03/20/pytorch实现Word-embedding/</id>
    <published>2019-03-20T12:16:21.000Z</published>
    <updated>2019-07-07T07:11:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>word embedding是稠密的实数向量。Word embedding是一个词的语义表示，有效地编码了词的语义信息。</p><a id="more"></a> <h2 id="one-hot编码"><a href="#one-hot编码" class="headerlink" title="one-hot编码"></a>one-hot编码</h2><p>在自然语言处理任务中，我们常常要与词打交道。那么在计算机上，我们怎么表示一个单词呢？一种思路是one-hot编码。假设词汇表为$V$,词汇表大小(vocab_size)为$N_V$。我们可以用向量$N_V$维向量$[1,0,0…,0,0]$来表示第一个词。以此类推，来表示所有的词。<br>这种方法有致命的弱点。首先是向量维度太大，太稀疏，效率太低。更要命的是，one-hot编码把词与词间看做完全独立的，没有表达出词与词之间的联系和相似性。而这正是我们想要的。<br>举个例子，我们想要构建一个语言模型。有以下三个句子</p><ul><li>数学家待在实验室里。</li><li>物理学家待在实验室里。</li><li>数学家解决了一个难题。</li></ul><p>我们又看到一个新的句子：</p><ul><li>物理学家解决了一个难题。</li></ul><p>我们希望语言模型可以学习到以下特点：</p><ul><li><code>数学家</code>和<code>物理学家</code>在一个句子中同样的位置出现。这两个词之间有某种语义上的联系</li><li><code>数学家</code>曾经出现在我们看到的这个新句子中<code>物理学家</code>出现的位置。</li></ul><p>这就是<strong>语义相似性</strong>想表达的。语义相似性可以将没见过的数据与已经见过的数据联系起来，来解决语言数据的稀疏性问题。这个例子基于一个基本的语义学假设：出现在相似文本中的词汇在语义上是相互联系的。这称为<strong>distributional hypothesis</strong><br>值得一提的是，在分类问题中，one-hot编码很适合用在类别的编码上。</p><h2 id="word-embedding"><a href="#word-embedding" class="headerlink" title="word embedding"></a>word embedding</h2><p>我们怎样编码来表达词汇的语义相似性呢？我们考虑词汇的semantic attributes。例如，物理学家和数学家学可能[头发不多，爱喝咖啡，会看论文，会说英语]。我们可以用这四个属性来编码<code>物理学家</code>和<code>数学家</code>。$$q_物 = [0.9,0.8,0.98,0.8]$$$$q_数 = [0.91,0.89,0.9,0.85]$$<br>我们可以衡量这两个词之间的语义相似度：$$similarity(q_物,q_数) = \frac{q_物\cdot q_数}{|q_物| \cdot |q_数|}=cos(\phi)    其中\phi是两个向量之间的夹角。$$<br>但我们如何选择属性特征，并决定每个属性的值呢？深度学习的核心思想是神经网络学习特征表示，而不用人为指定特征。我们干脆将Word embedding作为神经网络的参数，让神经网络在训练的过程中学习Word embedding。<br>神经网络学到的Word embedding是潜在语义属性。也就是说，如果两个词在某个维度上都有大的值，我们并不知道这个维度代表了什么属性，这不能人为解释。这就是潜在语义属性的含义。<br>总的来说，Word embedding是一个词的语义表示，有效地编码了词的语义信息。</p><h2 id="PyTorch实现word-embedding"><a href="#PyTorch实现word-embedding" class="headerlink" title="PyTorch实现word embedding"></a>PyTorch实现word embedding</h2><p>代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"># 词汇表字典</span><br><span class="line">word_to_ix = &#123;&apos;The&apos;: 0, &apos;dog&apos;: 1, &apos;ate&apos;: 2, &apos;the&apos;: 3, &apos;apple&apos;: 4, &apos;Everybody&apos;: 5, &apos;read&apos;: 6, &apos;that&apos;: 7, &apos;book&apos;: 8&#125;</span><br><span class="line">vocab_size = len(word_to_ix) </span><br><span class="line">embedding_dim = 15</span><br><span class="line">word_embeddings = nn.Embedding(vocab_size,embedding_dim)</span><br></pre></td></tr></table></figure><p><code>nn.Embedding()</code>随机初始化了一个形状为[vocab_size,embedding_dim]的词向量矩阵，是神经网络的参数。<br>接下来我们查询”dog”这个词的向量表示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dog_idx = torch.LongTensor([word_to_ix[&apos;dog&apos;]]) #注意输入应该是一维数组。</span><br><span class="line">dog_idx = Variable(dog_idx)</span><br><span class="line">dog_embed = word_embeddings(dog_idx) #注意不是索引</span><br><span class="line">print(dog_embed)</span><br></pre></td></tr></table></figure><p>上述代码中，要访问<code>dog</code>的词向量，要得到一个Variable。word_embeddings的输入应该是一个一维tensor。<br>接下来，我们查询一句话的向量表示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sent = &apos;The dog ate the apple&apos;.split()</span><br><span class="line">sent_idxs = [word_to_ix[w] for w in sent]</span><br><span class="line">sent_idxs = torch.LongTensor(sent_idxs)</span><br><span class="line">sent_idxs = Variable(sent_idxs)</span><br><span class="line">sent_embeds = embeds(sent_idxs) </span><br><span class="line">print(sent_embeds)</span><br></pre></td></tr></table></figure><h2 id="pytorch加载预训练词向量"><a href="#pytorch加载预训练词向量" class="headerlink" title="pytorch加载预训练词向量"></a>pytorch加载预训练词向量</h2><p>之前的方法中，词向量是随机初始化的，作为模型参数在训练过程中不断优化。通常我们要用到预训练的词向量，这样可以节省训练时间，并可能取得更好的训练结果。下面介绍两种加载预训练词向量的方式。<br>方式一：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">word_embeddings = torch.nn.Embedding(vocab_size,embedding_dim) #创建一个词向量矩阵</span><br><span class="line">pretrain_embedding  = np.array(np.load(np_path),dtype = &apos;float32&apos;) #np_path是一个存储预训练词向量的文件路径</span><br><span class="line">word_embeddings.weight.data.copy_(troch.from_numpy(pretrain_embedding)) #思路是将np.ndarray形式的词向量转换为pytorch的tensor，再复制到原来创建的词向量矩阵中</span><br></pre></td></tr></table></figure><p>方式二：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">word_embeddings = torch.nn.Embedding(vocab_size,embedding_dim) #创建一个词向量矩阵</span><br><span class="line">word_embeddings.weight = nn.Parameter(torch.FloatTensor(pretrain_embedding))</span><br></pre></td></tr></table></figure><h3 id="涉及函数详解"><a href="#涉及函数详解" class="headerlink" title="涉及函数详解"></a>涉及函数详解</h3><h4 id="numpy-与from-numpy"><a href="#numpy-与from-numpy" class="headerlink" title="numpy()与from_numpy()"></a>numpy()与from_numpy()</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.from_numpy(ndarray) $\to$ tensor</span><br></pre></td></tr></table></figure><ul><li>作用：numpy桥，将<code>numpy.ndarray</code>转换为pytorch的<code>tensor</code>.返回的张量与numpy.ndarray共享同一内存空间，修改一个另一个也会被修改。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor.numpy()</span><br></pre></td></tr></table></figure><ul><li>作用：numpy桥，将pytorch的<code>tensor</code>转换为<code>numpy.ndarray</code>.二者共享同一内存空间，修改一个另一个也会被修改。</li></ul><p>举个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(5)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">c = b.numpy()</span><br></pre></td></tr></table></figure><h4 id="tensor-copy-src"><a href="#tensor-copy-src" class="headerlink" title="tensor.copy_(src)"></a>tensor.copy_(src)</h4><ul><li>作用：将<code>src</code>中的元素复制到tensor并返回。两个tensor应该有相同数目的元素和形状，可以是不同数据类型或存储在不同设备上。</li></ul><p>举个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(1,5)</span><br><span class="line">b = torch.randn(1,5)</span><br><span class="line">b.copy_(a)</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html?highlight=embed" target="_blank" rel="noopener">Word Embeddings: Encoding Lexical Semantics</a></li><li><a href="https://ptorch.com/news/11.html" target="_blank" rel="noopener">PyTorch快速入门教程七（RNN做自然语言处理）</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;word embedding是稠密的实数向量。Word embedding是一个词的语义表示，有效地编码了词的语义信息。&lt;/p&gt;
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="word embedding" scheme="http://yoursite.com/tags/word-embedding/"/>
    
  </entry>
  
  <entry>
    <title>去新藏线上骑车</title>
    <link href="http://yoursite.com/2019/03/14/%E5%8E%BB%E6%96%B0%E8%97%8F%E7%BA%BF%E4%B8%8A%E9%AA%91%E8%BD%A6/"/>
    <id>http://yoursite.com/2019/03/14/去新藏线上骑车/</id>
    <published>2019-03-14T09:49:34.000Z</published>
    <updated>2019-07-22T00:58:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>18年的夏天，热烈的阳光透过浓密的叶子照在窗台的盆栽上，有着丝丝的风。就在这美丽的季节里，我们毕业了。毕业后的暑假，我终于做到了我想做的一件事，骑车去那小小的尼泊尔。</p><a id="more"></a><p>该说说出发的动机和情景。我曾经产生这样的念头：“骑车出国，横穿整个欧亚大陆，是件了不起的事啊！”直到旺哥在论坛上发帖征新藏线的队友，这个念头促使我下了决心去新藏线上骑车。出发前还需要做些准备，克服一些阻力。我回家办了护照和边防证，在北京办好了尼泊尔的签证，在学校做好路书和高程图，准备好了衣服装备。出发前，超哥、大胖儿和狗子帮我修理了我那辆难骑的车。我曾怀疑我这个念头是不是心血来潮，我问弟弟：“我骑车太多了，是不是有点不务正业啊？”弟弟跟我说：“这是你喜欢做的事情嘛！”家人和朋友给了我很多的帮助和支持，我才得以做好出发的准备。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/14.jpg" alt title>                </div>                <div class="image-caption"></div>            </figure><p>7月21日-24日，西行的火车经过57个小时的颠簸，载着我到了新疆喀什，我和旺哥约好了从这出发。喀什市是一个不大的城市，分为旧城区和新城区，除了维吾尔族，还有不少定居在这的汉族人。正式出发前的一天，我和旺哥去逛了旧城区，常可以见到在小巷子里、在空地上踢足球的小男孩。第一天的目的地是莎车县，行程约190公里，加上中午的酷热，下午的逆风，到莎车县安顿下来已经是晚上九点，一路上几近崩溃，身体已经被掏空。用鲁豫对于谦的访谈内容来形容第一天的骑行恰如其分。</p><ul><li>鲁豫：成名之前，你和郭德纲经常整天整天地表演相声，很少有休息时间。那段日子快乐吗？</li><li>于谦：快死了！</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/15.jpg" alt title>                </div>                <div class="image-caption"></div>            </figure><p>新疆地广人稀，大片的地方是没有人烟的荒漠，有人烟的村落常隔着几十甚至上百公里远，至于城镇则更少。新藏线差不多已经是我国边疆区域，有着很多“地方特色”。城里的银行、邮局、药店，进出都要刷身份证登记。曾在县城里看到一场浩大的阵势，一辆装甲车开路，后面跟着两排公安巡逻车，得有二十多辆，整整齐齐。出英吉沙县城区的路上，有段路有许多防暴的警察，个个全副武装，头戴黑色头盔，身着黑色制服，外面再套上黑马甲，上面写着“警察 police”。这些警察大多是维族青壮年，手执的武器变化多端，有一人高的黑色长棍，半人高前端配有刺刀的棍子，防暴叉，冲锋枪…….真是十八般兵器，令人眼花缭乱。稳定是发展的前提，这也是情有可原的事。新疆的治安十分严格，这里写一则趣事。趁吃午饭的空档，我骑车去邮局盖邮戳，回饭店的路上偷懒逆行了一段路。一个警察挥挥手示意我停下来，接着便一顿训斥“不走人行道，逆行，啊！能不能有点素质！”我赶忙认错，等候发落，等了一会，他没再理我，我才灰溜溜地走开了。</p><p>第三天的行程是叶城到阿克美其特村。叶城是219国道的0公里所在，新藏线真正的起点。219国道的零公里处有个大拱门，左右各写：“天路零公里”，“昆仑第一城”，横批就是一个大大的“0”。叶城之后就很少有城镇了，大多是村落，物资补给就比较困难了。我和旺哥的后货架载得满满的，像是个小山。骑车出了叶城，自然环境是这样变化的，大树变小树，小树变低矮的灌木，灌木变成野草，戈壁滩渐渐露出了它的面目。在新藏线上，如果你能看到高高的树，那这个地方就有比较丰富的水，有水源的地方一般就有人烟。晚上，我们到了阿克美其特村，一个经常停电的小村子，我和旺哥住在村民家里。</p><p>阿克美其特村，故事在这里发生，这是个我铭记着的村子。早上出发，骑车出去没多远，我发现我的车子后轮花鼓断了。我们决定：旺哥继续前行，到物资补给更方便的地方等我；我返回去修理后轮。断花鼓的第一天，我卸下自行车的后轮，背上小包，村干部找了辆车把我送到了柯克亚乡，我在乡里坐出租车到了叶城县。我偷懒没去更远的喀什市，只是在叶城县找了一个不靠谱的修车师傅给我换了个花鼓，修理完已经快天黑了，于是夜宿叶城。断花鼓的第二天，一大早我就到汽车站坐车，上午十点返回阿克美其特村，把后轮换好再次出发，没上次骑得远，车子故障，发现后轮没修好。我要再返回叶城，这次没有车送我了，我边走边搭车，一百公里的路，走了十几公里，搭了四五辆车到了叶城。在叶城买火车票，坐火车到喀什市。断花鼓的第三天，一大早我到了喀什，前往捷安特店，买了个后轮。买火车票返回叶城，边走边搭车，晚上十点返回到阿克美其特村。</p><p>断花鼓的第三天，我几乎想放弃了。高婷婷同学恰好发微信慰问我，是我艰难日子里的一缕阳光！返回阿克美其特村时，我搭了一辆大卡车，司机师傅是山西的，一路上陪师傅聊天。师傅说，海拔高，氧气少，路难走，在新藏线上开大卡车就是在玩命。新藏线上常可以看到翻倒在路边的大卡车。有的司机带着老婆出来开大卡车拉货，出了事，就剩个孩子跟着爷爷奶奶。新藏线上有各样的人，踩单车的，骑摩托的，自驾游的，来谋生的，开卡车，摆水果摊，开旅店。</p><p>我搭车走了一百多公里，在三十里营房追上了旺哥。在红柳滩我们遇到了两个新伙伴，吴锡贤和邓翱，分别大一和大二。他们俩都走过川藏线，体力好，干练，真不愧英雄出少年！加入新的队友后，我还是队里体力最差的那个人。红柳滩后三百公里被称为无人区，人烟极少，必须严格按照行程赶到住宿地点，不然只能露宿荒野。出发前的那个晚上，有个骑友滔滔不绝地谈论这段路：“去年有两个骑友，没到达住宿点，露营在一个没有门的厕所里，被狼啃得只剩一条腿了。”听了这不知真假的话，我如临大敌，连夜把驼包收拾好，给车打满气。第二天早早地就起床了，早饭丰盛而美味，香甜的玉米糊，榨菜、拍黄瓜、花生米三样小菜，热乎松软的馒头，每人一个蒸鸡蛋，像是上刑场前的盛宴。<br> <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/16.jpg" alt title>                </div>                <div class="image-caption"></div>            </figure><br>三天后，我们终于穿过了无人区，后面的路就好走了。无限风光在险峰，我们几个人在无人区远远地看到了藏羚羊或是黄羊，看不清她的样子丝毫不影响我见到她时的激动和惊喜。新藏线辽阔俊美，大大小小的湖泊像是美玉点缀其间，远远近近的雪山在阳光照耀下度过岁月，起起伏伏的路延伸向远方没有尽头。新藏线上有时可以看到长长的军车车队驶过，像是士兵突击里的样子，不禁感叹一句：“好男儿就是要当兵。”</p><p>在西藏萨嘎县，我和他们仨分道扬镳，他们仨前往珠峰，我转向吉隆口岸去尼泊尔。出萨嘎县后，有六七十公里的路还在修，大部分是烂泥路。遇到大水坑，我就脱下鞋挂在车把上，推着车趟过去。实在骑不动了，我放弃了一定要全程骑完的念头，心安理得地推着车前进。就这样骑了一整天十个小时，只前进了五十公里。下午起了很大的逆风，遇到一个对面来的骑友，颇有惺惺相惜之感。他说前面有条河拦住了路，打算原路返回。天色渐晚，我再往前只能露宿荒野，于是借宿在修路的项目部。六七个西安的爷们收留我住了一宿，还用高压锅煮了面。有位做饭的阿姨聊天总是笑不停，让这座在大风中摇摆不停的帐篷里充满了温暖。</p><p>从吉隆镇到吉隆口岸的一百公里路，海拔陡降，全是下坡，而且景色渐美，仿佛置身于画中，空气中有淡淡的木香味。独自欣赏这美景，不禁想念起我的队友来。推着自行车，过了海关，就踏出了国门，骑行在尼泊尔！再翻过两座山，我就要到加德满都了。尼泊尔境内的路有一大半是烂路，但景色很不错，常有泉水从山上流到路上来，后来我干脆踩水玩，让泉水冲去我鞋上的泥沙。这段路太烂了，非常不推荐骑车去尼泊尔。在尼泊尔境内骑行了两天，8月22日我终于抵达了加德满都！洗个澡，换身干净衣服，卖掉自行车，去杜巴广场喝酸奶，去看黄昏里的梦花园，看猴子在城市里游荡。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/17.jpg" alt="尼泊尔的小孩子" title>                </div>                <div class="image-caption">尼泊尔的小孩子</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/18.jpg" alt="俯瞰加德满都" title>                </div>                <div class="image-caption">俯瞰加德满都</div>            </figure><p>理性地来说，旺哥的队医知识、修车技术和体力都胜过我（除了帅，我真是一无是处啊！），如果没有旺哥的帮助，我很难走完这条线。新藏线这一路上，没怎么写日记，倒是跟旺哥斗了很多盘地主，给一些朋友写了好多明信片，盖到了几个邮戳。</p><p>骑车有什么意义呢？当谈到尼泊尔，我对自己说：“嘿，这个地方我骑车去过哦！”曾经到达就是我的意义。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;18年的夏天，热烈的阳光透过浓密的叶子照在窗台的盆栽上，有着丝丝的风。就在这美丽的季节里，我们毕业了。毕业后的暑假，我终于做到了我想做的一件事，骑车去那小小的尼泊尔。&lt;/p&gt;
    
    </summary>
    
      <category term="生活记录" scheme="http://yoursite.com/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="新藏线" scheme="http://yoursite.com/tags/%E6%96%B0%E8%97%8F%E7%BA%BF/"/>
    
      <category term="骑车" scheme="http://yoursite.com/tags/%E9%AA%91%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>sublime插件</title>
    <link href="http://yoursite.com/2019/03/11/sublime%E6%8F%92%E4%BB%B6/"/>
    <id>http://yoursite.com/2019/03/11/sublime插件/</id>
    <published>2019-03-11T11:41:12.000Z</published>
    <updated>2019-03-11T13:04:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>记录sublime的一些插件。</p><a id="more"></a> <h2 id="OmniMarkupPreviewer"><a href="#OmniMarkupPreviewer" class="headerlink" title="OmniMarkupPreviewer"></a>OmniMarkupPreviewer</h2><p><strong>作用：</strong>插件OmniMarkupPreviewer支持将markdown语言渲染为html并且在浏览器上实时预览，也就是将markdown内容实时显示为网页，效果之好令人惊叹。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>可以使用<code>Package Control</code>的<code>Insatll Package</code>来安装，也可以直接从<a href="https://github.com/timonwong/OmniMarkupPreviewer" target="_blank" rel="noopener">OmniMarkupPreviewer的github主页</a>下载压缩包，解压到目录<code>\Sublime Text 3\Packages\</code>下。</p><ol><li>快捷键<code>Ctrl + shift + p</code>打开<code>Package Control</code></li><li>输入<code>install</code>选择<code>Package Control: Install Package</code></li><li>从列表中选择<code>OmniMarkupPreviewer</code>安装。</li></ol><h3 id="使用方法："><a href="#使用方法：" class="headerlink" title="使用方法："></a>使用方法：</h3><p>对于window和Linux：</p><ul><li><code>Ctrl+Alt+O</code> 在浏览器中预览</li><li><code>Ctrl+Alt+X</code> 输出为html文件</li><li><code>Ctrl+Alt+C</code> 复制为HTML文件</li></ul><h3 id="插件配置"><a href="#插件配置" class="headerlink" title="插件配置"></a>插件配置</h3><p>修改插件的配置，点击菜单栏的<code>Preferences - Packages Settings - OmniMarkdownPreviwer - Setting-User</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;server_host&quot;: &quot;127.0.0.1&quot;,  //默认为localhost,修改为你电脑的ip，可以实现远程访问。也就是从其他电脑预览网页效果</span><br><span class="line">    &quot;server_port&quot;: 51004,</span><br><span class="line">    &quot;refresh_on_modified&quot;: true,</span><br><span class="line">    &quot;refresh_on_modified_delay&quot;: 500,</span><br><span class="line">    &quot;refresh_on_saved&quot;: true,</span><br><span class="line">    &quot;browser_command&quot;: [],</span><br><span class="line">    &quot;html_template_name&quot;: &quot;github&quot;,</span><br><span class="line">    &quot;ajax_polling_interval&quot;: 500,</span><br><span class="line">    &quot;ignored_renderers&quot;: [&quot;LiterateHaskellRenderer&quot;],</span><br><span class="line">    &quot;mathjax_enabled&quot;: true,  //渲染数学公式要用到MathJax库，将值设为true,mathjax会在后端自动下载。</span><br><span class="line">    &quot;export_options&quot; : &#123;</span><br><span class="line">        &quot;template_name&quot;: &quot;github-export&quot;,</span><br><span class="line">        &quot;target_folder&quot;: &quot;.&quot;,</span><br><span class="line">        &quot;timestamp_format&quot; : &quot;_%y%m%d%H%M%S&quot;,</span><br><span class="line">        &quot;copy_to_clipboard&quot;: false,</span><br><span class="line">        &quot;open_after_exporting&quot;: false</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;renderer_options-MarkdownRenderer&quot;: &#123;</span><br><span class="line">        &quot;extensions&quot;: [&quot;tables&quot;, &quot;fenced_code&quot;, &quot;codehilite&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="遇到的错误"><a href="#遇到的错误" class="headerlink" title="遇到的错误"></a>遇到的错误</h3><p>预览文本时报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Error: 404 Not Found</span><br><span class="line">Sorry, the requested URL &apos;http://127.0.0.1:51004/view/593&apos; caused an error:</span><br><span class="line"></span><br><span class="line">&apos;buffer_id(593) is not valid (closed or unsupported file format)&apos;</span><br><span class="line"></span><br><span class="line">**NOTE:** If you run multiple instances of Sublime Text, you may want to adjust</span><br><span class="line">the `server_port` option in order to get this plugin work again.</span><br></pre></td></tr></table></figure><p>解决办法是修改配置文件<code>Sublime Text &gt; Preferences &gt; Package Settings &gt; OmniMarkupPreviewer &gt; Settings - User</code>粘贴下面的代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;renderer_options-MarkdownRenderer&quot;: &#123;</span><br><span class="line">        &quot;extensions&quot;: [&quot;tables&quot;, &quot;fenced_code&quot;, &quot;codehilite&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul><li><a href="https://github.com/timonwong/OmniMarkupPreviewer" target="_blank" rel="noopener">OmniMarkupPreviewer的github主页</a></li><li><a href="https://blog.csdn.net/qq_30490125/article/details/53230408" target="_blank" rel="noopener">近乎完美的Markdown写作体验 - SublimeText3 + OmniMarkupPreviewer</a></li></ul><h2 id="OmniMarkupPreviewer-MathJax"><a href="#OmniMarkupPreviewer-MathJax" class="headerlink" title="OmniMarkupPreviewer + MathJax"></a>OmniMarkupPreviewer + MathJax</h2><p>OmniMarkupPreviewerx渲染markdown内容为网页，MathJax对LATEX编辑的数学公式进行渲染。</p><h3 id="下载mathjax"><a href="#下载mathjax" class="headerlink" title="下载mathjax"></a>下载mathjax</h3><ol><li>下载<a href="https://link.jianshu.com/?t=https://github.com/downloads/timonwong/OmniMarkupPreviewer/mathjax.zip" target="_blank" rel="noopener">mathjax</a>，解压到目录<code>Sublime Text 3\Packages\OmniMarkupPreviewer\public</code>下。</li><li>在目录<code>Sublime Text3\Packages\OmniMarkupPreviewer\</code>创建空文件<code>MATHJAX.DOWNLOADED</code>。这样就安装好了。</li></ol><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>新建markdown文件输入内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">This expression </span><br><span class="line">$\sqrt&#123;3x-1&#125;+(1+x)^2$ is an example of a $\LaTeX$ inline equation.he Lorenz Equations:</span><br><span class="line">$$\begin&#123;aligned&#125;\dot&#123;x&#125; &amp; = \sigma(y-x) \\\dot&#123;y&#125; &amp; = \rho x - y - xz \\\dot&#123;z&#125; &amp; = -\beta z + xy\end&#123;aligned&#125;$$</span><br></pre></td></tr></table></figure><p>在sublime中用<code>Ctrl+Alt+O</code>预览，显示效果如下：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/13.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h3 id="参考链接-1"><a href="#参考链接-1" class="headerlink" title="参考链接"></a>参考链接</h3><ul><li><a href="https://www.jianshu.com/p/23b02c1708ae" target="_blank" rel="noopener">使用Markdown的时候需要插入LaTeX公式方法</a></li></ul><p>关于LATEX:</p><ul><li><a href="https://liam.page/2014/09/08/latex-introduction/" target="_blank" rel="noopener">一份其实很短的 LaTeX 入门文档</a></li><li><a href="https://www.kancloud.cn/thinkphp/latex/41806" target="_blank" rel="noopener">一份其实很短的 LaTeX 入门文档</a></li><li><a href="http://mohu.org/info/symbols/symbols.htm" target="_blank" rel="noopener">常用数学符号的 LaTeX 表示方法</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录sublime的一些插件。&lt;/p&gt;
    
    </summary>
    
      <category term="技术资料" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E8%B5%84%E6%96%99/"/>
    
    
      <category term="sublime" scheme="http://yoursite.com/tags/sublime/"/>
    
  </entry>
  
  <entry>
    <title>熵、交叉熵与KL散度</title>
    <link href="http://yoursite.com/2019/03/11/%E7%86%B5%E3%80%81%E4%BA%A4%E5%8F%89%E7%86%B5%E4%B8%8EKL%E6%95%A3%E5%BA%A6/"/>
    <id>http://yoursite.com/2019/03/11/熵、交叉熵与KL散度/</id>
    <published>2019-03-11T06:31:33.000Z</published>
    <updated>2019-07-22T00:57:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>介绍交叉熵和KL散度。</p><a id="more"></a> <h2 id="从信息量到信源熵"><a href="#从信息量到信源熵" class="headerlink" title="从信息量到信源熵"></a>从信息量到信源熵</h2><ol><li>信息量是通信专业的名词。一个变量的主要特征就是不确定性，也就是发生的概率。信息量用来衡量不确定性的大小。一个事情发生的概率越小，使人越感到意外，则这件事的信息量越大；反之，概率越大，越不意外，信息量越小。举个例子，有一架波音747飞机失事，发生的概率很小，让人很意外，带给人的信息量很大。<br> 信息量函数应满足两个特性：1）随着概率的增大而减小，即是概率的减函数；2）信息量函数满足可加性，即两个统计独立的消息提供的信息量等于他们分别提供的信息量之和。同时满足递减性和可加性的函数是对数函数，即<br> $$ I[p(x_i)] = log \frac{1}{p(x_i)} = -log p(x_i)$$</li><li>信源熵定义为信源输出的平均信息量，即信息量的数学期望。$$ H(X) = E(I[p(x_i)]) = E(-log p(x_i)) = - \sum_{i=1}^{n}p(x_i)log p(x_i)$$信源实际上是一个概率分布，信源熵可以解释为表示这个概率分布至少需要的信息量。</li></ol><h2 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h2><p>对于一个随机事件，真实概率分布是$p(x_i)$ 是未知的，从数据中得到概率分布为$q(x_i)$。我们用概率分布$q(x_i)$来近似和逼近真实的概率分布$p(x_i)$ 。交叉熵定义为：$$H(p,q) = \sum_{i=1}^{n}p(x_i) I[q(x_i)] =- \sum_{i=1}^{n}p(x_i)log(x_i) $$交叉熵$H(p,q)$是用概率分布$q(x_i)$来近似真实概率分布$p(x_i)$需要的信息量。上面我们说过，信源熵$H(X)$是表示真实概率分布$p(x_i)$需要的最小信息量。可以得到结论：$$H(p,q) \ge H(p)$$由吉布斯不等式可以证明，当且仅当分布$p(x_i)$与$q(x_i)$完全一致时，等号才成立。这个不等式的意义是：用概率分布$q(x_i)$来近似真实概率分布$p(x_i)$需要的信息量一定大于等于概率分布$p(x_i)$本身的信源熵。交叉熵比信源熵多出来的这部分，就是冗余信息量，我们称为KL散度（相对熵）。<br>$$KL(p||q)= H(p,q) - H(p) \ge 0$$容易看出交叉熵并不是一个对称量，即$ H(p,q) \not=H(q,p)$。同样的,KL散度也不是一个对称量，即$KL(p||q) \not =KL(q||p) $<br>给定概率分布$p(x_i)$,信源熵$H(p)$就是固定不变的。在机器学习中，交叉熵常用作分类问题的损失函数。交叉熵刻画了预测概率分布$q(x_i)$与真实概率分布$p(x_i)$之间的距离。通过减小交叉熵$H(p,q)$,我们可以使得预测概率分布$q(x_i)$不断逼近真实概率分布$p(x_i)$</p><h2 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵"></a>相对熵</h2><p>真实的概率分布为$p(x_i)$，我们用预测概率分布$q(x_i)$对它进行建模和近似。我们需要的平均附加量，也就是冗余量是：<br>$$KL(p,q) = H(p,q) - H(q) = -\sum_{i=1}^{n}p(x_i)logq(x_i) - \biggl(-\sum_{i=1}^{n}p(x_i)logp(x_i)\biggr) = -\sum_{i=1}^{n}p(x_i)log{\frac{q(x_i)}{p(x_i)}}$$KL散度有以下几个特性：</p><ul><li>KL散度不是一个对称量，即$KL(p||q) \not =KL(q||p) $</li><li>$KL(p||q)\ge 0$，当且仅当分布$p(x_i)$与$q(x_i)$完全一致时，等号才成立。</li><li>KL散度可以看做两个分布之间不相似程度的度量。KL散度越小，两个分布的不相似程度越小，分布$q(x_i)$越适合来近似$p(x_i)$。</li></ul><h2 id="tensorflow用交叉熵做损失函数"><a href="#tensorflow用交叉熵做损失函数" class="headerlink" title="tensorflow用交叉熵做损失函数"></a>tensorflow用交叉熵做损失函数</h2><p>在机器学习中交叉熵常常用作分类问题的损失函数。这里有个问题，交叉熵用于概率分布，但神经网络的输出并不一定是一个概率分布。<br>概率分布应满足2个条件:<br>1) $0 \le p(X =x) \le 1$<br>2) $\sum_{x}{} p(X=x) = 1$<br>如何把神经网络的输出变成概率分布呢？这里就要用到softmax回归。假设输出层的输出为$y_0,y_1,y_2 \dots y_n$,则softmax函数的形式为：$$softmax(y_i) = \frac{exp(y_i)}{\sum_{j}exp(y_j)}$$由于交叉熵一般会与softmax回归一起使用，TensorFlow对这两个功能进行了统一，可以直接用函数<a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3.html" target="_blank" rel="noopener">tf.nn.softmax_cross_entropy_with_logits</a>来计算softmax后的交叉熵函数。对于只有一个正确答案的分类问题，可以用函数<a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3.html" target="_blank" rel="noopener">tf.nn.sparse_nn.softmax_cross_entropy_with_logits</a>来加速计算过程。</p><h2 id="pytorch中交叉熵损失函数的实现"><a href="#pytorch中交叉熵损失函数的实现" class="headerlink" title="pytorch中交叉熵损失函数的实现"></a>pytorch中交叉熵损失函数的实现</h2><p>在多分类问题中，实际概率分布是 $y = [y_0,y_1,…,y_{C-1}]$,其中C为类别数;y是样本标签的one-hot表示，当样本属于第$i$类时$y_i=1$,否则$y_i=0$。预测概率分布为$p = [p_0,p_1,p_2,…,p_{C-1}]$。$c$是样本标签。此时，交叉熵损失函数为$$loss = -\sum_{i=0}^{C-1}y_i log(p_i) = - y_c \cdot log(p_c) = - log(p_c)$$<br>接下来介绍pytorch中具体实现这个数学式子的函数。</p><h3 id="torch-nn-functional-log-softmax-与class-torch-nn-NLLLoss"><a href="#torch-nn-functional-log-softmax-与class-torch-nn-NLLLoss" class="headerlink" title="torch.nn.functional.log_softmax()与class torch.nn.NLLLoss()"></a>torch.nn.functional.log_softmax()与class torch.nn.NLLLoss()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.log_softmax()</span><br></pre></td></tr></table></figure><ul><li>作用：先做softmax运算，再做log运算。在数学上等价于$log(softmax(x))$</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class torch.nn.NLLLoss(weight = None)</span><br></pre></td></tr></table></figure><ul><li>作用：这是neg log likelihood loss（NLLLoss），即负对数似然函数。</li><li>参数：   <ul><li>weight(tensor,optional): 一维tensor，里面的值对应类别的权重。当训练集样本分布不均匀时，使用这个参数非常重要。手动指定类别的权重，长度应为类别个数C。</li></ul></li><li>输入：<ul><li>input(N,C): C是类别个数。为<code>log_probabilities</code>形式，即概率分布再取log。可以在最后一层加<code>log_softmax</code>,这就要用到函数<code>torch.nn.functional.log_softmax()</code></li><li>targets(N): 是类别的索引，而不是类别的one-hot表示。比如，5个类别中的第3类，target应为<code>2</code>,而不是<code>[0,0,1,0,0]</code></li></ul></li></ul><p>loss可以表示为：$$loss(x,class) = -x[class]$$如果指定了weight，可以表示为：$$loss(x,class) = - weight[class]*x[class]$$<br>举个例子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">log_m = torch.nn.functional.log_softmax()</span><br><span class="line">loss_function = torch.nn.NLLLoss()</span><br><span class="line">inputs = torch.randn(3,5) #batch_size * num_classes = 3 * 5</span><br><span class="line">target = torch.LongTensor([1,0,4])</span><br><span class="line">loss = loss_function(log_m(inputs),target)  # inputs要先做log_softmax，再送入loss_function</span><br><span class="line">loss.backward()</span><br></pre></td></tr></table></figure><h3 id="class-torch-nn-CrossEntropyLoss-weight-None"><a href="#class-torch-nn-CrossEntropyLoss-weight-None" class="headerlink" title="class torch.nn.CrossEntropyLoss(weight = None)"></a>class torch.nn.CrossEntropyLoss(weight = None)</h3><ul><li>作用：将函数<code>log_softmax</code>和<code>NLLLoss</code>集成到一起。在多分类问题中非常有用。</li><li>参数：   <ul><li>weight(tensor,optional): 一维tensor，里面的值对应类别的权重。当训练集样本分布不均匀时，使用这个参数非常重要。手动指定类别的权重，长度应为类别个数C。</li></ul></li><li>输入：<ul><li>input(N,C): C是类别个数。每个类别的分数，不用过softmax层。</li><li>targets(N): 是类别的索引，而不是类别的one-hot表示。比如，5个类别中的第3类，target应为<code>2</code>,而不是<code>[0,0,1,0,0]</code>。</li></ul></li></ul><p>loss可以表示为：$$loss(x,class) = - \text{log}\frac{e^{x[class]}}{ \sum_{j=0}^{C-1}e^{x[j]}} = -x[class] + \text{log}(\sum_{j=0}^{C-1}e^{x[j]}) $$当指定了weight时，loss计算公式为： $$ loss(x, class) = weights[class] \cdot (-x[class] + \text{log}(\sum_{j=0}^{C-1}e^{x[j]})) $$<br>参见：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/56638625" target="_blank" rel="noopener">PyTorch学习笔记——多分类交叉熵损失函数</a></li><li><a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#loss-functions" target="_blank" rel="noopener">pytorch官方手册</a><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2></li><li><a href="https://wizyoung.github.io/%E4%BF%A1%E6%81%AF%E7%86%B5%EF%BC%8C%E7%9B%B8%E5%AF%B9%E7%86%B5%EF%BC%8C%E4%BA%A4%E5%8F%89%E7%86%B5%E7%9A%84%E7%90%86%E8%A7%A3/#more" target="_blank" rel="noopener">信息熵，相对熵，交叉熵的理解</a></li><li><a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3.html" target="_blank" rel="noopener">Tensorflow基础知识—损失函数详解</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍交叉熵和KL散度。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="交叉熵" scheme="http://yoursite.com/tags/%E4%BA%A4%E5%8F%89%E7%86%B5/"/>
    
      <category term="相对熵" scheme="http://yoursite.com/tags/%E7%9B%B8%E5%AF%B9%E7%86%B5/"/>
    
  </entry>
  
  <entry>
    <title>python的一些函数</title>
    <link href="http://yoursite.com/2019/03/10/python%E7%9A%84%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0/"/>
    <id>http://yoursite.com/2019/03/10/python的一些函数/</id>
    <published>2019-03-10T08:12:51.000Z</published>
    <updated>2019-07-07T07:07:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>记录python的一些函数，实现某些功能。</p><a id="more"></a> <h2 id="求最大-小值的索引"><a href="#求最大-小值的索引" class="headerlink" title="求最大/小值的索引"></a>求最大/小值的索引</h2><h3 id="对于list"><a href="#对于list" class="headerlink" title="对于list"></a>对于list</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">a = range(100)</span><br><span class="line">np.random.shuffle(a)</span><br><span class="line">index_max = a.index(max(a)) #求最大值的索引</span><br><span class="line">index_min = a.index(min(a)) #求最小值的索引</span><br></pre></td></tr></table></figure><h3 id="对于numpy的数组ndarray"><a href="#对于numpy的数组ndarray" class="headerlink" title="对于numpy的数组ndarray"></a>对于numpy的数组ndarray</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = np.array(a)</span><br><span class="line">index_max = np.argmax(a) #求最大值的索引</span><br><span class="line">index_min = np.argmin(a) #求最小值的索引</span><br><span class="line"># 对于二维的数组</span><br><span class="line">b = np.arange(100).reshape(10,-1)</span><br><span class="line">row_max_list = np.argmax(b,axis = 1) #按行计算最大值在行中的索引</span><br><span class="line">line_max_list = np.argmin(b,axis = 0) #按列计算最小值在列中的索引</span><br></pre></td></tr></table></figure><h2 id="sort与sorted"><a href="#sort与sorted" class="headerlink" title="sort与sorted"></a>sort与sorted</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sorted(iterable,key,reverse)</span><br></pre></td></tr></table></figure><ul><li>iterable: 可迭代对象</li><li>key：用来进行比较的元素。常用函数： lambda x:x[i]</li><li>reverse：排序规则。reverse=True按降序排列，reverse=False按升序排列（默认）</li></ul><p>比较sort与sorted:</p><ul><li>作用对象:sort()只能作用于list,sorted()可以作用于所有可迭代对象。</li><li>返回值：sort()没有返回值；sorted()返回一个新的list</li></ul><h2 id="字典的items-方法"><a href="#字典的items-方法" class="headerlink" title="字典的items()方法"></a>字典的items()方法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dict.items()</span><br></pre></td></tr></table></figure><p>返回可遍历的元素为（键，值）元组的数组。</p><h2 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h2><h3 id="collections–容器数据类型"><a href="#collections–容器数据类型" class="headerlink" title="collections–容器数据类型"></a>collections–容器数据类型</h3><p><a href="https://docs.python.org/zh-cn/3/library/collections.html#collections.Counter" target="_blank" rel="noopener">collections</a>模块是python内建的一个集合模块，提供了许多有用的集成类。提供了<code>list</code>,<code>dict</code>,<code>set</code>,<code>tuple</code>的替代选择，相当于这几个数据类型的加强版。</p><h4 id="collections-Counter-iterable"><a href="#collections-Counter-iterable" class="headerlink" title="collections.Counter(iterable)"></a>collections.Counter(iterable)</h4><p>Counter是一个计数器，用于计数可哈希对象，统计元素出现的个数。它是一个集合，<code>元素-计数</code>像<code>键-值</code>对一样存储。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; import collections</span><br><span class="line"></span><br><span class="line">&gt;&gt; a = [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;a&quot;,&quot;b&quot;,&quot;a&quot;]</span><br><span class="line">&gt;&gt; counter = collections.Counter(a)</span><br><span class="line">&gt;&gt; print(counter)</span><br><span class="line">Counter(&#123;&apos;a&apos;: 3, &apos;b&apos;: 2, &apos;c&apos;: 1&#125;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录python的一些函数，实现某些功能。&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>全文搜索引擎-Elasticsearch入门</title>
    <link href="http://yoursite.com/2019/03/10/%E5%85%A8%E6%96%87%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-Elasticsearch%E5%85%A5%E9%97%A8/"/>
    <id>http://yoursite.com/2019/03/10/全文搜索引擎-Elasticsearch入门/</id>
    <published>2019-03-10T07:11:17.000Z</published>
    <updated>2019-07-22T00:38:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>Elasticsearch是一个开源的搜索引擎框架。</p><a id="more"></a><h2 id="Elasticsearch安装和启动"><a href="#Elasticsearch安装和启动" class="headerlink" title="Elasticsearch安装和启动"></a>Elasticsearch安装和启动</h2><p><strong>安装前提：</strong>Elasticsearch需要Java7或以上的版本。</p><ol><li><p>下载压缩包并解压：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.1.zip</span><br><span class="line">unzip elasticsearch-6.6.1.zip</span><br><span class="line">cd elasticsearch-6.6.1</span><br></pre></td></tr></table></figure></li><li><p>进入解压后的文件目录，启动elasticsearch：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch</span><br></pre></td></tr></table></figure></li><li><p>如果一切正常，elasticsearch默认在本机9200端口运行。打开另一个命令行窗口，执行以下命令，检查elasticsearch是否运行成功：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl localhost:9200</span><br></pre></td></tr></table></figure><p> 如果输出以下信息，则运行正常。<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/12.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p></li><li><p>默认情况下，elasticsearch只允许本机访问。要想其他电脑可以访问，也就是实现远程访问，需要修改文件<code>/config/elasticsearch.yml</code>,取消字段<code>network.host</code>的注释，把该字段的值改为<code>0.0.0.0</code>。这样的话所有的电脑都能访问，实际情况中，最好不要这样。</p></li><li><p>如果启动遇到错误“Native controller process has stopped - no new native processes can be started”或“max virtual memory areas vm.maxmapcount [65530] is too low”。解决方法是执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w vm.max_map_count=262144</span><br></pre></td></tr></table></figure></li></ol><h2 id="在python中使用elasticsearch"><a href="#在python中使用elasticsearch" class="headerlink" title="在python中使用elasticsearch"></a>在python中使用elasticsearch</h2><p>要先安装elasticsearch包。在python中使用elasticsearch要先启动elasticsearch。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install elasticsearch</span><br></pre></td></tr></table></figure><h3 id="创建index"><a href="#创建index" class="headerlink" title="创建index"></a>创建index</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from elasticsearch import Elasticsearch </span><br><span class="line">es = Elasticsearch() #创建实例，默认localhost:9200</span><br><span class="line"># es = Elasticsearch([&#123;&apos;host&apos;:&apos;10.112.1.109&apos;,&apos;port&apos;:&apos;9200&apos;&#125;]) #远程访问</span><br><span class="line">result = es.indices.create(index = &apos;news&apos;,ignore = 400)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><p>如果创建成功，会返回以下信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&apos;acknowledged&apos;: True, &apos;shards_acknowledged&apos;: True, &apos;index&apos;: &apos;test_es&apos;&#125;</span><br></pre></td></tr></table></figure><p>如果再次创建，就会返回以下信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&apos;error&apos;: &#123;&apos;root_cause&apos;: [&#123;&apos;type&apos;: &apos;resource_already_exists_exception&apos;, &apos;reason&apos;: &apos;index [news/TrkzNdXZRi6ReiZqOM2Dvg] already exists&apos;, &apos;index_uuid&apos;: &apos;TrkzNdXZRi6ReiZqOM2Dvg&apos;, &apos;index&apos;: &apos;news&apos;&#125;], &apos;type&apos;: &apos;resource_already_exists_exception&apos;, &apos;reason&apos;: &apos;index [news/TrkzNdXZRi6ReiZqOM2Dvg] already exists&apos;, &apos;index_uuid&apos;: &apos;TrkzNdXZRi6ReiZqOM2Dvg&apos;, &apos;index&apos;: &apos;news&apos;&#125;, &apos;status&apos;: 400&#125;</span><br></pre></td></tr></table></figure><p>表示创建失败，失败的原因是要创建的index已经存在了。status状态码是400。</p><h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">datas = [</span><br><span class="line">    &#123;&apos;title&apos;:&quot;算法导论（原书第2版）&quot;,</span><br><span class="line">    &apos;url&apos;:&quot;https://book.douban.com/subject/1885170/&quot;,</span><br><span class="line">    &apos;introduction&apos;:&quot;这本书深入浅出，全面地介绍了计算机算法。对每一个算法的分析既易于理解又十分有趣，并保持了数学严谨性。本书的设计目标全面，适用于多种用途。涵盖的内容有：算法在计算中的作用，概率分析和随机算法的介绍。书中专门讨论了线性规划，介绍了动态规划的两个应用，随机化和线性规划技术的近似算法等，还有有关递归求解、快速排序中用到的划分方法与期望线性时间顺序统计算法，以及对贪心算法元素的讨论。此书还介绍了对强连通子图算法正确性的证明，对哈密顿回路和子集求和问题的NP完全性的证明等内容。全书提供了900多个练习题和思考题以及叙述较为详细的实例研究。这本书深入浅出，全面地介绍了计算机算法。对每一个算法的分析既易于理解又十分有趣，并保持了数学严谨性。本书的设计目标全面，适用于多种用途。涵盖的内容有：算法在计算中的作用，概率分析和随机算法的介绍。书中专门讨论了线性规划，介绍了动态规划的两个应用，随机化和线性规划技术的近似算法等，还有有关递归求解、快速排序中用到的划分方法与期望线性时间顺序统计算法，以及对贪心算法元素的讨论。此书还介绍了对强连通子图算法正确性的证明，对哈密顿回路和子集求和问题的NP完全性的证明等内容。全书提供了900多个练习题和思考题以及叙述较为详细的实例研究。&quot;&#125;,</span><br><span class="line">    &#123;&apos;title&apos;:&quot;计算机程序的构造和解释&quot;,</span><br><span class="line">    &apos;url&apos;:&quot;https://book.douban.com/subject/1148282/&quot;,</span><br><span class="line">    &apos;introduction&apos;:&quot;《计算机程序的构造和解释(原书第2版)》1984年出版，成型于美国麻省理工学院(MIT)多年使用的一本教材，1996年修订为第2版。在过去的二十多年里，《计算机程序的构造和解释(原书第2版)》对于计算机科学的教育计划产生了深刻的影响。第2版中大部分重要程序设计系统都重新修改并做过测试，包括各种解释器和编译器。作者根据其后十余年的教学实践，还对其他许多细节做了相应的修改。&quot;&#125;,</span><br><span class="line">    </span><br><span class="line">]</span><br><span class="line">for i in range(len(datas)):</span><br><span class="line">    es.index(index = &apos;book&apos;,doc_type = &apos;computer&apos;,id = i+1,body = datas[i])</span><br></pre></td></tr></table></figure><p>index()方法可以完成两个操作，如果数据不存在，那就插入数据；如果数据已经存在，那就更新数据。</p><h3 id="get-按ID查询"><a href="#get-按ID查询" class="headerlink" title="get()按ID查询"></a>get()按ID查询</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result= es.get(index=&apos;book&apos;,doc_type=&apos;computer&apos;,id =1)</span><br><span class="line">print(result[&apos;_source&apos;])</span><br></pre></td></tr></table></figure><h3 id="search-实现全文检索"><a href="#search-实现全文检索" class="headerlink" title="search()实现全文检索"></a>search()实现全文检索</h3><p>对于中文，我们要安装一个中文分词插件<a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">elasticsearch-analysis-ik</a>。可以使用elastic的另一个命令行工具elastisearch-plugin来安装，要确保版本号一致。进入elastic的目录下，执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.0/elasticsearch-analysis-ik-6.3.0.zip</span><br></pre></td></tr></table></figure><p>注意将<code>6.3.0</code>替换为自己的版本号。安装成功后，重启elasticsearch，就会自动加载这个中文分词插件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">es = Elasticsearch()</span><br><span class="line">mapping = &#123;</span><br><span class="line">    &apos;properties&apos;: &#123;</span><br><span class="line">        &apos;title&apos;: &#123;</span><br><span class="line">            &apos;type&apos;: &apos;text&apos;,</span><br><span class="line">            &apos;analyzer&apos;: &apos;ik_max_word&apos;,</span><br><span class="line">            &apos;search_analyzer&apos;: &apos;ik_max_word&apos;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">result = es.indices.put_mapping(index=&apos;news&apos;, doc_type=&apos;politics&apos;, body=mapping)</span><br></pre></td></tr></table></figure><p>指定使用中文分词器，如果不指定默认使用英文分词器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dsl = &#123;</span><br><span class="line">    &apos;query&apos;: &#123;</span><br><span class="line">        &apos;match&apos;: &#123;</span><br><span class="line">            &apos;introduction&apos;: &apos;计算机&apos;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">result = es.search(index=&apos;news&apos;, doc_type=&apos;politics&apos;, body=dsl)</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html" target="_blank" rel="noopener">全文搜索引擎 Elasticsearch 入门教程—–阮一峰</a></li><li><a href="https://elasticsearch-py.readthedocs.io/en/master/" target="_blank" rel="noopener">Python Elasticsearch文档</a></li><li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/running-elasticsearch.html" target="_blank" rel="noopener">Elasticsearch官方文档</a></li><li><a href="https://cuiqingcai.com/6214.html" target="_blank" rel="noopener">Elasticsearch基本介绍及其与Python的对接实现–崔庆才</a></li><li><a href="https://www.jianshu.com/p/914f102bc174" target="_blank" rel="noopener">Elasticsearch搜索中文分词优化</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Elasticsearch是一个开源的搜索引擎框架。&lt;/p&gt;
    
    </summary>
    
      <category term="web搜索" scheme="http://yoursite.com/categories/web%E6%90%9C%E7%B4%A2/"/>
    
    
      <category term="Elasticsearch" scheme="http://yoursite.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu服务器遇到的一些问题</title>
    <link href="http://yoursite.com/2019/03/07/Ubuntu%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2019/03/07/Ubuntu服务器遇到的一些问题/</id>
    <published>2019-03-07T11:53:00.000Z</published>
    <updated>2019-03-12T06:13:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>记录Ubuntu服务器遇到的一些问题。</p><a id="more"></a> <h2 id="linux服务器连不上网"><a href="#linux服务器连不上网" class="headerlink" title="linux服务器连不上网"></a>linux服务器连不上网</h2><ol><li><p>先检查网线是否插好了，若网线口发亮才是插好。检查电脑是否能<code>ping</code>通局域网的其他电脑。</p><ul><li>查看其他电脑的ip地址<br><code>ifconfig | grep inet</code></li><li>ping其他电脑的IP地址<br><code>ping 10.112.0.1</code><br>如果可以ping通其他电脑，再检查下一步。</li></ul></li><li><p>可以ping通其他电脑，但<code>ping 10.3.8.211</code>校园网网关失败。这时可能是路由出错，查看服务器的路由是否正确。</p><ul><li>查看比较服务器与可以正常联网的电脑的路由。<br><code>route -n</code></li><li>添加正确的默认路由。<br><code>route add default gw 10.112.0.1</code></li><li>检查能否连接到校园网。<br><code>ping 10.3.8.211</code><br>Ubuntu配置路由参见: <a href="https://blog.51cto.com/solin/1900865" target="_blank" rel="noopener">ubuntu配置静态路由及重启生效</a></li></ul></li><li><p>连接到校园网，但是<code>ping www.baidu.com</code>失败。服务器ping不通域名，但可以ping通百度的ip地址<code>112.34.112.40</code>。这是服务器的DNS配置出错了，无法解析域名。</p><ul><li><p>修改文件<code>/etc/resolv.conf</code>，必须有sudo权限。<br><code>sudo vim /etc/resolv.conf</code></p></li><li><p>添加以下内容<br><code>nameserver 8.8.8.8</code></p></li><li><p>重启网络使修改立即生效。<br><code>sudo /etc/init.d/networking restart</code></p></li><li><p>这时应该能ping通百度了。</p><p>重启电源后，以上方法会被清除而失效，导致开机后需要重新配置。有效的方法是卸载开机重写<code>/etc/resolv.conf</code>的<code>resolvconf</code>，执行命令<br><code>sudo apt-get autoremove resolvconf</code><br>配置域名解析参见：<a href="https://blog.csdn.net/danielpei1222/article/details/65452451" target="_blank" rel="noopener">Ubuntu 无法解析域名</a></p></li></ul></li></ol><h2 id="不能通过Xshell或ssh命令连接到服务器"><a href="#不能通过Xshell或ssh命令连接到服务器" class="headerlink" title="不能通过Xshell或ssh命令连接到服务器"></a>不能通过Xshell或ssh命令连接到服务器</h2><ol><li>检查是否安装了<code>ssh-server</code>服务。<br><code>ps -e | grep ssh</code><ul><li>若没有安装，使用以下命令安装：<br><code>sudo apt-get install openssh-server</code></li></ul></li><li>若安装了<code>ssh-server</code>服务，检查ssh服务是否打开。需要sudo权限<ul><li>检查ssh服务状态<br><code>service sshd status</code><br>或<br><code>/etc/init.d/ssh status</code></li><li>开启ssh服务<br><code>service sshd start</code><br>或<br><code>/etc/init.d/ssh start</code></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录Ubuntu服务器遇到的一些问题。&lt;/p&gt;
    
    </summary>
    
      <category term="技术资料" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E8%B5%84%E6%96%99/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
      <category term="服务器" scheme="http://yoursite.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>pytorch学习笔记</title>
    <link href="http://yoursite.com/2019/03/05/pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/03/05/pytorch学习笔记/</id>
    <published>2019-03-05T01:27:14.000Z</published>
    <updated>2019-07-07T07:09:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>这里是pytorch学习笔记。</p><a id="more"></a> <h2 id="创建操作"><a href="#创建操作" class="headerlink" title="创建操作"></a>创建操作</h2><h3 id="torch-randn"><a href="#torch-randn" class="headerlink" title="torch.randn()"></a>torch.randn()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randn(*size,out = None)</span><br></pre></td></tr></table></figure><ul><li>输入：<ul><li>size(int)：指定了输出张量的形状</li></ul></li><li>输出：输出结果为张量</li><li>作用：返回一个张量，从标准正态分布中抽取一组随机数。形状由*size决定</li></ul><h2 id="张量维度操作"><a href="#张量维度操作" class="headerlink" title="张量维度操作"></a>张量维度操作</h2><h3 id="转置：transpose"><a href="#转置：transpose" class="headerlink" title="转置：transpose"></a>转置：transpose</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.transpose(input,dim0,dim1)</span><br></pre></td></tr></table></figure><ul><li>参数：<ul><li>input: 输入张量，可以是二维及二维以上的张量</li><li>dim0,dim1: 要转置的两个维度。</li></ul></li><li>作用： 返回输入矩阵的转置。一次只能转置张量的两个维度。输出张量与输入张量共享内存，同步改变。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.t(tensor)</span><br></pre></td></tr></table></figure><p>输入一个二维张量（矩阵），并转置0,1维。可以看做函数<code>torch.transpose(input,0,1)</code>的简写函数。<br>比较下<code>transpose</code>与<code>view</code>这两个函数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; a = torch.randn(2,3,5)</span><br><span class="line">&gt;&gt; b = torch.transpose(a,1,2)</span><br><span class="line">&gt;&gt; c = a.view(2,5,3)</span><br><span class="line">&gt;&gt; print(a)</span><br><span class="line">tensor([[[ 0.9926, -0.1669, -1.6571, -0.2730, -0.1313],</span><br><span class="line">         [ 0.9811, -1.9854,  1.5519,  0.1383,  1.4571],</span><br><span class="line">         [ 0.8221, -1.1283, -0.7675, -2.0497,  0.4748]],</span><br><span class="line"></span><br><span class="line">        [[ 0.1594,  0.7166, -0.2603,  1.1027,  1.5283],</span><br><span class="line">         [-0.7652, -1.4711,  0.5077,  0.6639,  0.0374],</span><br><span class="line">         [ 1.8121, -1.4864, -2.9863, -0.5769, -0.2915]]]) </span><br><span class="line">&gt;&gt; print(b)</span><br><span class="line">tensor([[[ 0.9926,  0.9811,  0.8221],</span><br><span class="line">         [-0.1669, -1.9854, -1.1283],</span><br><span class="line">         [-1.6571,  1.5519, -0.7675],</span><br><span class="line">         [-0.2730,  0.1383, -2.0497],</span><br><span class="line">         [-0.1313,  1.4571,  0.4748]],</span><br><span class="line"></span><br><span class="line">        [[ 0.1594, -0.7652,  1.8121],</span><br><span class="line">         [ 0.7166, -1.4711, -1.4864],</span><br><span class="line">         [-0.2603,  0.5077, -2.9863],</span><br><span class="line">         [ 1.1027,  0.6639, -0.5769],</span><br><span class="line">         [ 1.5283,  0.0374, -0.2915]]]) </span><br><span class="line">&gt;&gt; print(c)</span><br><span class="line">tensor([[[ 0.9926, -0.1669, -1.6571],</span><br><span class="line">         [-0.2730, -0.1313,  0.9811],</span><br><span class="line">         [-1.9854,  1.5519,  0.1383],</span><br><span class="line">         [ 1.4571,  0.8221, -1.1283],</span><br><span class="line">         [-0.7675, -2.0497,  0.4748]],</span><br><span class="line"></span><br><span class="line">        [[ 0.1594,  0.7166, -0.2603],</span><br><span class="line">         [ 1.1027,  1.5283, -0.7652],</span><br><span class="line">         [-1.4711,  0.5077,  0.6639],</span><br><span class="line">         [ 0.0374,  1.8121, -1.4864],</span><br><span class="line">         [-2.9863, -0.5769, -0.2915]]])</span><br></pre></td></tr></table></figure><p>可以看到:二者得到的结果并不相同。<code>transpose</code>是进行转置操作。<code>view</code>对张量整形时，张量中元素的顺序保持不变。相当于将这个三维张量按顺序</p><h2 id="torch-Tensor"><a href="#torch-Tensor" class="headerlink" title="torch.Tensor"></a>torch.Tensor</h2><h3 id="torch-manual-seed"><a href="#torch-manual-seed" class="headerlink" title="torch.manual_seed()"></a>torch.manual_seed()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(seed)</span><br></pre></td></tr></table></figure><ul><li>输入：<ul><li>seed(int or long)：设定种子，为int类型或long类型</li></ul></li><li>作用：设定生成随机数的种子。种子相同，生成的随机数就是相同的，实验结果就可以复现。</li></ul><p>参见：<a href="https://cloud.tencent.com/developer/article/1149041" target="_blank" rel="noopener">利用随机数种子来使pytorch中的结果可以复现</a></p><h3 id="view-整形"><a href="#view-整形" class="headerlink" title=".view() 整形"></a>.view() 整形</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor.view(*size)</span><br></pre></td></tr></table></figure><ul><li>输入：<ul><li>*size(int)：指定了输出张量的形状</li></ul></li><li>输出：输出结果为张量</li><li>作用：整形，只改变原张量的形状，形状由*size指定。</li></ul><p>例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; x = torch.randn(5,4)</span><br><span class="line">&gt;&gt; x.size()</span><br><span class="line">torch.Size([5,4]</span><br><span class="line">&gt;&gt; x.view(30)</span><br><span class="line">&gt;&gt; x.size()</span><br><span class="line">torch.Size([20])</span><br><span class="line">&gt;&gt; x.view(1,1,-1) # -1表示该维度由其他的维度推断。</span><br><span class="line">&gt;&gt; x.size()</span><br><span class="line">torch.Size([1, 1, 20])</span><br></pre></td></tr></table></figure><h3 id="torch-cat-连接"><a href="#torch-cat-连接" class="headerlink" title="torch.cat() 连接"></a>torch.cat() 连接</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(inputs,dimension = 0)</span><br></pre></td></tr></table></figure><ul><li>输入：<ul><li>inputs(sequence of Tensors)： 多个Tensor的python序列。 如[tensor1,tensor2…]或(Tensor1，tensor2)</li><li>dimension(int,optional): 沿着该维连接张量序列。默认为0。</li></ul></li><li>作用：在指定维度上，对输入张量序列进行连接操作。</li></ul><p>举个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; impotr torch </span><br><span class="line">&gt;&gt; x = torch.randn(4,3)</span><br><span class="line">&gt;&gt; x.size()</span><br><span class="line">torch.Size([4, 3])</span><br><span class="line">&gt;&gt; y = torch.cat((x,x,x),0)</span><br><span class="line">&gt;&gt; y.size()</span><br><span class="line">torch.Size([12, 3])</span><br><span class="line">&gt;&gt; z = torch.cat((x,x,x),1)</span><br><span class="line">&gt;&gt; z.size() </span><br><span class="line">torch.Size([4, 9])</span><br></pre></td></tr></table></figure><h2 id="torch-optim"><a href="#torch-optim" class="headerlink" title="torch.optim"></a>torch.optim</h2><h3 id="class-torch-optim-SGD-params-lr-momentum-0-weight-decay-0"><a href="#class-torch-optim-SGD-params-lr-momentum-0-weight-decay-0" class="headerlink" title="class torch.optim.SGD(params,lr=,momentum=0,weight_decay=0)"></a>class torch.optim.SGD(params,lr=,momentum=0,weight_decay=0)</h3><ul><li>参数：<ul><li>params： 待优化参数的iterable</li><li>lr(float): 学习率</li><li>momentum(float,可选)： 动量因子，默认为0</li><li>weight_decay(float,可选): 权重衰减，默认为0</li></ul></li><li>作用：实现随机梯度下降算法。</li></ul><p>如何使用optimizer?</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import torch.optim as optim </span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD(model.parameters(),lr = 0.01) #构建一个optimizer,model.parameters()给出了所有要优化的参数</span><br><span class="line">for input,target in dataset:</span><br><span class="line">    optimizer.zero_grad() #清空所有被优化过的Variable的梯度</span><br><span class="line">    output = model(input)</span><br><span class="line">    loss = loss_fn(output,target)</span><br><span class="line">    loss.backward()  #反向传播算法，计算好所有要优化Variable的梯度。</span><br><span class="line">    optimizer.step() #单步优化，基于计算得到的梯度进行参数更新。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里是pytorch学习笔记。&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>Numpy学习笔记</title>
    <link href="http://yoursite.com/2019/02/27/Numpy%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/02/27/Numpy学习笔记/</id>
    <published>2019-02-27T12:33:15.000Z</published>
    <updated>2019-07-22T00:37:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>这里是numpy学习笔记。</p><a id="more"></a> <h3 id="np-copy"><a href="#np-copy" class="headerlink" title="np.copy"></a>np.copy</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.copy(a)</span><br></pre></td></tr></table></figure><p>a为ndarray数组。<a href="https://het.as.utexas.edu/HET/Software/Numpy/reference/generated/numpy.copy.html" target="_blank" rel="noopener">np.copy</a>复制一个与a完全相同的dnarray数组。<br>来看看<code>=</code>与<code>np.copy</code>的区别。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; x = np.array([1,2,3])</span><br><span class="line">&gt;&gt; y = x</span><br><span class="line">&gt;&gt; z = x.copy(x)</span><br><span class="line">&gt;&gt; x[0] = 10</span><br><span class="line">&gt;&gt; x[0] == y[0]</span><br><span class="line">True</span><br><span class="line">&gt;&gt; x[0] == z[0]</span><br><span class="line">False</span><br></pre></td></tr></table></figure><p>对于<code>=</code>，x与y共享同一内存，数据同步改变。一个改变另一个跟着改变。<br>对于<code>np.copy</code>,x与z在不同的内存，数据改变互不影响。</p><h3 id="np-load与np-save"><a href="#np-load与np-save" class="headerlink" title="np.load与np.save"></a>np.load与np.save</h3><p>numpy可以读写磁盘上的二进制数据。为将ndarray数组对象保存到文件，引入了文件格式<code>npy</code>。数组对象ndarray以未压缩的原始二进制格式保存在扩展名为<code>.npy</code>的文件中。</p><ul><li><strong>np.save(file,array)</strong><ol><li>作用： 将数组以二进制格式保存到扩展名为<code>npy</code>的文件中。</li></ol></li><li><strong>np.load(file)</strong><ol><li>作用： 从<code>.npy</code>文件中读取二进制数据还原为数组。<br>举个例子：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np </span><br><span class="line">a = arange(5)</span><br><span class="line">np.save(&apos;a.npy&apos;,a)</span><br><span class="line">b = np.load(&apos;a.npy&apos;)</span><br></pre></td></tr></table></figure></li></ol></li></ul><h3 id="np-full"><a href="#np-full" class="headerlink" title="np.full"></a><a href="https://het.as.utexas.edu/HET/Software/Numpy/reference/generated/numpy.full.html" target="_blank" rel="noopener">np.full</a></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.full(shape,fill_value,dtype)</span><br></pre></td></tr></table></figure><p>作用： 返回一个 给定形状为<code>shape</code>，数据类型为<code>dtype</code>，全都由<code>fill_value</code>填充后的ndarray。</p><h3 id="np-foat32"><a href="#np-foat32" class="headerlink" title="np.foat32"></a>np.foat32</h3><p><code>np.float32(x)</code><br>作用：变换数据类型为float32</p><h3 id="np-pad"><a href="#np-pad" class="headerlink" title="np.pad"></a>np.pad</h3><p><strong>参数解释</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.pad(array, pad_width, mode, **kwargs)</span><br></pre></td></tr></table></figure><ul><li>输入<ul><li><code>array</code> 为待填充的数组</li><li>pad_width 为((before_1,after_1),(before_2,after_2),….,(before_N,after_N))在每个维度前后填充的个数</li><li>mode 常用<code>constant</code>,用常数填充。</li></ul></li><li>返回值： 填充后的ndarray</li></ul><p>举个例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np </span><br><span class="line">a = range(5)</span><br><span class="line"># 在一维数组前后分别填充2,3位数字；填充的数字分别为0,2</span><br><span class="line">ndarray = np.pad(a,(2,3),&apos;constant&apos;,constant_values=(0,2))</span><br><span class="line">print(a)</span><br><span class="line">print(ndarray)</span><br></pre></td></tr></table></figure><p>执行结果为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[0, 1, 2, 3, 4]</span><br><span class="line">[0 0 0 1 2 3 4 2 2 2]</span><br></pre></td></tr></table></figure><h3 id="np-random"><a href="#np-random" class="headerlink" title="np.random"></a>np.random</h3><h4 id="np-random-uniform"><a href="#np-random-uniform" class="headerlink" title="np.random.uniform"></a>np.random.uniform</h4><p><code>np.random.uniform(low = 0,high = 1,size = None)</code><br>作用： 生成一个形状为size的随机数矩阵，每个数从均匀分布的半开半闭区间[low,high)中抽样得到。</p><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul><li><a href="https://docs.scipy.org/doc/numpy/index.html" target="_blank" rel="noopener">Numpy官方手册</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这里是numpy学习笔记。&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Numpy" scheme="http://yoursite.com/tags/Numpy/"/>
    
  </entry>
  
  <entry>
    <title>2018-群星陨落</title>
    <link href="http://yoursite.com/2019/01/16/2018-%E7%BE%A4%E6%98%9F%E9%99%A8%E8%90%BD/"/>
    <id>http://yoursite.com/2019/01/16/2018-群星陨落/</id>
    <published>2019-01-16T12:56:00.000Z</published>
    <updated>2019-07-22T00:35:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>游龙当归海，海不迎我自来也！</p><a id="more"></a> <p>今天是农历12月十一，明天就是爸爸的生日。阳历的2018年已经过去了，但春节还没来呢！研究生一年级的学期期末，我想着回顾一下这一年，看看自己这一年是怎么度过的。2018年，许多了不起的人去世了，因此选了这个小标题。<br>2018年，我大学毕业，顺利通过了研究生复试。考研，是与高考同等级别的考试，不同的是考研没有老师和家长的督促，只得一个人奋战。备战考研初试已经是2017年的往事了，但还是值得一提的。准备初试的小半年里基本上每天泡在图书馆里，坐在某个固定的座位。虽然有时候也会懈怠懒惰，但大部分时间都是在认真地学习。晚上九点半从图书馆出来，我常要绕着学校跑上五公里；回宿舍经过一楼的镜子，我看着自己嘴里念叨着学校的名字。如愿以偿，2018年年初，我查自己的考研初试成绩409，是比高考还令人满意的了。查到成绩后，我欢欣鼓舞了一阵子。</p><h3 id="上半年-本科最后的日子"><a href="#上半年-本科最后的日子" class="headerlink" title="上半年 - 本科最后的日子"></a>上半年 - 本科最后的日子</h3><p>年初，我因为考驾照的缘故住在我姨家里，有了跟亲戚一起生活半个月的机会。亲戚走动的机会不多，平时没有机会去了解他们促进感情，全凭着血缘的纽带联系着。但这次难得地坐在亲戚家里有了不一样的感受，感受到日久生情（可能用词不当，但意思到了呢）。有天中午，我姨有事外出，我跟表妹一块做了午饭，手忙脚乱，做出来的饭味道竟还不错！<br>考过了科二，我便回了家。每年过年都得下一场雪，有到脚踝那么厚，到处都白茫茫的一片。我拿着铲子去屋顶铲雪，花了两个半天，把屋顶上的雪收拾到了院子里。只是那时候竟没有兴致堆个雪人，今天冬天北京一丝雪都没有落，真想回到家能看一场雪啊。<br>高中的班主任还在带着高三的学生，过了年没几天高三的学生便开学了。班主任想着我给高三的同学们聊聊天，说“现在的学生都没有你高三下苦”，我勉强算是个刻苦的笨孩子吧。在老班家里吃了午饭，下午便回到曾经的教室里，跟高三的同学们聊天。时间在一天一天地度过，我们在一步一步地向前走呢！</p><p>大四下，已经没课了，只剩下做毕业设计。我在明德楼B座的人才办找了一份勤工俭学的差事，平常的工作是给老师整理文件，打印，拿快递和打扫卫生。这是段闲适又想着充实的日子，想着好好完成毕业设计，想着去做大学里想做还没做的事，想着去看几本书，想着跟朋友们告别。我每天在老师的办公室里做毕设，中午便在沙发上睡一会，算不上特别努力，只是想在大学最后的几个月里把事情做好一些。办公室的窗口有一些灰尘，窗台上有爬山虎的脚，窗外有许多树。阳光照进来，树影婆娑的，像极了大学最后的这段日子。<br>大四下，我去圣昆仑音乐厅听了音乐会，只听得一半便溜了出来；也在圣昆仑音乐厅看了话剧《蜀道难》，虽然有一些瑕疵，但依然十分精彩，震撼人心，让我领略到了现场话剧的魅力；我常去文理馆三楼找文学类的书，在做毕设的闲暇翻看。读了王小波写给李银河的信，知道爱情会让人牵肠挂肚；读了杨绛先生的散文集，我原先以为散文集是无趣的，但读了杨绛先生的散文集，才体会到朴实文字的动人之处。尤其当读到杨绛先生写文革期间女婿被红卫兵打死，父亲去世却奔丧不成，自己被分配到厕所刷马桶这些情节，就好像在讲述一些生活中的小事。也看到杨绛先生去菜园找钱钟书时流露出的不难察觉的爱意和在苦难中的幽默感。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/9.jpg" alt="杨绛先生和她的女儿钱瑗、丈夫钱钟书" title>                </div>                <div class="image-caption">杨绛先生和她的女儿钱瑗、丈夫钱钟书</div>            </figure>车协是我大学四年最重要的地方吧，也是我大学归属感的来源。在最后这半年里，在周二周四的晚上参加了许多次的体训，周一周三周五也偶尔跟着大家骑车去怪坡。最后还参加了几次小假期的拉练：“放火烧山，牢底坐穿”，黄巢的篝火没有烧起来，但心里的篝火不曾熄灭，"聚是一团火，散作满天星"；“清明拉练”去看了遍野的油菜花，大一第一次参加拉练也是清明拉练呢；五一是药乡选拔，新的远征队又将踩着单车用车轮丈量祖国的大好河山！快要离开的时候，想着要做一些事，比平时更用心些。婷婷提出要办一个车协的"考研、保研、工作交流会"，但她因为要工作提前离校了，我接过这个活，跟车协的伙伴一起办了这个交流会。在北京比赛之前，我想起了前两年给京赛队员加油的火腿肠，今年该是我了吧！大学的许多生活都与车协相关，大学许多朋友都是车协的伙伴。我似乎没给留下些什么，但一同经历就是意义啊！<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/8.jpg" alt="16年黄巢拉练的篝火" title>                </div>                <div class="image-caption">16年黄巢拉练的篝火</div>            </figure>大学最后的尾声是在拍毕业照和送老会中进行的。终于穿上那一身幼时憧憬的毕业服，拍学院里的毕业照，拍班级里的毕业照。也拍协会那一群人的毕业照，小树林，南门外，臧克家和闻一多的雕像旁，曾经朝夕相处，今日便要离之而去。在车协的送老会上，我以为我不会哭的，两年远征都没有哭，只是未曾坦开心扉，在送老会上，平时话不多的我也不知哪来那么多的话和眼泪。嘿，毕业快乐！！！<h3 id="暑期-目的地在尼泊尔的新藏线"><a href="#暑期-目的地在尼泊尔的新藏线" class="headerlink" title="暑期 - 目的地在尼泊尔的新藏线"></a>暑期 - 目的地在尼泊尔的新藏线</h3><p>大学毕业后，趁着年轻力壮去骑了新藏线。时间跨度是7月21日到8月28日近四十天的时间。先坐火车从北京到叶城，中途在吐鲁番转车，从祖国的东边到最西边。骑车的路段是“喀什-萨嘎县-吉隆口岸-加德满都”。返程是费尽周折的，先坐吉普车从加德满都回国到基隆口岸，再做大巴车到日喀则，再坐火车“日喀则-青海西宁-陕西西安-山西临汾”，从陆地回家的成本虽然只有机票钱的一半，但花了整整五天。<br>之前有过骑车出国门的想法，但不是十分笃定的。旺哥在论坛上发帖征新藏线的队友，我毅然地回了贴。原先计划的新藏线小队有我、旺哥和宇哥三个人，后来宇哥因为入职没能成行。新藏线是一条比川藏线要难的路线，我每天晚上跑步五公里来做体力储备，有时候也偷懒；在美骑网上看别人的路书和骑行游记，做了自己的路书和攻略。特地回老家办了护照和边防证，办边防证的过程费了一些周折，办边防证需要一份小领导写个名字，但他又不来上班，花了几天才终于办好了。又在北京的尼泊尔大使馆办了签证，准备地差不多只等出发了。</p><p>7月21日，坐火车从北京出发，坐了38个小时的硬座到了吐鲁番，再坐19个小时的硬座到新疆喀什地区喀什市跟旺哥会合。全国用的都是北京时间，因此到晚上九点，喀什的天还是亮的。略作修整，便到了开始每天的骑行。第一天的骑行就差点要了老命，一是第一天的路程远，又有很大的逆风，晚上到宾馆已经累地快虚脱了。新藏线前几天的路是比较平坦的，海拔上升不太大。骑车的第四天我遇到一个致命的问题，差点导致我的新藏线骑行半路夭折。我自行车后轮的花鼓在一个小村子阿克美其特村里断了，小村子里连去城里的公交车都没有，完全不可能修理。我跟旺哥商议，旺哥继续骑车到下个地点补给更方便的库地达坂等我，我返回叶城去修车。我拆了自行车的后轮，村里的村干部开车送我到了镇上，我在镇上坐了个出租车返回了叶城。为了节省时间，我没去更远更大的喀什市去修理，只在叶城找人修理，这给我后来的不幸埋下了隐患。在叶城找了一个不靠谱的单车修理店给我修理后轮，信誓旦旦地坐车回到阿克美其特村，结果骑了不到二公里，自行车的后轮又坏了，是根本没有修理好。悔不该杀那华佗！我终于下定决心老老实实地去喀什找捷安特专卖店买了轮子，又是艰难的交通，先在路边搭回城里的顺风车，再坐火车到喀什，买好轮子，再坐火车返回叶城，最后搭了许多车（私家车，大卡车）终于回到阿克美其特村。我修理好车，战战兢兢的出发了，小心翼翼地，生怕轮子再出幺蛾子。所幸后面一路上都没再出什么大问题，这一次就够我折腾的了，反反复复弄弄三天。以致于我想要不车子也不要了，买张票回家吧！现在回过头来看，所幸坚持了下来。<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/7.jpg" alt="](/images/10.jpg " 阿克美其特村前面的达坂")因为修车我耽误了三天行程，旺哥还在前面等着我。为了追上旺哥，不让他多等，我搭了一个大卡车从麻扎兵站到四十里营方跟旺哥会合，这是一天的行程。在红柳滩我和旺哥找到了新的伙伴，贤弟和邓翱，我们变成了四人小队。从红柳滩往后的三百公里是无人区，但还有人烟，是一段可怕的路。骑友中流传着有些骑友没能赶到住宿点，在野外扎营被狼群吃掉的传说，不知真假。进无人区前一天的晚上，我如临大敌，把驼包收拾好，买好水和补给，第二天早早地就出发了。四人小队顺利地走过了无人区，无人区大多荒无人烟，是野生动物被不断蚕食的栖息地。新藏线比川藏线更难，因为新藏线整体海拔高，空气稀薄；而且人烟稀少，缺乏物资补给；再加上时不时的逆风和鬼见愁的上坡、高耸入云的达坂；新藏线这条路想着一辈子走一次就够了，打死不想再煎熬一次了。但新藏线有着她的魅力，荒芜广袤而静默无声的沙漠，精致如翡翠般的湖泊，奔跑的藏羚羊和黄羊，让人敬畏自然；世界上海拔最高的公路，让人想要去挑战和完成，走完新藏线后，有油然而生的骄傲。![" title="骑行在新藏线上">                </div>                <div class="image-caption">骑行在新藏线上</div>            </figure>新藏线广袤荒芜，很少有高的树，当你看到高大的杨树和绿色的植物，就说明附近有水源，此处有人烟。新藏线上是一条连接新疆与西藏的纽带，有许多跑新藏线的大卡车司机。搭车的时候跟几位司机聊天，司机师傅大多是山西河南的，汉族人多，藏族少。在新藏线上跑大卡车，就是在拿命挣钱，高原反应和疲劳驾驶，一个不小心就是车毁人亡。新藏线路边会常看得到翻倒在路边的大卡车，有的男人带着妻子来跑车，出了事一家子就没了，剩个孩子跟着爷爷奶奶。新藏线有除了踩单车的，还有骑摩托车的，自驾游的。常看得到自驾游的大妈披着丝巾拍照。封路的时候，自驾游的车夹杂着拉水泥拉货的大卡车长长地排着队。一路上的比较大的客栈旅店，大都是汉族人开的，四川人很多，四川人勤劳敢拼，新疆西藏到处可见到他们的身影。新藏线这条长长的路上，整整齐齐训练有素的军车是一道靓丽的风景，让人感叹“好男儿就要当兵，保家卫国”。新藏线上，有人的地方就有众生相。<br>到了萨嘎县之后，我们四人要分道扬镳了，我一路出吉隆口岸到加德满都，他们三人一路。旺哥先去珠峰大本营再去拉萨，邓翱和贤弟先去珠峰大本营再去加德满都。萨嘎县到吉隆县的路是非常难走的，没有硬实的柏油路，只有下雨后泥泞的泥路。十米宽的水坑，我脱了鞋子挂在车把上，推着车趟过去。泥泞的路，一脚一脚的踩踏着，车轮上滚满了泥巴，像是炸酥肉前给肉裹上厚厚的面。顶着下午刮个不停的巨大的逆风，长长的上坡，我再也没有了绝不推车的坚持。遇到难爬的上坡，就下来推着车走一段再骑车。大风和泥巴路，骑了一整天只走了五十公里，眼看就要露宿野外而帐篷早寄走了，终于看到一个大大的施工营地，像是溺水的人抓住一根救命稻草。营地里七八个西安的爷们收留了我一宿，度过了危机。到了基隆口岸，我换好尼币，经过中国海关，出了国门。尼泊尔的路才是真的烂路，石头路，泥路，山体滑坡封路都是家常便饭，偶尔能看到一段柏油路便开心地不行。尼泊尔的路是不推荐骑自行车的。尼泊尔是山地里的国家，较大的城镇都分布在平坦的河谷地。我买了尼泊尔的电话卡，但是用不了网络，不能看谷歌地图。我只能一边走，一边用蹩脚的英语问路“这条路是到加德满都吗？”；尼泊尔年轻人大多会说英语，偶尔几个会说汉语。在烂路里走了两天，我他娘的终于到了加德满都，在泰米尔区见到了中国人和中国店铺，激动地不行。只要有出发的勇气，就一定会到达！我终于到了加德满都！<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/11.jpg" alt="在山坡上俯瞰加德满都" title>                </div>                <div class="image-caption">在山坡上俯瞰加德满都</div>            </figure>新藏线一路上盖了一些邮戳，但并不多。骑车的间隙，抽空给15和16远征队的队友和一些老友寄去了明信片，现在有些明信片寄到了，有些寄丢了。我寄给自己的丢在路上了，就让他代替我在路上飘荡吧！骑完新藏线是一件了不起的事，是一件有意义的事。</p><h3 id="下半年-研究生的日子"><a href="#下半年-研究生的日子" class="headerlink" title="下半年 - 研究生的日子"></a>下半年 - 研究生的日子</h3><p>暑假，在去新藏线之前来了读研的学校上了三周的暑期课程，《机器学习》和《凸优化》。9月初开学正式开始了研究生生活。之前我有一个错误的认识，认为研究生生活应该完全舍弃掉自行车，因为之前骑车太多了吧。后来，我认识到生活需要balance，不能只是学习，要让骑车和娱乐成为生活里积极的一部分。来了北京之后，出去玩的次数并不多。训超骑车从济南到北京，来我宿舍住了一晚，我跟他一块去了故宫。国庆节那天，旺哥来北京转车，我和训超早早地去看升旗，给旺哥接风洗尘。后来约着在北京读书工作的高中同学聚了一次。周末骑了两次车，去了卢沟桥和香山公园旁的西山国家森林公园。<br>研一上，还有一些课要修。除了上课，其他时间是待在实验室里，看论文，写代码。前期，感觉有许多需要学习的东西，总能早早地起床。后来感觉不到自己的进步，有些陷入迷茫，不知道该做些什么，就失去了劲头，起床时间晚了许多。我找了一个辅导考研专业课的差事，每周末辅导一个半小时，《通信原理》已经大半年没看过了，但上手简单看一遍就能想起来那些知识点。妈妈生日那天，我买了一只天鹅项链做生日礼物。弟弟生日那天，我给他发了红包，他没领说自己有钱。爸爸今天生日，我鼓动身边的朋友给老爸发了祝福的短信。<br>2019年，希望可以更加勇敢和更加积极地面对生活里的变化。你好，2019！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;游龙当归海，海不迎我自来也！&lt;/p&gt;
    
    </summary>
    
      <category term="年度总结" scheme="http://yoursite.com/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="年度总结" scheme="http://yoursite.com/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
      <category term="生活记录" scheme="http://yoursite.com/tags/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
</feed>
