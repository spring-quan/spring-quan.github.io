<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>spring&#39;s Blog</title>
  
  <subtitle>æ¸¸é¾™å½“å½’æµ·ï¼Œæµ·ä¸è¿æˆ‘è‡ªæ¥ä¹Ÿã€‚</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-10-23T06:22:31.503Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>spring</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>è®ºæ–‡ç¬”è®°ï¼šã€Š(BiDAF)Bi-Directional Attention Flow for Machine Comprehensionã€‹</title>
    <link href="http://yoursite.com/2019/10/23/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%9A%E3%80%8A-BiDAF-Bi-Directional-Attention-Flow-for-Machine-Comprehension%E3%80%8B/"/>
    <id>http://yoursite.com/2019/10/23/è®ºæ–‡ç¬”è®°ï¼šã€Š-BiDAF-Bi-Directional-Attention-Flow-for-Machine-Comprehensionã€‹/</id>
    <published>2019-10-23T01:48:41.000Z</published>
    <updated>2019-10-23T06:22:31.503Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ã€æ¥æºã€‘ï¼šICLR2017<br>ã€é“¾æ¥ã€‘ï¼š<a href="https://arxiv.org/abs/1611.01603" target="_blank" rel="noopener">https://arxiv.org/abs/1611.01603</a><br>ã€ä»£ç ã€æ•°æ®é›†ã€‘ï¼š <a href="https://github.com/allenai/bi-att-flow" target="_blank" rel="noopener">https://github.com/allenai/bi-att-flow</a></p></blockquote><a id="more"></a><p>è¿™æ˜¯ç”±åç››é¡¿å¤§å­¦å’Œè‰¾ä¼¦äººå·¥æ™ºèƒ½ç ”ç©¶æ‰€å‘è¡¨çš„è®ºæ–‡ã€‚è‰¾ä¼¦äººå·¥æ™ºèƒ½ç ”ç©¶æ‰€æ˜¯å¤§åé¼é¼çš„å¾®è½¯è”åˆåˆ›å§‹äººä¿ç½—Â·è‰¾ä¼¦åˆ›å»ºçš„ã€‚<br>è¿™æ˜¯ä¸€ç¯‡ç»å…¸çš„è®ºæ–‡ï¼Œæˆªè‡³ç›®å‰è¢«å¼•æ¬¡æ•°é«˜è¾¾678æ¬¡ã€‚è®ºæ–‡æœ€å¤§çš„è´¡çŒ®æ˜¯åœ¨é˜…è¯»ç†è§£ä»»åŠ¡ä¸­æå‡ºäº†åŒå‘attentionæœºåˆ¶ï¼ˆBiDirectional attention flow, BiDAFï¼‰ï¼ŒBiDAFä¹Ÿå¯ä»¥ç”¨åœ¨å…¶ä»–ä»»åŠ¡ä¸­ã€‚</p><h2 id="é˜…è¯»ç†è§£ä»»åŠ¡å®šä¹‰"><a href="#é˜…è¯»ç†è§£ä»»åŠ¡å®šä¹‰" class="headerlink" title="é˜…è¯»ç†è§£ä»»åŠ¡å®šä¹‰"></a>é˜…è¯»ç†è§£ä»»åŠ¡å®šä¹‰</h2><p>ç»™å®šæ–‡ç« context $\lbrace{x_1,x_2,â€¦,x_T}\rbrace$åŠquery $\lbrace{q_1,q_2,â€¦,q_J}\rbrace$ï¼Œåœ¨æ–‡ç« contextä¸­æ‰¾åˆ°æŸä¸ªæ®µspanä½œä¸ºqueryçš„ç­”æ¡ˆã€‚è¾“å‡ºå…¶å®æ˜¯è¿™ä¸ªspançš„èµ·å§‹åæ ‡å’Œç»“æŸåæ ‡ã€‚</p><h2 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h2><p>è®¾encoderåŒ…å«embeddingå±‚å’ŒBi-LSTMå±‚ï¼Œç»è¿‡encoderåçš„context representationä¸º$H = \lbrace{h_1,h_2,â€¦,h_T}\rbrace$ï¼Œquery representationä¸º$U = \lbrace{u_1,u_2,â€¦,u_J}\rbrace$ã€‚å…¶ä¸­$H \in R^{2d\times  T}, U \in R^{2d\times  J}$ã€‚</p><h3 id="ä¼ ç»Ÿattentionæœºåˆ¶çš„å‡ ä¸ªç‰¹å¾"><a href="#ä¼ ç»Ÿattentionæœºåˆ¶çš„å‡ ä¸ªç‰¹å¾" class="headerlink" title="ä¼ ç»Ÿattentionæœºåˆ¶çš„å‡ ä¸ªç‰¹å¾"></a>ä¼ ç»Ÿattentionæœºåˆ¶çš„å‡ ä¸ªç‰¹å¾</h3><p>å…ˆä»‹ç»ä¼ ç»Ÿattentionçš„è®¡ç®—æ–¹å¼ã€‚åœ¨æ—¶é—´æ­¥tè®¡ç®—ä¼ ç»Ÿattentionæ—¶ï¼Œéœ€è¦ç”¨åˆ°ä¸Šä¸ªæ—¶é—´æ­¥t-1çš„decoder RNNçš„éšè—çŠ¶æ€$s_{t-1}$ã€‚decoder RNNçš„éšè—çŠ¶æ€æ›´æ–°å…¬å¼ä¸ºï¼š$$s_t = f(s_{t-1},y_{t-1},c_t)$$å…¶ä¸­c_tä¸ºcontext vectorï¼Œè®¡ç®—æ–¹å¼ä¸ºï¼š$$c_t = \sum_{i=1}^{T}\alpha_{t,i}h_i$$ $$\alpha_{t,i} = softmax(\beta_{t,i})$$ $$\beta_{t,i} = score(s_{t-1},h_t)$$å…¶ä¸­score(s,h)å‡½æ•°è®¡ç®—sä¸tä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚</p><p>ä»ä¼ ç»Ÿattentionçš„è®¡ç®—æ–¹å¼å¯ä»¥çœ‹å‡ºï¼Œä¼ ç»Ÿattentionæœ‰ä»¥ä¸‹å‡ ä¸ªç‰¹å¾ï¼š</p><ul><li>attentionæƒé‡ç”¨æ¥å°†æ‰€æœ‰çš„context representation $\lbrace{h_1,h_2,â€¦,h_T}\rbrace$æ€»ç»“ä¸ºä¸€ä¸ªå›ºå®šç»´åº¦çš„å‘é‡$c_t$ã€‚<em>è¿™ä¸ªè¿‡ç¨‹ä¸å¯é¿å…åœ°ä¼šå¸¦æ¥ä¿¡æ¯ä¸¢å¤±ã€‚</em></li><li>æ—¶é—´æ­¥tçš„attentionæƒé‡$\alpha_{t_i}$è®¡ç®— ä¾èµ–äºä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„å‘é‡$s_{t-1}$ã€‚<em>è¿™é‡Œå¯ä»¥çœ‹å‡ºï¼Œattentionæƒé‡çš„è®¡ç®—æ˜¯æœ‰è®°å¿†çš„ã€‚</em></li><li>attentionçš„è®¡ç®—æ˜¯å•å‘çš„ã€‚</li></ul><div align="center"><img src="/images/BiDAF.png" width="100%" height="100%"></div><div align="center"><font color="grey" size="2">Fig.1. æ¨¡å‹çš„æ•´ä½“æ¡†æ¶å›¾</font></div><h3 id="åŒå‘attentionæœºåˆ¶"><a href="#åŒå‘attentionæœºåˆ¶" class="headerlink" title="åŒå‘attentionæœºåˆ¶"></a>åŒå‘attentionæœºåˆ¶</h3><p>è®ºæ–‡ä¸­æ¨¡å‹åˆ†ä¸ºäº†6å±‚ï¼Œè¿™é‡Œåªä»‹ç»æœ€å…³é”®çš„ä¸€å±‚ï¼šattention flow layerã€‚è¯¥å±‚çš„è¾“å…¥æ˜¯context representation $H$å’Œquery representation $U$ï¼Œè¾“å‡ºæ˜¯æ„è¯†åˆ°queryçš„context words representation $G$,ä»¥åŠå‰ä¸€å±‚çš„context representationã€‚</p><ol><li><strong>ç›¸ä¼¼åº¦çŸ©é˜µS</strong><br>å…ˆå®šä¹‰ä¸€ä¸ª $H\in R^{2d\times T}$å’Œ $U\in R^{2d\times J}$ä¹‹é—´çš„å…±äº«ç›¸ä¼¼åº¦çŸ©é˜µ$S\in R^{T\times J}$ã€‚å…¶ä¸­$S_{tj}$è¡¡é‡äº†ç¬¬tä¸ªcontext wordä¸ç¬¬jä¸ªquery wordä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚$$S_{tj} = \alpha(H_{:t},U_{:j}) \in R$$ å…¶ä¸­$H_{:t}\in R^{2d}$æ˜¯Hçš„ç¬¬tä¸ªåˆ—å‘é‡ï¼Œ$U_{:j}\in R^{2d}$æ˜¯Uçš„ç¬¬jä¸ªåˆ—å‘é‡ã€‚$\alpha()$æ˜¯ä¸€ä¸ªè®¡ç®—ç›¸ä¼¼åº¦çš„å‡½æ•°ï¼š$$\alpha(h,u) = w_{(S)}[h;u;hÂ·u]$$</li><li><strong>context-to-query attention</strong><br>è¡¨ç¤ºå¯¹äºæ¯ä¸ªcontext wordï¼Œå“ªä¸ªquery wordæ˜¯æœ€ç›¸å…³çš„ã€‚<br>å¯¹äºç¬¬tä¸ªcontext wordï¼Œåœ¨æ‰€æœ‰query words ${q_1,q_2,â€¦,q_J}$ä¸Šçš„attentionæƒé‡ä¸º$a_t\in R^{J}$ï¼Œæœ‰$$\sum_{j}a_{tj} = 1$$<br>attentionæƒé‡$a_t$çš„è®¡ç®—æ–¹å¼ä¸ºï¼š$$a_t = softmax(S_{t:}) \in R^{J}$$ å¯¹äºç¬¬tä¸ªcontext wordçš„attended query vectorä¸º$$\widetilde{U_{:t}} = \sum_{j}a_{tj}U_{:j} \in R^{2d}$$ å¯¹äºæ‰€æœ‰çš„context words ${x_1,x_2,â€¦,x_T}$,åˆ™æœ‰$\widetilde{U} \in R^{2d\times T}$</li><li><strong>query-to-context attention</strong><br>è¡¨ç¤ºå¯¹äºæ¯ä¸ªquery wordsï¼Œå“ªä¸ªcontext wordæ˜¯æœ€ç›¸ä¼¼çš„ï¼Œå¯¹äºå›ç­”queryæœ€é‡è¦ã€‚<br>è®¡ç®—åœ¨æ‰€æœ‰context words ${x_1,â€¦,x_T}$ä¸Šçš„attentionæƒé‡ä¸º $$b = softmax(max_{col}(S)) \in R^{T}$$å…¶ä¸­$max_{col}(S) \in R^{T}$å‡½æ•°è¡¨ç¤ºåœ¨çŸ©é˜µ$S \in R^{T\times J}$çš„åˆ—ä¸Šå–æœ€å¤§å€¼ã€‚<br>åˆ™attended context vectorä¸º$$\widetilde{h} = \sum_{t}b_{t}H_{:t} \in R^{2d}$$ è¿™ä¸ªå‘é‡çš„å«ä¹‰æ˜¯å¯¹äºqueryæ‰€æœ‰é‡è¦çš„context wordsçš„åŠ æƒå’Œã€‚<br>æŠŠ$\widetilde{h}$åœ¨åˆ—ä¸Šå¤åˆ¶Tæ¬¡ï¼Œå¾—åˆ°äº†$\widetilde{H} \in R^{2d\times T}$</li><li><strong>è¾“å‡ºèåˆ</strong><br>æŠŠä¸Šä¸€å±‚çš„context representation $H$å’Œattended vector $\widetilde{H}$å’Œ$\widetilde{U}$æ€»ç»“ç»„åˆèµ·æ¥å¾—åˆ°<em>æ„è¯†åˆ°queryçš„context words representation</em> $G$ï¼Œè®¡ç®—æ–¹å¼ä¸ºï¼š$$G_{:t} = \beta(H_{:t},\widetilde{U_{:t}},\widetilde{H_{:t}}) \in R^{d_{G}}$$ å…¶ä¸­$\beta()$å‡½æ•°å¯ä»¥æ˜¯ä»»æ„ç¥ç»ç½‘ç»œï¼Œæ¯”å¦‚MLPå¤šå±‚æ„ŸçŸ¥æœºã€‚è®ºæ–‡ä¸­é‡‡ç”¨äº†ç®€å•çš„è¿æ¥æ“ä½œï¼Œå°†$\beta()$å‡½æ•°å®šä¹‰ä¸ºï¼š$$\beta(h,\widetilde{h},\widetilde{u}) = [h;\widetilde{u};h \cdot \widetilde{u};h \cdot \widetilde{h}] \in R^{8d\times T}$$</li></ol><p>ä»åŒå‘attentionæœºåˆ¶çš„è®¡ç®—å¯ä»¥çœ‹å‡ºï¼ŒåŒå‘attentionæœºåˆ¶æœ‰ä»¥ä¸‹å‡ ä¸ªç‰¹å¾ï¼š</p><ul><li>ä¸ä¼ ç»Ÿattentionå°†æ‰€æœ‰context representation $\lbrace{h_1,h_2,â€¦,h_T}\rbrace$æ€»ç»“ä¸ºä¸€ä¸ªå›ºå®šç»´åº¦çš„å‘é‡$c_t$ä¸åŒã€‚åŒå‘attentionæœºåˆ¶ä¸ºæ¯ä¸ªæ—¶é—´æ­¥éƒ½è®¡ç®—attentionï¼Œå¹¶å°†attended vector $\widetilde{H}$ã€$\widetilde{U}$å’Œå‰ä¸€å±‚çš„context representation $H$æµåŠ¨åˆ°ä¸‹ä¸€å±‚ã€‚è¿™æ ·å‡å°‘äº†æå‰æ€»ç»“ä¸ºå›ºå®šç»´åº¦çš„å‘é‡å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ã€‚</li><li>è¿™æ˜¯æ— è®°å¿†çš„attentionæœºåˆ¶ã€‚å½“å‰æ—¶é—´æ­¥çš„attentionè®¡ç®—åªå–å†³äºå½“å‰çš„context representation $H$å’Œquery representation $U$ï¼Œè€Œä¸ä¾èµ–äºä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„attentionã€‚ è¿™ç§æ— è®°å¿†çš„attentionæœºåˆ¶å°†<em>attention layer</em>å’Œ<em>model layer</em>åˆ†éš”å¼€ï¼Œè¿«ä½¿<em>attention layer</em>ä¸“æ³¨äºå­¦ä¹ contextä¸queryä¹‹é—´çš„attentionï¼Œè€Œ<em>model layer</em>ä¸“æ³¨äºå­¦ä¹ attention layerè¾“å‡ºå†…éƒ¨ä¹‹é—´çš„è”ç³»ã€‚</li><li>åŒå‘attentionæœºåˆ¶æ˜¯åŒå‘çš„ï¼ŒåŒ…å«query-to-context attentionå’Œcontext-to-query attentionï¼Œå¯ä»¥å½¼æ­¤ä¹‹é—´ç›¸äº’è¡¥å……ã€‚</li></ul><h2 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h2><ul><li><a href="https://allenai.github.io/bi-att-flow/" target="_blank" rel="noopener">BiDAF</a></li><li><a href="https://zhuanlan.zhihu.com/p/53626872" target="_blank" rel="noopener">æœºå™¨é˜…è¯»ç†è§£ä¹‹åŒå‘æ³¨æ„åŠ›æµ||Bidirectional Attention Flow for Machine Comprehension</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;ã€æ¥æºã€‘ï¼šICLR2017&lt;br&gt;ã€é“¾æ¥ã€‘ï¼š&lt;a href=&quot;https://arxiv.org/abs/1611.01603&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/abs/1611.01603&lt;/a&gt;&lt;br&gt;ã€ä»£ç ã€æ•°æ®é›†ã€‘ï¼š &lt;a href=&quot;https://github.com/allenai/bi-att-flow&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/allenai/bi-att-flow&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="è®ºæ–‡" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
      <category term="BiDAF" scheme="http://yoursite.com/tags/BiDAF/"/>
    
      <category term="Machine Comprehension" scheme="http://yoursite.com/tags/Machine-Comprehension/"/>
    
  </entry>
  
  <entry>
    <title>å¯¹è¯ç³»ç»Ÿçš„æ•°æ®é›†</title>
    <link href="http://yoursite.com/2019/09/06/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <id>http://yoursite.com/2019/09/06/å¯¹è¯ç³»ç»Ÿçš„æ•°æ®é›†/</id>
    <published>2019-09-06T02:07:32.000Z</published>
    <updated>2019-09-06T02:11:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>åœ¨è¯»è®ºæ–‡çš„è¿‡ç¨‹ä¸­ï¼Œç§¯ç´¯è®°å½•ä¸€äº›è®ºæ–‡ä¸­ç”¨åˆ°çš„æ•°æ®é›†ï¼Œå¹¶å¯¹æ•°æ®é›†çš„å¤§å°ã€æ ·ä¾‹ã€è·å–é“¾æ¥ä½œç®€å•ä»‹ç»ã€‚</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;åœ¨è¯»è®ºæ–‡çš„è¿‡ç¨‹ä¸­ï¼Œç§¯ç´¯è®°å½•ä¸€äº›è®ºæ–‡ä¸­ç”¨åˆ°çš„æ•°æ®é›†ï¼Œå¹¶å¯¹æ•°æ®é›†çš„å¤§å°ã€æ ·ä¾‹ã€è·å–é“¾æ¥ä½œç®€å•ä»‹ç»ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="å¯¹è¯ç³»ç»Ÿ" scheme="http://yoursite.com/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="å¯¹è¯ç³»ç»Ÿ" scheme="http://yoursite.com/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="æ•°æ®é›†" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>è®ºæ–‡ç¬”è®°ã€ŠBridging the Gap between Training and Inference for Neural Machine Translationã€‹</title>
    <link href="http://yoursite.com/2019/08/02/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%8ABridging-the-Gap-between-Training-and-Inference-for-Neural-Machine-Translation%E3%80%8B/"/>
    <id>http://yoursite.com/2019/08/02/è®ºæ–‡ç¬”è®°ã€ŠBridging-the-Gap-between-Training-and-Inference-for-Neural-Machine-Translationã€‹/</id>
    <published>2019-08-02T06:46:00.000Z</published>
    <updated>2019-08-05T05:14:53.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ã€æ¥æºã€‘ï¼šACL2019<br>ã€é“¾æ¥ã€‘ï¼š<a href="https://arxiv.org/abs/1906.02448" target="_blank" rel="noopener">https://arxiv.org/abs/1906.02448</a><br>ã€ä»£ç ã€æ•°æ®é›†ã€‘ï¼š æ— </p></blockquote><a id="more"></a><p>è¿™ç¯‡è®ºæ–‡ç”±ä¸­ç§‘é™¢å‘è¡¨ï¼Œè·å¾—äº†ACL2019çš„ â€œbest long paperâ€ã€‚</p><h3 id="è¦è§£å†³çš„é—®é¢˜"><a href="#è¦è§£å†³çš„é—®é¢˜" class="headerlink" title="è¦è§£å†³çš„é—®é¢˜"></a>è¦è§£å†³çš„é—®é¢˜</h3><p>åœ¨Neural Machine Translation(NMT)ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹é€šå¸¸é‡‡ç”¨encoder-decoderæ¡†æ¶ï¼ŒåŸºäºRNN æˆ– CNN æˆ–attentionã€‚å‡è®¾è¾“å…¥ä¸º$X = \lbrace{x_1,x_2,â€¦,x_m}\rbrace$ï¼ŒçœŸå®è¾“å‡ºä¸º$Y = \lbrace{y_1^*,y_2^*,â€¦,y_n^*}\rbrace$ï¼Œé¢„æµ‹è¾“å‡ºä¸º$Yâ€™ = \lbrace {y_1â€™,y_2â€™,â€¦,y_mâ€™}\rbrace$ã€‚</p><p>ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ï¼šdecoderä¼šä¸€ä¸ªè¯ä¸€ä¸ªè¯åœ°ç”Ÿæˆæ•´ä¸ªå›å¤ã€‚åœ¨trainé˜¶æ®µï¼Œåœ¨æ—¶é—´æ­¥tç”Ÿæˆ$y_tâ€™$æ—¶ï¼Œdecoderä¼šæ ¹æ®ä¹‹å‰çœŸå®çš„è¯$\lbrace{y_1^*,y_2^*,â€¦,y_{t-1}^*}\rbrace$æ¥é¢„æµ‹$y_tâ€™$ã€‚åœ¨inferé˜¶æ®µï¼Œç”±äºä¸å¯èƒ½çŸ¥é“çœŸå®è¾“å‡ºï¼Œåœ¨æ—¶é—´æ­¥ç”Ÿæˆ$y_tâ€™$æ—¶ï¼Œdecoderä¼šæ ¹æ®ä¹‹å‰é¢„æµ‹çš„è¯$\lbrace{y_1â€™,y_2â€™,â€¦,y_{t-1}â€™}\rbrace$æ¥é¢„æµ‹$y_tâ€™$ã€‚<br>å¯ä»¥çœ‹åˆ°trainé˜¶æ®µä¸inferé˜¶æ®µæ‰€ä¾æ®çš„è¯æ˜¯ä¸åŒçš„ï¼Œtrainé˜¶æ®µå’Œinferé˜¶æ®µé¢„æµ‹çš„è¯$y_tâ€™$æ¥è‡ªä¸¤ä¸ªä¸åŒçš„æ¦‚ç‡åˆ†å¸ƒï¼Œåˆ†åˆ«æ˜¯æ•°æ®åˆ†å¸ƒ(data distribution)å’Œæ¨¡å‹çš„åˆ†å¸ƒ(model distribution)ï¼Œè¿™ç§å·®åˆ«ç§°ä¸ºâ€œçˆ†ç‚¸åå·®(exposure bias)â€ã€‚éšç€é¢„æµ‹åºåˆ—çš„é•¿åº¦å¢åŠ ï¼Œé”™è¯¯ä¼šé€æ¸ç´¯ç§¯ã€‚<br>ä¸ºäº†è§£å†³ç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œæ¶ˆé™¤trainé˜¶æ®µå’Œinferé˜¶æ®µçš„è¿™ç§å·®åˆ«ï¼Œä¸€ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ³•æ˜¯ï¼šåœ¨trainé˜¶æ®µï¼ŒdecoderåŒæ—¶æ ¹æ®çœŸå®çš„è¯$\lbrace{y_1^*,y_2^*,â€¦,y_{t-1}^*}\rbrace$å’Œé¢„æµ‹çš„è¯$\lbrace{y_1â€™,y_2â€™,â€¦,y_{t-1}â€™}\rbrace$æ¥ç”Ÿæˆ$y_tâ€™$ã€‚</p><p>ç¬¬äºŒä¸ªé—®é¢˜æ˜¯: NMTæ¨¡å‹é€šå¸¸æœ€ä¼˜åŒ–$Yä¸Yâ€™$ä¹‹é—´çš„äº¤å‰ç†µç›®æ ‡å‡½æ•°æ¥æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œä½†äº¤å‰ç†µå‡½æ•°ä¼šä¸¥æ ¼åŒ¹é…é¢„æµ‹è¾“å‡º$Yâ€™$ä¸çœŸå®çš„è¾“å‡º$Y$ã€‚ä½†åœ¨NMTä»»åŠ¡ä¸­ï¼Œä¸€å¥è¯å¯ä»¥æœ‰å¤šä¸ªä¸åŒä½†åˆç†çš„ç¿»è¯‘ã€‚ä¸€æ—¦é¢„æµ‹è¾“å‡º$Yâ€™$çš„æŸä¸ªè¯ä¸$Y$ä¸åŒï¼Œå°½ç®¡å®ƒæ˜¯åˆç†çš„ï¼Œä¹Ÿä¼šè¢«äº¤å‰ç†µå‡½æ•°çº æ­£ã€‚è¿™ç§æƒ…å†µç§°ä¸ºâ€œè¿‡åº¦çº æ­£çš„ç°è±¡â€ã€‚</p><p>ä¸ºäº†æ¶ˆé™¤trainé˜¶æ®µä¸inferé˜¶æ®µçš„å·®åˆ«ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åœ¨trainé˜¶æ®µåšæ”¹è¿›çš„è§£å†³æ–¹æ¡ˆã€‚é¦–å…ˆï¼Œä»é¢„æµ‹çš„è¯ä¸­é€‰æ‹©oracle word $y_{j-1}^{oracle}$ï¼Œè®¾çœŸå®è¾“å‡ºä¸­ä¸Šä¸€ä¸ªè¯ä¸º$y_{j-1}^{*}$ã€‚æ¥ç€ä»$\lbrace{y_{j-1}^{oracle},y_{j-1}^{*}}\rbrace$ä¸­æŠ½æ ·ä¸€ä¸ªè¯ï¼ŒæŠ½ä¸­$y_{j-1}^{*}$çš„æ¦‚ç‡ä¸º$p$ï¼ŒæŠ½ä¸­$y_{j-1}^{oracle}$çš„æ¦‚ç‡ä¸º$1-p$ã€‚æœ€åï¼Œdecoderæ ¹æ®æŠ½æ ·çš„è¿™ä¸ªè¯æ¥é¢„æµ‹$y_j$ã€‚</p><p>åœ¨trainé˜¶æ®µåˆšå¼€å§‹æ—¶ï¼ŒæŠ½ä¸­çœŸå®çš„è¯$y_{j-1}^{*}$çš„æ¦‚ç‡æ¯”è¾ƒå¤§ï¼Œéšç€æ¨¡å‹é€æ¸æ”¶æ•›ï¼ŒæŠ½ä¸­é¢„æµ‹çš„è¯$y_{j-1}^{oracle}$çš„æ¦‚ç‡å˜å¤§ï¼Œè®©æ¨¡å‹æœ‰èƒ½åŠ›å¤„ç†â€è¿‡åº¦çº æ­£çš„é—®é¢˜â€ã€‚</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/oracle.png" alt="Fig.1 è®ºæ–‡æå‡ºçš„æ–¹æ³•çš„ç»“æ„å›¾" title>                </div>                <div class="image-caption">Fig.1 è®ºæ–‡æå‡ºçš„æ–¹æ³•çš„ç»“æ„å›¾</div>            </figure><h3 id="RNN-based-NMT-Model"><a href="#RNN-based-NMT-Model" class="headerlink" title="RNN-based NMT Model"></a>RNN-based NMT Model</h3><p>NMTä»»åŠ¡å¸¸é‡‡ç”¨encoder-decoderæ¡†æ¶ï¼Œå¯ä»¥åŸºäºRNNæˆ–CNNæˆ–çº¯attentionã€‚è®ºæ–‡æå‡ºçš„æ¶ˆé™¤trainé˜¶æ®µå’Œinferé˜¶æ®µå·®åˆ«çš„æ–¹æ³•ï¼Œå¯ä»¥ç”¨äºä»»ä½•NMTæ¨¡å‹ã€‚è®ºæ–‡ä»¥åŸºäºRNNçš„NMTæ¨¡å‹ä¸ºä¾‹ï¼Œæ¥ä»‹ç»è¿™ç§æ–¹æ³•ã€‚è¿™ä¸€èŠ‚å…ˆä»‹ç»RNN-based NMTæ¨¡å‹ã€‚ä¸‹ä¸€èŠ‚ä»‹ç»NMTæ¨¡å‹å¦‚ä½•ç»“åˆè¿™ç§æ–¹æ³•ã€‚</p><h4 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h4><p>è®°è¾“å…¥ä¸º$X = \lbrace{x_1,x_2,â€¦,x_m}\rbrace$ï¼ŒçœŸå®è¾“å‡ºä¸º$Y = \lbrace{y_1,y_2,â€¦,y_n}\rbrace$ã€‚encoderé‡‡ç”¨bi-GRUåˆ†åˆ«è·å–æ­£å‘å’Œåå‘çš„éšè—çŠ¶æ€$\overrightarrow{h_i},\overleftarrow{h_i}$ã€‚$x_i$çš„embeddingå‘é‡ä¸º$e_{x_i}$ã€‚$$\overrightarrow{h_i} = GRU(e_{x_i},h_{i-1})$$ $$\overleftarrow{h_i} = GRU(e_{x_i},h_{i+1})$$ å°†$\overrightarrow{h_i},\overleftarrow{h_i}$è¿æ¥èµ·æ¥ï¼Œä½œä¸º$x_i$å¯¹åº”çš„éšè—çŠ¶æ€ï¼š$$h_i = [\overrightarrow{h_i},\overleftarrow{h_i}] \tag{1}$$</p><h4 id="attention"><a href="#attention" class="headerlink" title="attention"></a>attention</h4><p>attentionæœºåˆ¶ç”¨æ¥è”ç³»encoderå’Œdecoderï¼Œæ›´å¥½åœ°æ•æ‰source sequenceçš„ä¿¡æ¯ã€‚ä¹Ÿå°±æ˜¯åœ¨æ—¶é—´æ­¥t,é€šè¿‡encoderæ‰€æœ‰çš„éšè—çŠ¶æ€$\lbrace h_1,h_2,â€¦,h_m \rbrace$æ¥è®¡ç®—context vector $c_t$ã€‚è®°decoderä¸Šä¸€æ—¶é—´æ­¥çš„éšè—çŠ¶æ€ä¸º$s_{t-1}$ã€‚ $c_t$æ˜¯encoderæ‰€æœ‰éšè—çŠ¶æ€$\lbrace h_1,h_2,â€¦,h_m \rbrace$çš„åŠ æƒå’Œï¼š$$c_t = \sum_{i=1}^{m}\alpha_{ti}h_i \tag{2}$$ å…¶ä¸­$\alpha_{ti}$æ˜¯attentionæƒé‡ï¼Œè®¡ç®—æ–¹å¼ä¸º:$$\beta_{ti} = v_a^\top tanh(W_as_{t-1} + U_ah_i) \tag{3}$$ $$\alpha_{ti} = softmax(\beta_{ti}) = \frac{exp(\beta_{ti})}{\sum_jexp(\beta_{tj})}$$</p><h4 id="decoder"><a href="#decoder" class="headerlink" title="decoder"></a>decoder</h4><p>decoderé‡‡ç”¨å•å‘GRUçš„å˜ä½“ï¼Œéšè—çŠ¶æ€æ›´æ–°å…¬å¼ä¸º:$$s_t = GRU(s_{t-1},e_{y_{t-1}^*},c_t) \tag{4}$$ æœ€åæ ¹æ®e_{y_{t-1}^*}ï¼Œdecoderçš„éšè—çŠ¶æ€$s_t$ï¼Œå¯¹åº”çš„context vector $c_t$æ¥é¢„æµ‹$y_t$ã€‚ $$o_t = W_og(e_{y_{t-1}^*},s_t,c_t) \tag{5}$$ åœ¨è¯æ±‡è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒä¸ºï¼š$$P_t(y_t = w) = softmax(o_t) \tag{6}$$</p><h3 id="æ–¹æ³•"><a href="#æ–¹æ³•" class="headerlink" title="æ–¹æ³•"></a>æ–¹æ³•</h3><p>ä¸ºäº†æ¶ˆé™¤æˆ–å‡è½»trainé˜¶æ®µå’Œinferé˜¶æ®µçš„å·®åˆ«ï¼Œè®ºæ–‡æå‡º ä»çœŸå®çš„è¯$y_{t-1}*$å’Œ$y_{t-1}^{oracle}$é¢„æµ‹çš„è¯ä¸­æŠ½æ ·ï¼Œdecoderæ ¹æ®æŠ½æ ·çš„è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè¯$y_t$ã€‚ä½¿ç”¨è®ºæ–‡æå‡ºçš„æ–¹æ³•ï¼Œåœ¨æ—¶é—´æ­¥té¢„æµ‹$y_t$åˆ†ä¸ºä¸‰æ­¥ï¼š</p><ol><li>å…ˆä»é¢„æµ‹çš„è¯ä¸­é€‰æ‹©$y_{t-1}^{oracle}$ã€‚ è®ºæ–‡æå‡ºäº†ä¸¤ç§æ–¹æ³•æ¥é€‰æ‹©oracle wordï¼Œåˆ†åˆ«æ˜¯è¯çº§åˆ«çš„æ–¹æ³•å’Œå¥å­çº§åˆ«çš„æ–¹æ³•ã€‚</li><li>ä»$\lbrace{y_{t-1}^{oracle},y_{t-1}*}\rbrace$ä¸­æŠ½æ ·å¾—åˆ°$y_{t-1}$ï¼ŒæŠ½ä¸­$y_{t-1}*$çš„æ¦‚ç‡ä¸º$p$ï¼ŒæŠ½ä¸­$y_{t-1}^{oracle}$çš„æ¦‚ç‡ä¸º$1-p$ã€‚</li><li>ç”¨æŠ½æ ·çš„è¯$y_{t-1}$æ¥æ›¿æ¢å…¬å¼$(4)(5)$ä¸­çš„$y_{t-1}^*$æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ã€‚</li></ol><h4 id="oracle-wordçš„é€‰æ‹©"><a href="#oracle-wordçš„é€‰æ‹©" class="headerlink" title="oracle wordçš„é€‰æ‹©"></a>oracle wordçš„é€‰æ‹©</h4><p>ä¼ ç»Ÿçš„æ–¹æ³•ä¸­ï¼Œdecoderä¼šæ ¹æ®ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çœŸå®çš„$y_{t-1}^*$æ¥é¢„æµ‹$y_t$ã€‚ä¸ºäº†æ¶ˆé™¤trainé˜¶æ®µçš„inferé˜¶æ®µçš„å·®åˆ«ï¼Œå¯ä»¥ä»é¢„æµ‹çš„è¯ä¸­é€‰æ‹©oracle word $y_{t-1}^{oracle}$æ¥ä»£æ›¿$y_{t-1}^*$ã€‚ä¸€ç§æ–¹æ³•æ˜¯æ¯ä¸ªæ—¶é—´æ­¥é‡‡ç”¨è¯çº§åˆ«çš„greedy searchæ¥ç”Ÿæˆoracle wordï¼Œç§°ä¸ºword-level oracle(WO)ï¼Œå¦ä¸€ç§æ–¹æ³•æ˜¯é‡‡ç”¨beam-searchï¼Œæ‰©å¤§æœç´¢ç©ºé—´ï¼Œç”¨å¥å­çº§çš„è¡¡é‡æŒ‡æ ‡(å¦‚ï¼šBLEU)å¯¹beam-searchçš„ç»“æœè¿›è¡Œæ’åºï¼Œç§°ä¸ºsentence-level oracle(SO).</p><h5 id="word-level-oracle"><a href="#word-level-oracle" class="headerlink" title="word-level oracle"></a>word-level oracle</h5><p>é€‰æ‹©$y_{t-1}^{oracle}$æœ€ç®€å•ç›´è§‚çš„æ–¹æ³•æ˜¯ï¼Œåœ¨æ—¶é—´æ­¥t-1ï¼Œé€‰æ‹©å…¬å¼$P_{t-1}$ä¸­æ¦‚ç‡æœ€é«˜çš„è¯ä½œä¸º$y_{t-1}^{oracle}$ï¼Œå¦‚Fig.2æ‰€ç¤ºã€‚ ä¸ºäº†è·å¾—æ›´å¥å£®çš„$y_{t-1}^{oracle}$ï¼Œæ›´å¥½åœ°é€‰æ‹©æ˜¯ä½¿ç”¨<a href="https://www.cnblogs.com/initial-h/p/9468974.html" target="_blank" rel="noopener">gumbel maxæŠ€æœ¯</a>æ¥å†²ç¦»æ•£åˆ†å¸ƒä¸­è¿›è¡ŒæŠ½æ ·ï¼Œå¦‚Fig.3æ‰€ç¤ºã€‚<br>å…·ä½“åœ°è®²ï¼Œå°†gumbel noise $\eta$ä½œä¸ºæ­£åˆ™åŒ–é¡¹åŠ åˆ°å…¬å¼(5)ä¸­çš„$o_{t-1}$ï¼Œå†è¿›è¡Œsoftmaxæ“ä½œå¾—åˆ°$y_{t-1}$çš„æ¦‚ç‡åˆ†å¸ƒã€‚$$\eta = -log(-log(u)) $$ $$\tilde{o_{t-1}} = \frac{o_{t-1} + \eta}{\tau} \tag{7}$$ $$\tilde{P_{t-1}} = softmax(\tilde{o_{t-1}}) \tag{8}$$ å…¶ä¸­å˜é‡$u \sim U(0,1)$æœä»å‡åŒ€åˆ†å¸ƒã€‚$\tau$ä¸ºæ¸©åº¦ç³»æ•°ï¼Œå½“$\tau \to 0$æ—¶ï¼Œå…¬å¼(8)çš„softmax()é€æ¸ç›¸å½“äºargmax()å‡½æ•°ï¼›å½“$\tau \to \infty$æ—¶ï¼Œsoftmax()å‡½æ•°é€æ¸ç›¸å½“äºå‡åŒ€åˆ†å¸ƒã€‚<br>åˆ™$y_{t-1}^{oracle}$ä¸º$$y_{t-1}^{oracle} = y_{t-1}^{WO} =argmax(\tilde{P_{t-1}}) \tag{9}$$éœ€è¦æ³¨æ„çš„æ˜¯gumbel noise $\eta$åªç”¨æ¥é€‰æ‹©oracle wordï¼Œè€Œä¸ä¼šå½±å“trainé˜¶æ®µçš„ç›®æ ‡å‡½æ•°ã€‚</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/word_level_oracle_without_gumbel_noise.png" alt="Fig.2. word level oracle without gumbel noise" title>                </div>                <div class="image-caption">Fig.2. word level oracle without gumbel noise</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/word_level_oracle_with_gumbel_noise.png" alt="Fig.3. word level oracle with gumbel noise" title>                </div>                <div class="image-caption">Fig.3. word level oracle with gumbel noise</div>            </figure><h5 id="sentence-level-oracle"><a href="#sentence-level-oracle" class="headerlink" title="sentence-level oracle"></a>sentence-level oracle</h5><p>ä¸ºäº†é€‰æ‹©sentence-level oracle wordï¼Œé¦–å…ˆè¦è¿›è¡Œbeam-searchè§£ç ï¼Œè®¾beam sizeä¸ºkï¼Œå¾—åˆ°kä¸ªcandidateå¥å­ã€‚åœ¨beam-searchè§£ç çš„è¿‡ç¨‹ä¸­ï¼Œç”Ÿæˆæ¯ä¸ªè¯æ—¶ä¹Ÿåº”ç”¨gumbel maxæŠ€æœ¯ã€‚<br>æ¥ç€ï¼Œå¾—åˆ°kä¸ªcandidateå¥å­åï¼Œç”¨å¥å­çº§è¡¡é‡æŒ‡æ ‡BLEUæ¥ç»™è¿™kä¸ªå¥å­æ‰“åˆ†ï¼Œå¾—åˆ†æœ€é«˜çš„å¥å­ä¸ºoracle sentence $Y^S = \lbrace{y_1^S,y_2^S,..,y_{|y^S|}^S}\rbrace$ã€‚<br>åˆ™æ—¶é—´æ­¥tè§£ç å¯¹åº”çš„oracle word $y_{t-1}^{oracle}$ä¸º$$y_{t-1}^{oracle} = y_{t-1}^{SO} = y_{t-1}^{S} \tag{10}$$ å½“æ¨¡å‹ä»çœŸå®è¾“å‡º$Y$å’Œsentence oracle $Y^S$æŠ½æ ·ï¼Œè¿™æœ‰ä¸€ä¸ªå‰ææ˜¯ï¼Œè¿™ä¸¤ä¸ªåºåˆ—çš„é•¿åº¦éœ€è¦æ˜¯ä¸€è‡´çš„ã€‚ä½†beam-search decodeä¸èƒ½ä¿è¯è§£ç åºåˆ—çš„é•¿åº¦ã€‚ä¸ºäº†ä¿è¯è¿™ä¸¤ä¸ªåºåˆ—é•¿åº¦ä¸€è‡´ï¼Œè®ºæ–‡æå‡ºäº†<em>force decoding</em>çš„è§£å†³æ–¹æ³•ã€‚</p><p><strong>force decoding</strong><br>è®¾çœŸå®è¾“å‡º$Y = \lbrace{y_1,y_2,â€¦,y_n}\rbrace$çš„åºåˆ—é•¿åº¦ä¸ºnã€‚<em>force decoding</em>éœ€è¦è§£ç å¾—åˆ°é•¿åº¦åŒæ ·ä¸ºnçš„åºåˆ—ï¼Œä»¥ç‰¹æ®Šå­—ç¬¦â€EOSâ€ç»“æŸã€‚è®¾beam search decodeæ—¶ï¼Œæ—¶é—´æ­¥tå¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒä¸º$P_t$ã€‚</p><ul><li>å½“$t&lt; n$æ—¶ï¼Œå¯¹äºæ¦‚ç‡åˆ†å¸ƒ$P_t$ï¼Œå³ä½¿å­—ç¬¦â€EOSâ€æ˜¯æ¦‚ç‡æœ€é«˜çš„è¯ï¼Œé‚£ä¹ˆç”Ÿæˆæ¦‚ç‡æ¬¡é«˜çš„è¯ã€‚</li><li>å½“$t = n+1$æ—¶ï¼Œå¯¹äºæ¦‚ç‡åˆ†å¸ƒ$P_{n+1}$ï¼Œå³ä½¿å­—ç¬¦â€EOSâ€ä¸æ˜¯æ¦‚ç‡æœ€é«˜çš„è¯ï¼Œä¹Ÿè¦ç”Ÿæˆâ€EOSâ€ã€‚</li></ul><p>æœçœŸæ˜¯å¼ºåˆ¶ç”Ÿæˆé•¿åº¦ä¸ºnçš„åºåˆ—ã€‚è¿™æ ·beam-search decodeå¾—åˆ°çš„åºåˆ—ä¸çœŸå®è¾“å‡ºåºåˆ—çš„é•¿åº¦å°±æ˜¯ä¸€è‡´çš„ï¼Œéƒ½ä¸ºnã€‚</p><h4 id="é€’å‡æŠ½æ ·"><a href="#é€’å‡æŠ½æ ·" class="headerlink" title="é€’å‡æŠ½æ ·"></a>é€’å‡æŠ½æ ·</h4><p>æ ¹æ®å…¬å¼(9)æˆ–(10)å¾—åˆ°$y_{t-1}^{oracle}$åï¼Œä¸‹ä¸€æ­¥æ˜¯ä»$\lbrace{y_{t-1}^{oracel},y_{t-1}^*}\rbrace$ä¸­æŠ½æ ·ï¼ŒæŠ½ä¸­$y_{t-1}^*$çš„æ¦‚ç‡æ˜¯pï¼ŒæŠ½ä¸­$y_{t-1}^{oracle}$çš„æ¦‚ç‡æ˜¯1-pã€‚åœ¨è®­ç»ƒçš„åˆå§‹é˜¶æ®µï¼Œå¦‚æœè¿‡å¤šåœ°é€‰æ‹©$y_{t-1}^{oracle}$ï¼Œä¼šå¯¼è‡´æ¨¡å‹æ”¶æ•›é€Ÿåº¦æ…¢ï¼›åœ¨è®­ç»ƒçš„åæœŸé˜¶æ®µï¼Œå¦‚æœè¿‡å¤šåœ°é€‰æ‹©$y_{t-1}^*$ï¼Œä¼šå¯¼è‡´æ¨¡å‹åœ¨trainé˜¶æ®µæ²¡æœ‰å­¦ä¹ åˆ°å¦‚ä½•å¤„ç†inferé˜¶æ®µçš„å·®åˆ«ã€‚<br>å› æ­¤ï¼Œå¥½çš„é€‰æ‹©æ˜¯ï¼šåœ¨è®­ç»ƒçš„åˆå§‹é˜¶æ®µï¼Œæ›´å¤§æ¦‚ç‡åœ°é€‰æ‹©$y_{t-1}^*$æ¥åŠ å¿«æ¨¡å‹æ”¶æ•›ï¼Œå½“æ¨¡å‹é€æ¸æ”¶æ•›åï¼Œä»¥æ›´å¤§æ¦‚ç‡é€‰æ‹©$y_{t-1}^{oracle}$ï¼Œæ¥è®©æ¨¡å‹å­¦ä¹ åˆ°å¦‚ä½•å¤„ç†inferé˜¶æ®µçš„å·®åˆ«ã€‚ä»æ•°å­¦è¡¨ç¤ºä¸Šï¼Œæ¦‚ç‡$p$å…ˆå¤§åé€æ¸è¡°å‡ï¼Œ$p$éšç€è®­ç»ƒè½®æ•°$e$çš„å¢å¤§è€Œé€æ¸å˜å°ã€‚$$p = \frac{\mu}{\mu + exp(\frac{e}{\mu})} \tag{11}$$å…¶ä¸­ï¼Œ$\mu$æ˜¯è¶…å‚æ•°ã€‚$p$æ˜¯è½®æ•°$e$çš„å•è°ƒé€’å‡å‡½æ•°ã€‚$e$ä»0å¼€å§‹ï¼Œæ­¤æ—¶ï¼Œ$p=1$ã€‚</p><h4 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h4><p>å°†é‡‡æ ·å¾—åˆ°çš„$y_{t-1}$ä»£æ›¿å…¬å¼(4)-(6)ä¸­çš„$y_{t-1}^*$æ¥é¢„æµ‹$y_t$åœ¨è¯æ±‡è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚é‡‡ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œç›¸å½“äºæœ€å°åŒ–ä»¥ä¸‹ç›®æ ‡å‡½æ•°ï¼š$$L(\theta) = -\sum_{n=1}^{N}\sum_{j=1}^{|y_n|}logP_j^n[y_j^n]$$</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;ã€æ¥æºã€‘ï¼šACL2019&lt;br&gt;ã€é“¾æ¥ã€‘ï¼š&lt;a href=&quot;https://arxiv.org/abs/1906.02448&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/abs/1906.02448&lt;/a&gt;&lt;br&gt;ã€ä»£ç ã€æ•°æ®é›†ã€‘ï¼š æ— &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="è®ºæ–‡" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="ACL2019" scheme="http://yoursite.com/tags/ACL2019/"/>
    
      <category term="Neural Machine Translation" scheme="http://yoursite.com/tags/Neural-Machine-Translation/"/>
    
  </entry>
  
  <entry>
    <title>è®ºæ–‡ç¬”è®°ã€ŠMulti-Level Memory for Task Oriented Dialogsã€‹</title>
    <link href="http://yoursite.com/2019/08/01/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E3%80%8AMulti-Level-Memory-for-Task-Oriented-Dialogs%E3%80%8B/"/>
    <id>http://yoursite.com/2019/08/01/è®ºæ–‡ç¬”è®°ã€ŠMulti-Level-Memory-for-Task-Oriented-Dialogsã€‹/</id>
    <published>2019-08-01T06:14:37.000Z</published>
    <updated>2019-08-01T08:32:54.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ã€æ¥æºã€‘ï¼šNAACL2019<br>ã€é“¾æ¥ã€‘ï¼š<a href="https://arxiv.org/pdf/1810.10647.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1810.10647.pdf</a><br>ã€ä»£ç ã€æ•°æ®é›†ã€‘ï¼š<a href="https://github.com/DineshRaghu/multi-level-memory-network" target="_blank" rel="noopener">https://github.com/DineshRaghu/multi-level-memory-network</a></p></blockquote><a id="more"></a><p>å·²æœ‰å·¥ä½œä¸­ï¼Œç«¯åˆ°ç«¯çš„ä»»åŠ¡å‹å¯¹è¯ç³»ç»Ÿé‡‡ç”¨memory networkæ¥ç»“åˆå¤–éƒ¨çš„çŸ¥è¯†åº“(knowledgt base) å’Œ å¯¹è¯å†å²(context)ã€‚ä¸ºäº†ä½¿ç”¨ä»è·‘ä¸€è¶Ÿ networkï¼Œé€šå¸¸å°†äºŒè€…æ”¾åœ¨åŒä¸€ä¸ªmemoryä¸­ã€‚è¿™æ ·å¸¦æ¥çš„é—®é¢˜æ˜¯ï¼šmemoryå˜å¾—å¤ªå¤§ï¼Œæ¨¡å‹åœ¨è¯»å–memoryæ—¶éœ€è¦åŒºåˆ†å¤–éƒ¨çŸ¥è¯†åº“å’Œå¯¹è¯å†å²ï¼Œå¹¶ä¸”åœ¨memoryä¸Šçš„æ¨ç†å˜å¾—å¾ˆéš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè®ºæ–‡å°†å¤–éƒ¨çŸ¥è¯†åº“å’Œå¯¹è¯å†å²åŒºåˆ†å¼€ï¼Œå¦å¤–ï¼Œå°†å¤–éƒ¨çŸ¥è¯†åº“ä¿å­˜ä¸ºåˆ†å±‚çš„memoryã€‚</p><h3 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h3><p>æ¨¡å‹ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªéƒ¨åˆ†ã€‚ </p><ul><li>åˆ†çº§encoderï¼š<br>  åˆ†åˆ«ç¼–ç å¯¹è¯å†å²ä¸­çš„å¥å­ã€‚</li><li>milti-level memory<br>  ä¿å­˜äº†ç›®å‰ä¸ºæ­¢æ‰€æœ‰çš„queryä»¥åŠå¯¹åº”çš„çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœï¼Œæ˜¯ä»¥åˆ†çº§çš„æ–¹å¼ä¿å­˜åœ¨memoryä¸­çš„ã€‚</li><li>copyæœºåˆ¶å¢å¼ºçš„decoderï¼š<br>  ä»è¯æ±‡è¡¨ä¸­ç”Ÿæˆè¯ï¼Œæˆ–è€…ä»çŸ¥è¯†åº“multi-level memoryä¸­å¤åˆ¶è¯ï¼Œæˆ–è€…ä»å¯¹è¯å†å²(context)ä¸­å¤åˆ¶è¯ã€‚</li></ul><div align="center"><img src="/images/multi-memory-model.jpg" width="150%" height="150%"></div><div align="center"><font color="grey" size="2">Fig.1. æ¨¡å‹çš„æ•´ä½“æ¡†æ¶å›¾</font><br><a href="https://arxiv.org/pdf/1810.10647.pdf" target="_blank" rel="noopener"><font color="grey" size="2">æ¥æº:Revanth Reddy2019</font></a></div><h4 id="åˆ†çº§encoder"><a href="#åˆ†çº§encoder" class="headerlink" title="åˆ†çº§encoder"></a>åˆ†çº§encoder</h4><p>åœ¨ç¬¬tè½®ï¼Œå¯¹è¯å†å²å…±æœ‰2t-1ä¸ªå¥å­$\lbrace{c_1,c_2,â€¦,c_{2t-1}}\rbrace$ï¼Œå…¶ä¸­ç”¨æˆ·å¯¹è¯ä¸ºtè½®ï¼Œå›å¤å¯¹è¯ä¸ºt-1è½®ã€‚ æ¯ä¸ªå¥å­$c_i$éƒ½æ˜¯è¯åºåˆ—$\lbrace{w_{i1},w_{i2},â€¦,w_{im}}\rbrace$ã€‚<br>æ¯ä¸ªå¥å­$c_i$å…ˆç»è¿‡embedding layerå¾—åˆ°è¯å‘é‡è¡¨ç¤ºï¼Œå†ç»è¿‡å•å±‚bi-GRUå¾—åˆ°å¥å­çš„å‘é‡è¡¨ç¤º$\varphi(c_i)$ã€‚$h_{ij}^e$è¡¨ç¤ºè¯$w_{ij}$å¯¹åº”çš„éšè—çŠ¶æ€ã€‚<br>å†å°†$\varphi{c_i}$ç»è¿‡å¦ä¸€ä¸ªå•è¯GRUæ¥å¾—åˆ°contextçš„å‘é‡è¡¨ç¤º$c$ã€‚</p><h4 id="multi-level-memory"><a href="#multi-level-memory" class="headerlink" title="multi-level memory"></a>multi-level memory</h4><p>memoryçš„å…³é”®æ˜¯åˆ†çº§çš„åˆ†ä¸ºä¸‰çº§ï¼šquery $\to$ result $\to$ result keyå’Œresult valueã€‚è§Fig.2ã€‚<br>è®°æœ¬è½®å¯¹è¯ä¹‹å‰æ‰€æœ‰çš„çŸ¥è¯†åº“queryä¸º$q_1,â€¦,q_k$ã€‚æ¯ä¸ªquery $q_i$æ˜¯ä¸€ä¸ª(key,value)å¯¹ï¼Œ$q_i = \lbrace{k_a^{q_i}:v_a^{q_i},0&lt; a&lt; n_{q_i}}\rbrace $ã€‚å…¶ä¸­keyå’Œvalueåˆ†åˆ«å¯¹åº”queryçš„æ§½(slots)å’Œæ§½å€¼ï¼Œ$n_{q_i}$æ˜¯query $q_i$çš„æ§½å€¼ä¸ªæ•°ã€‚<br>ç¬¬jè½®å¯¹è¯ï¼Œç”¨query $q_i$æŸ¥è¯¢çŸ¥è¯†åº“çš„è¿”å›ç»“æœä¸ºresult $r_{ij}$ã€‚$r_{ij}$ä¹Ÿæ˜¯ä¸€ä¸ªkey-valueå¯¹ï¼Œ$r_{ij} = \lbrace{k_a^{r_{ij}}:v_a^{r_{ij}},0&lt; a &lt; n_{r_{ij}}}\rbrace$ã€‚å…¶ä¸­$n_{r_{ij}}$æ˜¯key-valueå¯¹çš„ä¸ªæ•°ã€‚</p><div align="center"><img src="/images/multi-memory.png" width="150%" height="150%"></div><div align="center"><font color="grey" size="2">Fig.2. multi memory</font><br><a href="https://arxiv.org/pdf/1810.10647.pdf" target="_blank" rel="noopener"><font color="grey" size="2">æ¥æº:Revanth Reddy2019</font></a></div>ç¬¬ä¸€çº§memoryæ˜¯queryçš„å‘é‡è¡¨ç¤ºã€‚ $q_i$çš„å‘é‡è¡¨ç¤ºä¸º$q_i^v$ï¼Œ$q_i^v$ä¸ºæ‰€æœ‰values $v_a^{q_i}$çš„è¯è¢‹(bag of words)å‘é‡è¡¨ç¤ºã€‚ç¬¬äºŒçº§memoryæ˜¯resultçš„å‘é‡è¡¨ç¤ºã€‚åŒæ ·åœ°ï¼Œ$r_{ij}$çš„å‘é‡è¡¨ç¤ºä¸º$r_{ij}^v$ï¼Œ$r_{ij}^v$ä¸ºæ‰€æœ‰values $v_a^{r_{ij}}$çš„è¯è¢‹(BOW)å‘é‡è¡¨ç¤ºã€‚ç¬¬ä¸‰çº§memoryæ˜¯resultçš„key-valueå¯¹ï¼Œ$(k_a^{r_{ij}}:v_a^{r_{ij}})$ï¼Œå…¶ä¸­value $v_a^{r_{ij}}$å¯èƒ½ä¼šè¢«å¤åˆ¶åˆ°å›å¤ä¸­ã€‚<h4 id="copyæœºåˆ¶å¢å¼ºçš„decoder"><a href="#copyæœºåˆ¶å¢å¼ºçš„decoder" class="headerlink" title="copyæœºåˆ¶å¢å¼ºçš„decoder"></a>copyæœºåˆ¶å¢å¼ºçš„decoder</h4><p>decoderä¸€ä¸ªè¯ä¸€ä¸ªè¯åœ°ç”Ÿæˆå›å¤ã€‚åœ¨æ—¶é—´æ­¥tç”Ÿæˆè¯$y_t$æ—¶ï¼Œå¯èƒ½ä»è¯æ±‡è¡¨ä¸­ç”Ÿæˆï¼Œä¹Ÿèƒ½ä»ä¸¤ä¸ªåˆ†å¼€çš„memoryä¸Šå¤åˆ¶ã€‚ç”¨é—¨$g_1$æ¥é€‰æ‹©æ˜¯ä»è¯æ±‡è¡¨ä¸Šç”Ÿæˆï¼Œè¿˜æ˜¯ä»memoryä¸­å¤åˆ¶ã€‚å¦‚æœæ˜¯åè€…ï¼Œç”¨å¦ä¸€ä¸ªé—¨$g_2$æ¥é€‰æ‹©æ˜¯ä»contextä¸­å¤åˆ¶ï¼Œè¿˜æ˜¯ä»çŸ¥è¯†åº“å¤åˆ¶ã€‚</p><ol><li><strong>ä»è¯æ±‡è¡¨ç”Ÿæˆè¯</strong><br> æ—¶é—´æ­¥tï¼Œdecoderçš„éšè—çŠ¶æ€$h_t$ä¸º$$h_t = GRU(y_{t-1},s_{t-1})$$ç”¨$h_t$è®¡ç®—åœ¨encoderçš„æ‰€æœ‰éšè—çŠ¶æ€ä¸Šçš„attentionæƒé‡ï¼Œé‡‡ç”¨â€concat attentionâ€æœºåˆ¶ï¼š$$a_{ij} = softmax(w_1^\top tanh(W_2tanh(W_3[h_t,h_{ij}^e]))) = \frac{w_1^\top tanh(W_2tanh(W_3[h_t,h_{ij}^e]))}{\sum_{ij}w_1^\top tanh(W_2tanh(W_3[h_t,h_{ij}^e]))}$$åˆ™context vectorä¸º$$d_t = \sum_{ij}a_{ij}h^e_{ij}$$ $h_t$å’Œ$d_t$è¿æ¥åç»è¿‡çº¿æ€§å±‚å’Œsoftmaxå±‚å¾—åˆ°åœ¨è¯æ±‡è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒï¼š$$P_g(y_t) = softmax(W_1[h_t,d_t] + b_1)$$</li><li><strong>ä»context memoryä¸­å¤åˆ¶è¯</strong><br> ç›´æ¥å°†è®¡ç®—context vectoræ—¶çš„attentionæƒé‡ï¼Œä½œä¸ºåœ¨contextæ‰€æœ‰è¯$w_{ij}$ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒï¼š$$P_{con}(y_t = w) = \sum_{ij:w_{ij}=w}a_{ij}$$</li><li><strong>ä»KB memoryä¸­å¤åˆ¶å®ä½“</strong><br> æ—¶é—´æ­¥tçš„éšè—çŠ¶æ€$h_t$å’Œcontext vector $d_t$ç”¨æ¥è®¡ç®—åœ¨æ‰€æœ‰queryä¸Šçš„attentionæƒé‡ã€‚ç¬¬ä¸€çº§åœ¨æ‰€æœ‰query $q_1,q_2,â€¦,q_k$çš„attentionæƒé‡ä¸º$$\alpha_i = softmax(w_2^\top tanh(W_4[h_t,d_t,q_i^v])) = \frac{w_2^\top tanh(W_4[h_t,d_t,q_i^v])}{\sum_{i}w_2^\top tanh(W_4[h_t,d_t,q_i^v])}$$<br> ç¬¬äºŒçº§$\beta_i$åœ¨$q_i$å¯¹åº”çš„$r_i$ä¸Šçš„attentionæƒé‡ä¸º$$\beta_{ij} = softmax(w_3^\top tanh(W_5[h_t,d_t,r_{ij}^v])) = \frac{w_3^\top tanh(W_5[h_t,d_t,r_{ij}^v])}{\sum_{j}w_3^\top tanh(W_5[h_t,d_t,r_{ij}^v])}$$<br> ç¬¬ä¸€çº§attentionå’Œç¬¬äºŒçº§attentionçš„ä¹˜ç§¯æ˜¯åœ¨æ‰€æœ‰resultä¸Šçš„attentionæƒé‡åˆ†å¸ƒã€‚åˆ™memoryæ€»çš„å‘é‡è¡¨ç¤ºä¸º$$m_t = \sum_{i}\sum_j\alpha_i\beta_{ij}r_{ij}^v$$<br> ç¬¬ä¸‰çº§memoryä¸ºresultçš„key-valueå¯¹$(k_a^{r_{ij}}:v_a^{r_{ij}})$ï¼Œç±»ä¼¼äº<a href="https://arxiv.org/abs/1705.05414" target="_blank" rel="noopener">(Eric and Manning, 2017)</a>ï¼Œç”¨key $k_a^{r_{ij}}$æ¥è®¡ç®—attentionæƒé‡ï¼Œå°†å¯¹åº”çš„value $v_a^{r_{ij}}$å¤åˆ¶åˆ°å›å¤ä¸­ã€‚åœ¨$r_{ij}$æ‰€æœ‰keysä¸Šçš„attentionæƒé‡ä¸º$$\gamma_{ijl} = softmax(w_4^\top tanh(W_6[h_t,d_t,m_t,k_l^{r_{ij}}]))$$åˆ™åœ¨æ‰€æœ‰values $v_a^{r_{ij}}$çš„æ¦‚ç‡åˆ†å¸ƒä¸º:$$P_{kb}(y_t = w) = \sum_{ijl:v_l^{r_{ij}}=w}\alpha_i\beta_{ij}\gamma_{ijl}$$</li><li><strong>decoding</strong><br> æˆ‘ä»¬ç”¨é—¨æœºåˆ¶$g_2$æ¥æ¥ç»“åˆ$P_{con}(y_t)$å’Œ$P_{kb}(y_t)$ï¼Œå¾—åˆ°memoryä¸Šçš„copyæ¦‚ç‡åˆ†å¸ƒ$P_c(y_t)$ã€‚$$g_2 = sigmoid(W_7[h_t,d_t,m_t]+b_2)$$ $$P_c(y_t) = g_2P_{kb}(y_t) + (1-g_2)P_{con}(y_t)$$ ç”¨é—¨æœºåˆ¶$g_1$æ¥ç»“åˆ$P_{c}(y_t)$å’Œ$P_{g}(y_t)$æ¥å¾—åˆ°æ€»çš„æ¦‚ç‡åˆ†å¸ƒ$P(y_t)$ï¼š$$g_1 = sigmoid(W_8[h_t,d_t,m_t]+b_3)$$ $$P(y_t) = g_1P_g(y_t) + (1-g_1)P_c(y_t)$$</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;ã€æ¥æºã€‘ï¼šNAACL2019&lt;br&gt;ã€é“¾æ¥ã€‘ï¼š&lt;a href=&quot;https://arxiv.org/pdf/1810.10647.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/pdf/1810.10647.pdf&lt;/a&gt;&lt;br&gt;ã€ä»£ç ã€æ•°æ®é›†ã€‘ï¼š&lt;a href=&quot;https://github.com/DineshRaghu/multi-level-memory-network&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/DineshRaghu/multi-level-memory-network&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="è®ºæ–‡" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="NAACL2019" scheme="http://yoursite.com/tags/NAACL2019/"/>
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="Memory Network" scheme="http://yoursite.com/tags/Memory-Network/"/>
    
  </entry>
  
  <entry>
    <title>Neural Turing Machinesä¸Memory Network</title>
    <link href="http://yoursite.com/2019/07/26/Neural-Turing-Machines%E4%B8%8EMemory-Network/"/>
    <id>http://yoursite.com/2019/07/26/Neural-Turing-Machinesä¸Memory-Network/</id>
    <published>2019-07-26T03:03:15.000Z</published>
    <updated>2019-08-01T02:30:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>ä»‹ç»Memory Networksã€‚</p><a id="more"></a><h3 id="Neural-Turing-Machines-ç¥ç»å›¾çµæœº"><a href="#Neural-Turing-Machines-ç¥ç»å›¾çµæœº" class="headerlink" title="Neural Turing Machines-ç¥ç»å›¾çµæœº"></a>Neural Turing Machines-ç¥ç»å›¾çµæœº</h3><p>Google DeepMindå›¢é˜Ÿåœ¨<a href="https://arxiv.org/abs/1410.5401" target="_blank" rel="noopener">Alex Graves2014</a>æå‡ºNeural Turing Machinesï¼Œç¬¬ä¸€æ¬¡æå‡ºç”¨external memoryæ¥æé«˜ç¥ç»ç½‘ç»œçš„è®°å¿†èƒ½åŠ›ã€‚è¿™ä¹‹ååˆå‡ºç°äº†å¤šç¯‡å…³äºMemory Networksçš„è®ºæ–‡ã€‚æˆ‘ä»¬å…ˆçœ‹çœ‹Turing Machinesçš„æ¦‚å¿µã€‚</p><h4 id="Turing-Machines-å›¾çµæœº"><a href="#Turing-Machines-å›¾çµæœº" class="headerlink" title="Turing Machines-å›¾çµæœº"></a>Turing Machines-å›¾çµæœº</h4><p>è®¡ç®—æœºå…ˆé©±<a href="https://baike.baidu.com/item/%E8%89%BE%E4%BC%A6%C2%B7%E9%BA%A6%E5%B8%AD%E6%A3%AE%C2%B7%E5%9B%BE%E7%81%B5/3940576?fromtitle=%E5%9B%BE%E7%81%B5&fromid=121208" target="_blank" rel="noopener">turing</a>åœ¨1936å¹´æå‡ºäº†Turing Machinesè¿™æ ·ä¸€ä¸ªè®¡ç®—æ¨¡å‹ã€‚å®ƒç”±ä¸‰ä¸ªåŸºæœ¬çš„ç»„ä»¶ï¼š</p><ul><li>tape: ä¸€ä¸ªæ— é™é•¿çš„çº¸å¸¦ä½œä¸ºmemoryï¼ŒåŒ…å«æ— æ•°ä¸ªsymbolsï¼Œæ¯ä¸ªsymbolçš„å€¼ä¸º0ã€1æˆ–â€$\space$â€ã€‚</li><li>head: è¯»å†™å¤´ï¼Œå¯¹tapeä¸Šçš„symbolsè¿›è¡Œè¯»æ“ä½œå’Œå†™æ“ä½œã€‚</li><li>controllerï¼š æ ¹æ®å½“å‰çŠ¶æ€æ¥æ§åˆ¶headçš„æ“ä½œã€‚</li></ul><p>ç†è®ºä¸ŠTuring Machineså¯ä»¥æ¨¡æ‹Ÿä»»ä½•ä¸€ä¸ªè®¡ç®—ç®—æ³•ï¼Œä¸ç®¡è¿™ä¸ªç®—æ³•å¤šä¹ˆå¤æ‚ã€‚ä½†ç°å®ä¸­ï¼Œè®¡ç®—æœºä¸å¯èƒ½æœ‰æ— é™å¤§çš„memory spaceï¼Œå› æ­¤Turing Machinesåªæ˜¯æ•°å­¦æ„ä¹‰ä¸Šçš„è®¡ç®—æ¨¡å‹ã€‚</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/turing-machine.jpg" alt="Fig. 1. How a Turing machine looks like.(æ¥æº: http://aturingmachine.com/)" title>                </div>                <div class="image-caption">Fig. 1. How a Turing machine looks like.(æ¥æº: http://aturingmachine.com/)</div>            </figure><h4 id="Neural-Turing-Machines"><a href="#Neural-Turing-Machines" class="headerlink" title="Neural Turing Machines"></a>Neural Turing Machines</h4><p>Neural Turing Machines(NTM,<a href="https://arxiv.org/abs/1410.5401" target="_blank" rel="noopener">Alex Graves2014</a>)ç”¨external memoryæ¥æé«˜ç¥ç»ç½‘ç»œçš„è®°å¿†èƒ½åŠ›ã€‚<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">LSTM(Long and short memory)</a>é€šè¿‡é—¨æœºåˆ¶æœ‰æ•ˆç¼“è§£äº†RNNçš„â€™æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜â€™ï¼Œå¯ä»¥é€šè¿‡internal memoryå®ç°é•¿æœŸè®°å¿†ã€‚å½“LSTMçš„internal memoryçš„è®°å¿†èƒ½åŠ›æœ‰é™ï¼Œéœ€è¦ç”¨external memoryæ¥æé«˜ç¥ç»ç½‘ç»œçš„è®°å¿†èƒ½åŠ›ã€‚</p><p>Neural Turing MachinesåŒ…å«ä¸¤ä¸ªåŸºæœ¬ç»„ä»¶ï¼š<em>a neural network controller</em>å’Œ<em>memory bank</em>ã€‚<em>memory</em>æ˜¯ä¸€ä¸ª $N\cdot M$é˜¶çš„çŸ©é˜µï¼ŒåŒ…å«Nä¸ªå‘é‡ï¼Œæ¯ä¸ªå‘é‡çš„ç»´åº¦æ˜¯Mã€‚æˆ‘ä»¬æŠŠæ¯ä¸ªmemory vectorç§°ä¸ºmemory locationã€‚<em>controller</em>æ§åˆ¶<em>heads</em>å¯¹<em>memory</em>è¿›è¡Œè¯»å†™æ“ä½œã€‚</p><p>å¦‚ä½•å¯¹<em>memory matrix</em>è¿›è¡Œè¯»å†™æ“ä½œå‘¢ï¼Ÿå…³é”®é—®é¢˜æ˜¯å¦‚ä½•è®©è¯»å†™æ“ä½œæ˜¯å¯å¾®çš„ï¼Œè¿™æ ·æ‰èƒ½ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥æ›´æ–°æ¨¡å‹å‚æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œé—®é¢˜æ˜¯è®©æ¨¡å‹å…³äºmemory locationæ˜¯å¯å¾®çš„ï¼Œä½†memory locationsæ˜¯ç¦»æ•£çš„ã€‚Neural Turing Machinesç”¨äº†ä¸€ä¸ªå¾ˆèªæ˜çš„æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼šä¸æ˜¯å¯¹å•ç‹¬æŸä¸ªmemory locationè¿›è¡Œè¯»å†™æ“ä½œï¼Œè€Œæ˜¯å¯¹æ‰€æœ‰çš„memory locationsè¿›è¡Œä¸åŒç¨‹åº¦çš„è¯»å†™æ“ä½œï¼Œè¿™ä¸ªç¨‹åº¦æ˜¯é€šè¿‡attentionçš„æƒé‡åˆ†å¸ƒæ¥æ§åˆ¶çš„ã€‚</p><div align="center"><img src="/images/NTM.png" width="60%" height="60%"></div><div align="center"><font color="grey" size="2">Fig. 2. Neural Turing Machine Architecture</font></div><h5 id="è¯»æ“ä½œ"><a href="#è¯»æ“ä½œ" class="headerlink" title="è¯»æ“ä½œ"></a>è¯»æ“ä½œ</h5><p>è®°æ—¶é—´æ­¥t <em>memory matrix</em>ä¸º$N\cdot M$é˜¶çŸ©é˜µ$M_t$ï¼Œ$w_t$æ˜¯åœ¨Nä¸ªmemoryå‘é‡ä¸Šçš„æƒé‡åˆ†å¸ƒï¼Œæ˜¯ä¸€ä¸ªNç»´å‘é‡ã€‚åˆ™æ—¶é—´æ­¥tçš„read vector $r_t$ä¸º$$r_t = \sum_{i=1}^{N}w_t(i)\cdot M_t(i)$$ $$where: \sum_{i=1}^{N}w_t(i) = 1; 0 \le w_t(i) \le 1,\forall i $$å…¶ä¸­ï¼Œ$w_t(i)$æ˜¯$w_t$çš„ç¬¬iä¸ªå…ƒç´ ï¼Œ$M_t(i)$æ˜¯$M_t$çš„ç¬¬iä¸ªè¡Œå‘é‡ã€‚</p><h5 id="å†™æ“ä½œ"><a href="#å†™æ“ä½œ" class="headerlink" title="å†™æ“ä½œ"></a>å†™æ“ä½œ</h5><p>å—LSTMé—¨æœºåˆ¶çš„å¯å‘ï¼Œå°†å†™æ“ä½œåˆ†æˆä¸¤æ­¥ï¼šå…ˆ<em>erase</em>ï¼Œå†<em>add</em>ã€‚å…ˆæ ¹æ®<em>erase vector $e_t$</em>æ“¦å»æ—§çš„å†…å®¹ï¼Œå†æ ¹æ®<em>add vector $a_t$</em>æ·»åŠ æ–°çš„å†…å®¹ã€‚</p><ol><li>å…ˆeraseï¼š<br> åœ¨æ—¶é—´æ­¥tï¼Œattentionæƒé‡åˆ†å¸ƒä¸º$w_t$ï¼Œ<em>erase vector $e_t$</em>æ˜¯ä¸€ä¸ªMç»´å‘é‡ï¼Œæ¯ä¸ªå…ƒç´ å–å€¼[0,1]ï¼Œä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„<em>memory vector</em>ä¸º$M_{t-1}$ã€‚åˆ™eraseæ“ä½œä¸º$$\tilde{M_{t}}(i) = M_{t-1}(i)[\vec{1}-w_t(i)e_t]$$ $\vec{1}$æ˜¯ä¸€ä¸ªMç»´çš„å…¨1å‘é‡ã€‚å¯¹memory vectorçš„eraseæ“ä½œæ˜¯é€ç‚¹è¿›è¡Œçš„ã€‚å½“$e_t$çš„å…ƒç´ å’Œmemory locationå¯¹åº”æƒé‡$w_t(i)$çš„å…ƒç´ å€¼éƒ½æ˜¯1æ—¶ï¼Œmemory vector $M_t(i)$çš„å…ƒç´ å€¼æ‰ä¼šç½®ä¸º0ã€‚å¦‚æœ$e_t$æˆ–$w_t(i)$çš„å…ƒç´ å€¼ä¸º0æ—¶ï¼Œmemory vector $M_t(i)$çš„å…ƒç´ å€¼ä¿æŒä¸å˜ã€‚</li><li>å†add:<br> æ¯ä¸ª<em>write head</em>ä¼šäº§ç”Ÿä¸€ä¸ªMç»´çš„<em>add vector a_t</em>ï¼Œåˆ™ï¼š$$M_t(i) = \tilde{M_{t}}(i) + w_t(i)a_t$$è‡³æ­¤ï¼Œå°±å®Œæˆäº†å†™æ“ä½œã€‚</li></ol><h5 id="å¯»å€æœºåˆ¶"><a href="#å¯»å€æœºåˆ¶" class="headerlink" title="å¯»å€æœºåˆ¶"></a>å¯»å€æœºåˆ¶</h5><p>è¿›è¡Œè¯»å†™æ“ä½œå‰ï¼Œè¦ææ¸…æ¥šå¯¹å“ªä¸ªmemory locationè¿›è¡Œè¯»å†™å‘¢ï¼Ÿè¿™å°±æ˜¯å¯»å€ã€‚ä¸ºäº†è®©æ¨¡å‹å…³äºmemory locatioså¯å¾®ï¼ŒNeural Turing Machinesä¸æ˜¯å¯¹æŸä¸ªå•ç‹¬çš„memory locationè¿›è¡Œè¯»å†™æ“ä½œï¼Œè€Œæ˜¯å¯¹æ‰€æœ‰memory locationsè¿›è¡Œä¸åŒç¨‹åº¦çš„è¯»å†™æ“ä½œï¼Œè¿™ä¸ªç¨‹åº¦å°±æ˜¯ç”±æƒé‡åˆ†å¸ƒ$w_t$æ¥æ§åˆ¶çš„ã€‚æ¨¡å‹ç»“åˆå¹¶åŒæ—¶ä½¿ç”¨äº†content-basedå’Œlocation-basedä¸¤ç§å¯»å€æ–¹å¼æ¥è®¡ç®—è¿™ä¸ªæƒé‡åˆ†å¸ƒ$w_t$ã€‚å…·ä½“åœ°ï¼Œæƒé‡è®¡ç®—åˆ†ä¸ºä»¥ä¸‹å‡ æ­¥ï¼š</p><ol><li>content-based addressing<br> æ—¶é—´æ­¥tï¼Œæ¯ä¸ªheadäº§å‡ºä¸€ä¸ªMç»´çš„<em>key vector $k_t$</em>ï¼Œé€šè¿‡$k_t$ä¸memory vectors $M_t(i)$ä¹‹é—´çš„ç›¸ä¼¼æ€§æ¥è®¡ç®—content-based attentionæƒé‡åˆ†å¸ƒ$w_{t}^{c}$ã€‚ç›¸ä¼¼æ€§æ˜¯é€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦æ¥è¡¡é‡çš„ã€‚$$w_{t}^{c} = softmax(\beta_tK(k_t,M_t(i))) = \frac{\beta_tK(k_t,M_t(i))}{\sum_{j}K(k_t,M_t(j))}$$ $$K(u,v) = \frac{u\cdot v}{|u|\cdot |v|}$$<br> $\beta_t$å¯ä»¥æ”¾å¤§æˆ–ç¼©å°æƒé‡çš„ç²¾åº¦ã€‚</li><li>å†…æ’æ³•<br> æ¯ä¸ªheadäº§ç”Ÿä¸€ä¸ª<em>interpolation gate $g_t$</em>ï¼Œå–å€¼[0,1]ã€‚content-based attentionæƒé‡åˆ†å¸ƒä¸º$w_t^{c}$ï¼Œä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„attentionæƒé‡åˆ†å¸ƒä¸º$w_{t-1}$ã€‚åˆ™é—¨æ§åˆ¶çš„æƒé‡åˆ†å¸ƒ$w_t^g$ä¸ºï¼š$$w_t^g = g_tw_t^c + (1-g_t)w_{t-1}$$å½“$g_t$ä¸º0æ—¶ï¼Œé‡‡ç”¨ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„æƒé‡åˆ†å¸ƒ$w_{t-1}$ï¼Œå½“$g_t$ä¸º1æ—¶ï¼Œé‡‡ç”¨content-based attentionæƒé‡åˆ†å¸ƒ$w_t^c$ã€‚</li><li>å¾ªç¯å·ç§¯<br> å¯¹ç»è¿‡æ’å€¼åçš„æƒé‡åˆ†å¸ƒ$w_t^g$è¿›è¡Œå¾ªç¯å·ç§¯ï¼Œä¸»è¦åŠŸèƒ½æ˜¯å¯¹æƒé‡è¿›è¡Œæ—‹è½¬ä½ç§»ã€‚æ¯”å¦‚å½“æƒé‡åˆ†å¸ƒå…³æ³¨æŸä¸ªmemory locationæ—¶ï¼Œç»è¿‡å¾ªç¯å·ç§¯å°±ä¼šæ‰©å±•åˆ°é™„è¿‘çš„memory locationsï¼Œä¹Ÿä¼šå¯¹é™„è¿‘çš„memory locationsè¿›è¡Œå°‘é‡çš„è¯»å†™æ“ä½œã€‚æ¯ä¸ªheadäº§ç”Ÿçš„è½¬ç§»æƒé‡ä¸º$s_t$,å¾ªç¯å·ç§¯çš„æ“ä½œä¸º:$$\tilde{w_t(i)} = \sum_{j=0}^{N-1}w_t^g(i)s_t(i-j)$$<br> å…³äº$s_t$çš„è¯¦ç»†ä»‹ç»å¯ä»¥è§<a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#neural-turing-machines" target="_blank" rel="noopener">attention?attenion!</a>;<br> å¾ªç¯å·ç§¯çš„è¯¦ç»†ä»‹ç»å¯ä»¥è§<a href="https://blog.csdn.net/rtygbwwwerr/article/details/50548311" target="_blank" rel="noopener">Neural Turing Machines-NTMç³»åˆ—ï¼ˆä¸€ï¼‰ç®€è¿°</a></li><li>é”åŒ–<br> å¾ªç¯å·ç§¯å¾€å¾€ä¼šé€ æˆæƒé‡æ³„æ¼å’Œåˆ†æ•£ï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œéœ€è¦æœ€åè¿›è¡Œé”åŒ–æ“ä½œã€‚$$w_t(i) = \frac{\tilde{w_t(i)^{\gamma_t}}}{\sum_j\tilde{w_t(j)^{\gamma_t}}}$$å…¶ä¸­$\gamma_t &gt;1$ã€‚è‡³æ­¤ï¼Œå°±å¾—åˆ°äº†æ—¶é—´æ­¥tçš„æƒé‡åˆ†å¸ƒ$w_t$ã€‚å¯ä»¥æ ¹æ®è¿™ä¸ªæƒé‡åˆ†å¸ƒ$w_t$å¯¹memory matrixè¿›è¡Œè¯»å†™æ“ä½œã€‚</li></ol><p>æ€»ç»“ä»¥ä¸‹è¿™4æ­¥æ“ä½œã€‚ç¬¬ä¸€æ­¥content-based addressingæ ¹æ®è¾“å…¥å¾—åˆ°å…³äºmemory locationsçš„ç›¸ä¼¼åº¦ï¼›åä¸‰æ­¥å®ç°äº†location-based addressingã€‚ç¬¬äºŒæ­¥æ’å€¼æ“ä½œå¼•å…¥äº†ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„æƒé‡åˆ†å¸ƒï¼Œå¯¹content-based æƒé‡è¿›è¡Œä¿®æ­£ï¼›ç¬¬ä¸‰æ­¥å¾ªç¯å·ç§¯å°†æ¯ä¸ªä½ç½®çš„æƒé‡å‘ä¸¤è¾¹åˆ†æ•£ï¼›ç¬¬å››æ­¥é”åŒ–æ“ä½œå°†æƒé‡çªå‡ºåŒ–ï¼Œå¤§çš„æ›´å¤§ï¼Œå°çš„æ›´å°ã€‚</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/50.jpg" alt="Fig.3. å¯»å€æœºåˆ¶çš„4æ­¥æ“ä½œ" title>                </div>                <div class="image-caption">Fig.3. å¯»å€æœºåˆ¶çš„4æ­¥æ“ä½œ</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/NTM-flow-addressing.png" alt="Fig.4. å¯»å€æœºåˆ¶çš„4æ­¥æ“ä½œ<br>æ¥æºï¼š[Alex Graves2014](https://arxiv.org/abs/1410.5401)" title>                </div>                <div class="image-caption">Fig.4. å¯»å€æœºåˆ¶çš„4æ­¥æ“ä½œ<br>æ¥æºï¼š[Alex Graves2014](https://arxiv.org/abs/1410.5401)</div>            </figure><h4 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h4><ul><li><a href="https://distill.pub/2016/augmented-rnns/" target="_blank" rel="noopener">Attention and Augmented Recurrent Neural Networks</a><br>  ç”¨åŠ¨å›¾ç›´è§‚åœ°è¡¨ç°Neural Turing Machinesçš„è®¡ç®—è¿‡ç¨‹ã€‚æ¨èï¼ğŸ‘</li><li><a href="https://zhuanlan.zhihu.com/p/30383994" target="_blank" rel="noopener">è®°å¿†ç½‘ç»œä¹‹Neural Turing Machines</a>ï¼Œä¸­æ–‡</li><li><a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#neural-turing-machines" target="_blank" rel="noopener">attention?attenion!</a></li></ul><h3 id="Memory-Network"><a href="#Memory-Network" class="headerlink" title="Memory Network"></a>Memory Network</h3><p>åœ¨Neural Turing Machinesæå‡ºä»…ä»…äº”å¤©åï¼ŒFacebookç ”ç©¶å‘˜<a href="http://www.thespermwhale.com/jaseweston/" target="_blank" rel="noopener">Jason Weston</a>å‘è¡¨äº†<a href="http://arxiv.org/abs/1410.3916" target="_blank" rel="noopener">MEMORY NETWORKS</a>ã€‚åœ¨QAç³»ç»Ÿçš„é¢†åŸŸï¼Œåº”ç”¨memory networkã€‚è™½ç„¶RNNæˆ–LSTMå¯ä»¥é€šè¿‡hidden stateå’Œweightsæ¥è¿›è¡ŒçŸ­æœŸè®°å¿†ï¼Œä½†å®ƒä»¬çš„è®°å¿†èƒ½åŠ›æ˜¯æœ‰é™çš„ã€‚è¦å®ç°é•¿æœŸè®°å¿†ï¼Œéœ€è¦memory networkã€‚</p><h4 id="Memory-Networkçš„ä¸€èˆ¬æ¡†æ¶"><a href="#Memory-Networkçš„ä¸€èˆ¬æ¡†æ¶" class="headerlink" title="Memory Networkçš„ä¸€èˆ¬æ¡†æ¶"></a>Memory Networkçš„ä¸€èˆ¬æ¡†æ¶</h4><p>memory networkåŒ…æ‹¬ä¸€ä¸ªè®°å¿†å•å…ƒmemoryï¼Œå’Œå››ä¸ªåŸºæœ¬ç»„ä»¶ï¼š</p><ul><li>I(input feature map):<br>  å°†input <em>x</em>è¿›è¡Œå‘é‡åŒ–è¡¨ç¤ºï¼Œç¼–ç ä¸ºfeature representation <em>I(x)</em>ã€‚</li><li>G(generalization):<br>  å¯¹memoryè¿›è¡Œå†™æ“ä½œã€‚æ ¹æ®input æ¥æ›´æ–°memory <em>$m_i$</em>ã€‚$m_i = G(m_i,I(x),m)$</li><li>O(output feature map):<br>  å¯¹memoryè¿›è¡Œè¯»æ“ä½œã€‚æ ¹æ®inputå’Œmemoryç”Ÿæˆoutput featureã€‚$o = O(I(x),m)$</li><li>R(response):<br>  æ ¹æ®output feature oæ¥ç”Ÿæˆresponseã€‚</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/memn.jpg" alt="Fig.5. memory networkçš„æ¡†æ¶å›¾" title>                </div>                <div class="image-caption">Fig.5. memory networkçš„æ¡†æ¶å›¾</div>            </figure><h4 id="memory-networkæ¡†æ¶çš„å®ç°â€“MemNNs"><a href="#memory-networkæ¡†æ¶çš„å®ç°â€“MemNNs" class="headerlink" title="memory networkæ¡†æ¶çš„å®ç°â€“MemNNs"></a>memory networkæ¡†æ¶çš„å®ç°â€“MemNNs</h4><p>åœ¨Iæ¨¡å—å°†input $x_i$ç¼–ç ä¸º$I(x_i)$åï¼ŒGæ¨¡å—ä¹‹é—´å°†$I(x_i)$ä¿å­˜åˆ°ä¸‹ä¸€ä¸ªç©ºçš„memory slotä¸­ï¼Œè€Œä¸æ›´æ–°æ—§çš„memory slotsã€‚çœŸæ­£å®ç°inferenceçš„æ ¸å¿ƒæ¨¡å—æ˜¯Oå’ŒRã€‚</p><p>Oæ¨¡å—åœ¨ç»™å®šxçš„æ¡ä»¶ä¸‹ï¼Œä¾æ¬¡æ‰¾åˆ°ä¸xæœ€ç›¸å…³çš„kä¸ªmemory slotsã€‚è®ºæ–‡ä¸­é‡‡ç”¨k = 2ã€‚å…ˆæ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ€ç›¸å…³çš„memory slotï¼š$$m_{o1} = \mathop{argmax}\limits_{i = 1,â€¦,N} s_{o1}(x,m_i)$$å…¶ä¸­$s_o()$æ˜¯ä¸€ä¸ªåŒ¹é…å‡½æ•°ï¼Œè®¡ç®—xä¸$m_i$ä¹‹é—´çš„ç›¸å…³ç¨‹åº¦ã€‚æ¥ç€ï¼Œæ ¹æ®xå’Œç¬¬ä¸€ä¸ªmemoryæ‰¾åˆ°ä¸‹ä¸€ä¸ªmemoryï¼š$$m_{o2} = \mathop{argmax}\limits_{i = 1,â€¦,N} s_{o2}([x,m_{o1}],m_i)$$å°†output feature o = $[x,m_{o1},m_{o2}]$ä½œä¸ºRæ¨¡å—çš„è¾“å…¥ã€‚</p><p>Ræ¨¡å—å°†è¯æ±‡è¡¨ä¸­æ‰€æœ‰è¯ä¸output featureè¿›è¡ŒåŒ¹é…ï¼Œé€‰æ‹©åŒ¹é…åº¦æœ€é«˜çš„è¯ä½œä¸ºresponseã€‚è¿™æ ·ç”Ÿæˆçš„responseåªæœ‰ä¸€ä¸ªè¯ã€‚$$r = \mathop{argmax}\limits_{w \in W}s_R([x,m_{o1},m_{o2}],w)$$å…¶ä¸­$s_R()$æ˜¯ä¸€ä¸ªåŒ¹é…å‡½æ•°ã€‚</p><p>åŒ¹é…å‡½æ•°$s_O$å’Œ$s_R$éƒ½é‡‡ç”¨ä»¥ä¸‹å‡½æ•°ï¼š$$s(x,y) = \Phi_x(x)^\top U^\top U \Phi_y(y)$$å…¶ä¸­$\Phi_x(x),\Phi_y(y)$åˆ†åˆ«å°†x/yç¼–ç ä¸ºå‘é‡ã€‚<br><strong>ç›®æ ‡å‡½æ•°</strong><br>åœ¨è®­ç»ƒé˜¶æ®µé‡‡ç”¨æœ€å¤§è¾¹ç¼˜ç›®æ ‡å‡½æ•°ï¼Œè®¾å¯¹äºquestion xï¼ŒçœŸå®çš„labelä¸ºrï¼Œå¯¹åº”çš„memoryä¸º$m_{o1},m_{o2}$ã€‚åˆ™æœ€å¤§è¾¹ç¼˜ç›®æ ‡å‡½æ•°ä¸ºï¼š$$\sum_{m_i\ne m_{o1}}max(0,\gamma - s_{O1}(x,m_{o1}) + s_{O1}(x,m_i)) + $$ $$\sum_{m_j\ne m_{o2}}max(0,\gamma - s_{O2}([x,m_{o1}],m_{o2}) + s_{O2}([x,m_{o1}],m_j)) + $$ $$\sum_{râ€™ \ne r}max(0,\gamma - s_{R}([x,m_{o1},m_{o2}],r) + s_{R}([x,m_{o1},m_{o2}],râ€™))$$</p><p>ç”±äºargmax()å‡½æ•°çš„å­˜åœ¨ï¼Œè¿™ä¸ªæ¨¡å‹æ˜¯ä¸å¯å¾®çš„ã€‚è€Œä¸”ä¸­é—´è¿‡ç¨‹æ‰¾åˆ°ç›¸å…³memoryéœ€è¦ç›‘ç£ï¼Œè¿™ä¸ªæ¨¡å‹ä¸æ˜¯ç«¯åˆ°ç«¯çš„ã€‚<br>æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªmemory networkæ˜¯ä¸€ç§æ™®é€‚æ€§çš„æ¶æ„ï¼Œæ˜¯å¾ˆåˆçº§å¾ˆç®€å•çš„ï¼Œå¾ˆå¤šéƒ¨åˆ†è¿˜ä¸å®Œå–„ï¼Œä¸è¶³ä»¥åº”ç”¨å…·ä½“çš„ä»»åŠ¡ä¸Šã€‚ä¸è¿‡ï¼Œé€šè¿‡å¤šè·³æ–¹å¼æ‰¾åˆ°ç›¸å…³memoryçš„æ€è·¯æ˜¯å¾ˆå€¼å¾—å­¦ä¹ çš„ã€‚</p><h3 id="End-to-End-Memory-Network"><a href="#End-to-End-Memory-Network" class="headerlink" title="End-to-End Memory Network"></a>End-to-End Memory Network</h3><p>Jason Westonä½œä¸ºä¸‰ä½œçš„<a href="http://arxiv.org/abs/1503.08895" target="_blank" rel="noopener">Sainbayar Sukhbaatar2015</a>å¯¹Memory networkå·¥ä½œçš„æ”¹è¿›ï¼Œä¸»è¦æ”¹è¿›æ˜¯å®ç°äº†ç«¯åˆ°ç«¯ï¼Œå‡å°‘äº†ç›‘ç£ã€‚End-to-End Memory Networké‡‡ç”¨soft attentionè€Œä¸æ˜¯hard attentionæ¥read memoryï¼Œå› æ­¤æ˜¯ç«¯åˆ°ç«¯çš„ã€‚å¦å¤–ä¸éœ€è¦å¯¹ç›¸å…³memoryè¿›è¡Œç›‘ç£ã€‚æé«˜memory networkçš„å¯ç”¨æ€§ã€‚<br>å‡è®¾å¤šä¸ªå¥å­input $x_1,â€¦,x_n$ä½œä¸ºmemoryï¼Œå¯¹äºquery qï¼Œè¾“å‡ºå¯¹åº”çš„answer aã€‚ç»™å®šquery qï¼Œç»è¿‡å¤šè·³æ‰¾åˆ°ç›¸å…³çš„memoryï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„answer aã€‚</p><h4 id="single-layer"><a href="#single-layer" class="headerlink" title="single layer"></a>single layer</h4><p>ç»™å®šinput $x_1,x_2,â€¦,x_n$ï¼Œé‡‡ç”¨ä¸¤ä¸ªä¸åŒçš„embedding matrix Aå’ŒCåˆ†åˆ«ç¼–ç ä¸ºå‘é‡$\lbrace{m_1,â€¦,m_n}\rbrace$ï¼Œ$\lbrace{c_1,â€¦,c_n}\rbrace$,åˆ†åˆ«å¯¹åº”attentionæœºåˆ¶çš„keyså’Œvaluesã€‚å°†query qç»è¿‡embedding matrix Bç¼–ç ä¸ºå‘é‡è¡¨ç¤ºuã€‚</p><p>é‡‡ç”¨dot-product attentionè®¡ç®—æƒé‡ï¼š$$p_i = softmax(u^\top m_i) = \frac{exp(u^\top m_i)}{\sum_{j}exp(u^\top m_j)}$$<br>åˆ™memory representationä¸ºï¼š$$o = \sum_{i}p_i m_i$$<br>æ ¹æ®uå’Œoæ¥è¿›è¡Œé¢„æµ‹ï¼š$$\hat{a} = softmax(W (o + u))$$<br>é€šè¿‡æœ€å°åŒ–aä¸$\hat{a}$ä¹‹é—´çš„äº¤å‰ç†µæ¥è®­ç»ƒæ¨¡å‹å‚æ•°A,B,C,Wã€‚è¿™ä¸ªsingle layer end-to-end Memory networkæ˜¯ç®€å•è€Œç›´è§‚çš„ã€‚æ ¸å¿ƒæ˜¯ç”¨soft attentionæ¥read memoryï¼Œæ‰¾åˆ°ç›¸å…³çš„memoryï¼Œå¹¶è¿›è¡Œinferenceã€‚<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/mem.png" alt="Fig.6.å·¦:single layer;å³:multi layers<br>æ¥æºï¼š[Sainbayar Sukhbaatar2015](http://arxiv.org/abs/1503.08895)" title>                </div>                <div class="image-caption">Fig.6.å·¦:single layer;å³:multi layers<br>æ¥æºï¼š[Sainbayar Sukhbaatar2015](http://arxiv.org/abs/1503.08895)</div>            </figure></p><h4 id="multi-layers"><a href="#multi-layers" class="headerlink" title="multi layers"></a>multi layers</h4><p>å°†Kå±‚single layerè¿›è¡Œstackå¾—åˆ°Kå±‚memory networkï¼Œè¿›è¡ŒKè·³memoryæŸ¥è¯¢æ“ä½œã€‚å…·ä½“åœ°stackæ–¹å¼ä¸ºï¼š</p><ul><li>å°†ç¬¬kå±‚çš„è¾“å…¥$u^k$å’Œmemory representation $o^k$ç›¸åŠ ä½œä¸ºç¬¬k+1å±‚çš„è¾“å…¥:$$u^{k+1} = u^k + o^k$$</li><li>æ¯ä¸€å±‚éƒ½æœ‰å•ç‹¬çš„embedding matrix $A^k$å’Œ$C^k$</li><li>æœ€åä¸€å±‚çš„é¢„æµ‹è¾“å‡ºä¸ºï¼š$$\hat{a} = softmax(W u^{K+1}) = softmax(W(u^K + o^K))$$</li></ul><p>ä¸ºäº†å‡å°‘å‚æ•°é‡ï¼Œæœ‰ä¸¤ç§æ–¹æ³•ï¼š</p><ul><li>adjacent:<br>  è®©ç›¸é‚»å±‚çš„embedding matrix A=Cï¼Œå…±äº«å‚æ•°ã€‚å³ï¼š$C^k = A^{k+1}$ï¼Œå¯¹ç¬¬ä¸€å±‚æœ‰$A^1 = B$ï¼Œæœ€åä¸€å±‚æœ‰ï¼š$C^K = W$ã€‚è¿™æ ·å°±å‡å°‘äº†ä¸€åŠçš„å‚æ•°é‡ã€‚</li><li>RNN-like:<br>  è·ŸRNNä¸€æ ·ï¼Œé‡‡ç”¨å®Œå…¨å‚æ•°å…±äº«çš„æ–¹æ³•ï¼Œ$A^1 = A^2 = â€¦ = A^K$;$C^1 = C^2 = â€¦ = C^K$ã€‚å‚æ•°æ•°é‡å¤§å¤§å‡å°‘å¯¼è‡´æ¨¡å‹æ•ˆæœå˜å·®ï¼Œåœ¨å±‚ä¸å±‚ä¹‹é—´æ·»åŠ ä¸€ä¸ªçº¿æ€§æ˜ å°„ï¼š$u^{k+1} = Hu^k + o^k$</li></ul><h3 id="key-value-Memory-Networks"><a href="#key-value-Memory-Networks" class="headerlink" title="key-value Memory Networks"></a>key-value Memory Networks</h3><p>Jason Westonä½œä¸ºä½œè€…ä¹‹ä¸€çš„<a href="https://arxiv.org/abs/1606.03126" target="_blank" rel="noopener">Alexander Miller2016</a>åœ¨End-to-End Memory networksçš„åŸºç¡€ä¸Šç»§ç»­æ¨è¿›ï¼Œå¯ä»¥æ›´å¥½çš„é€šè¿‡memoryæ¥ç¼–ç å’Œåˆ©ç”¨å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶ä¸”å…·ä½“åœ°åº”ç”¨åˆ°äº†QAç³»ç»Ÿä¸­ã€‚</p><p>ä½œä¸ºmemoryçš„å…ˆéªŒçŸ¥è¯†å¯ä»¥æ˜¯ç»“æ„åŒ–çš„ä¸‰å…ƒç»„çŸ¥è¯†åº“ï¼Œä¹Ÿå¯ä»¥æ˜¯éç»“æ„åŒ–çš„æ–‡æœ¬ã€‚</p><ul><li>ä¸‰å…ƒç»„çŸ¥è¯†åº“ã€‚ä¸‰å…ƒç»„çš„å½¢å¼æ˜¯â€å®ä½“-å…³ç³»-å®ä½“â€ï¼Œæˆ–â€ä¸»è¯­-è°“è¯­-å®¾è¯­â€ã€‚ä¸‰å…ƒç»„çŸ¥è¯†åº“çš„ä¼˜ç‚¹æ˜¯ç»“æ„åŒ–çš„ï¼Œä¾¿äºæœºå™¨å¤„ç†ã€‚ä½†ç¼ºç‚¹æ˜¯ä¸ä¸€å¥å®Œæ•´çš„è¯æ¯”è¾ƒï¼Œä¸‰å…ƒç»„ç¼ºå°‘äº†ä¸€äº›ä¿¡æ¯ã€‚ç”±äºä¸‰å…ƒç»„çŸ¥è¯†åº“æ˜¯äººå·¥æ„å»ºçš„ï¼Œéš¾å…ä¼šæœ‰è¦†ç›–ä¸åˆ°çš„çŸ¥è¯†ï¼Œå¯¹äºæŸä¸ªé—®é¢˜å¯èƒ½çŸ¥è¯†åº“ä¸­æ ¹æœ¬å°±æ²¡æœ‰å¯¹åº”çš„çŸ¥è¯†ã€‚å¦å¤–ï¼Œä¸‰å…ƒç»„ä¸­çš„å®ä½“å¯ä»¥æœ‰å¤šç§ä¸åŒçš„è¡¨è¾¾ï¼Œæ¯”å¦‚çŸ¥è¯†åº“ä¸­æœ‰ä¸‰å…ƒç»„â€ä¸­å›½-é¦–éƒ½-åŒ—äº¬â€ã€‚å½“é—®é¢˜æ˜¯â€œä¸­åäººæ°‘å…±å’Œå›½çš„é¦–éƒ½æ˜¯ï¼Ÿâ€æ—¶ï¼Œå¯èƒ½å°±ä¸èƒ½å¾ˆå¥½åœ°å›ç­”ã€‚</li><li>åƒâ€œç»´åŸºç™¾ç§‘â€è¿™æ ·çš„éç»“æ„åŒ–æ–‡æœ¬ã€‚ä¼˜ç‚¹æ—¶è¦†ç›–é¢å¹¿ï¼Œå‡ ä¹åŒ…å«æ‰€æœ‰é—®é¢˜çš„çŸ¥è¯†ã€‚ç¼ºç‚¹æ˜¯éç»“æ„åŒ–çš„ï¼Œæœ‰æ­§ä¹‰ï¼Œéœ€è¦ç»è¿‡å¤æ‚çš„æ¨ç†æ‰èƒ½æ‰¾åˆ°ç­”æ¡ˆã€‚</li></ul><p>ä½œä¸ºå…ˆéªŒçŸ¥è¯†çš„memoryæ˜¯(key,value)å½¢å¼çš„ã€‚</p><ul><li>key memoryç”¨äºå¯»å€(addressing/lookup)é˜¶æ®µï¼Œé€šè¿‡è®¡ç®—queryä¸key memoryçš„ç›¸å…³ç¨‹åº¦æ¥è®¡ç®—attentionæƒé‡ï¼Œå› æ­¤åœ¨è®¾è®¡key memoryæ—¶ï¼Œkey memoryçš„ç‰¹å¾åº”è¯¥æ›´å¥½åœ°åŒ¹é…queryã€‚</li><li>value memoryç”¨äºreadé˜¶æ®µï¼Œå°†value memoryçš„åŠ æƒå’Œä½œä¸ºmemoryæ€»çš„å‘é‡è¡¨ç¤ºï¼Œå› æ­¤åœ¨æ¶‰åŠvalue memoryæ—¶ï¼Œvalue memoryçš„ç‰¹å¾åº”è¯¥æ›´å¥½åœ°åŒ¹é…responseã€‚</li></ul><p>æ¯”è¾ƒä¸€ä¸‹end-to-end memory networkä¸key-value memory networkçš„åŒºåˆ«ï¼š</p><ul><li>å‰è€…æ˜¯å°†ç›¸åŒçš„è¾“å…¥ç»è¿‡ä¸¤ä¸ªä¸åŒçš„embedding matrixç¼–ç åˆ†ä¸ºä½œä¸ºkey memoryå’Œvalue memoryã€‚è€Œåè€…å¯ä»¥å°†ä¸åŒçš„çŸ¥è¯†(key,value)åˆ†åˆ«ç¼–ç ä¸ºkey memoryå’Œvalue memoryï¼Œå¯ä»¥æ›´çµæ´»åœ°åˆ©ç”¨å…ˆéªŒçŸ¥è¯†ã€‚</li><li>åè€…çš„æ¯ä¸ªhopä¹‹é—´æ·»åŠ äº†ç”¨$R_j$æ¥è¿›è¡Œçº¿æ€§æ˜ å°„ã€‚</li></ul><h4 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h4><p>åœ¨é—®ç­”ç³»ç»Ÿä¸­ï¼Œè®°memory slotsä¸º$(k_1,v_1),â€¦,(k_M,v_M)$ï¼Œé—®é¢˜queryä¸ºxï¼ŒçœŸå®å›å¤ä¸ºaï¼Œé¢„æµ‹å›å¤ä¸º$\hat{a}$ã€‚$\Phi_{X},\Phi_{Y},\Phi_{K},\Phi_{V}$åˆ†åˆ«æ˜¯x,a,key,valueçš„embedding matrixï¼Œå°†æ–‡æœ¬ç¼–ç ä¸ºå‘é‡è¡¨ç¤ºã€‚</p><p>åˆ™å•æ¬¡memoryçš„å¯»å€å’Œè¯»å–å¯ä»¥åˆ†ä¸ºä¸‰æ­¥ï¼š</p><ul><li>key hashing:<br>  å½“çŸ¥è¯†åº“å¾ˆå¤§æ—¶ï¼Œè¿™ä¸€æ­¥æ˜¯éå¸¸å¿…è¦çš„ã€‚æ ¹æ®queryä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç­›é€‰å‡ºç›¸å…³çš„facts $ (k_{h_1},v_{h_1}),(k_{h_2},v_{h_2}),â€¦,(k_{h_N},v_{h_N})$ï¼Œç­›é€‰æ¡ä»¶å¯ä»¥æ˜¯keyä¸­è‡³å°‘åŒ…å«queryä¸­ä¸€ä¸ªç›¸åŒçš„è¯ï¼ˆå»é™¤åœç”¨è¯ï¼‰ã€‚è¿™ä¸€æ­¥å¯ä»¥åœ¨æ•°æ®é¢„å¤„ç†æ—¶è¿›è¡Œï¼Œç›´æ¥å°†queryå’Œç›¸å…³çš„factsä½œä¸ºæ¨¡å‹çš„è¾“å…¥ã€‚</li><li>key addressing(å¯»å€é˜¶æ®µ)<br>  è®¡ç®—queryä¸memoryçš„ç›¸å…³ç¨‹åº¦æ¥åˆ†é…åœ¨memoryä¸Šçš„æ¦‚ç‡åˆ†å¸ƒï¼š$$p_{h_i} = softmax(A\Phi_{X}(x) \cdot A\Phi_{K}(k_{h_i}))$$å…¶ä¸­$\Phi$å°†æ–‡æœ¬ç¼–ç ä¸ºDç»´å‘é‡ï¼ŒAæ˜¯ä¸€ä¸ª$d\times D$çš„å¯è®­ç»ƒçŸ©é˜µã€‚</li><li>value readingï¼š<br>  å°†valueçš„åŠ æƒæ±‚å’Œä½œä¸ºmemoryæ€»çš„å‘é‡è¡¨ç¤ºã€‚$$o = \sum_{i}p_{h_i}A\Phi_{V}(v_{h_i})$$</li></ul><p>memoryçš„è¯»å–è¿‡ç¨‹æ˜¯ç”±controllerç¥ç»ç½‘ç»œé€šè¿‡query $q = A\Phi_{X}(x)$æ¥æ§åˆ¶çš„ã€‚æ¨¡å‹ä¼šåˆ©ç”¨query $q$ä¸ä¸Šä¸€è·³(hop)çš„$o$æ¥æ›´æ–°queryï¼Œè¿›è€Œè¿­ä»£åœ°å¯»å€å’Œè¯»å–memoryï¼Œè¿™ä¸ªè¿­ä»£çš„è¿‡ç¨‹ç§°ä¸ºå¤šè·³(hops)ã€‚<br>ç”¨å¤šè·³æ–¹å¼æ¥è¿­ä»£åœ°å¯»å€å’Œè¯»å–memoryï¼Œå¯ä»¥è¿™æ ·æ¥ç†è§£ï¼šæµ…å±‚ç¥ç»ç½‘ç»œå¯ä»¥å­¦ä¹ åˆ°ä½çº§çš„ç‰¹å¾ï¼Œéšç€ç¥ç»ç½‘ç»œå±‚æ•°å¢å¤šå°±å¯ä»¥å­¦ä¹ åˆ°æ›´é«˜çº§çš„ç‰¹å¾ã€‚ç±»æ¯”CNNå¤„ç†äººè„¸å›¾ç‰‡æ—¶ï¼Œç¬¬ä¸€å±‚å¯ä»¥å­¦ä¹ åˆ°ä¸€äº›è¾¹ç¼˜ç‰¹å¾ï¼Œç¬¬äºŒå±‚å¯ä»¥å­¦ä¹ åˆ°çœ¼ç›ã€é¼»å­ã€å˜´å·´è¿™æ ·çš„ç‰¹å¾ï¼Œæœ€åä¸€å±‚å¾—åˆ°æ•´ä¸ªäººè„¸çš„ç‰¹å¾ã€‚åŒæ ·åœ°ï¼Œç”¨å¤šè·³æ–¹å¼æ¥å¯»å€å’Œè¯»å–memoryï¼Œå¯ä»¥å¾—åˆ°æ›´ç›¸å…³æ›´çªå‡ºçš„memoryï¼ŒåŒæ—¶å¯ä»¥èµ·åˆ°æ¨ç†çš„ä½œç”¨ã€‚</p><p>queryçš„æ›´æ–°å…¬å¼ä¸º:$$q_2 = R_1(q + o)$$å…¶ä¸­Ræ˜¯ä¸€ä¸ª$d\times d$çš„å¯è®­ç»ƒçŸ©é˜µã€‚æ¯ä¸€è·³ä½¿ç”¨ä¸åŒçš„çŸ©é˜µ$R_j$ã€‚<br>åˆ™ç¬¬jè·³æ›´æ–°queryåï¼Œå¯»å€é˜¶æ®µçš„è®¡ç®—å…¬å¼ä¸º$$p_{h_i} = softmax(q_{j+1}^\top \cdot A\Phi_{K}(k_{h_i}))$$<br>åœ¨ç»è¿‡Hè·³ä¹‹åï¼Œç”¨controllerç¥ç»ç½‘ç»œçš„æœ€ç»ˆçŠ¶æ€è¿›è¡Œé¢„æµ‹:$$\hat{a} = argmax_{i=1,â€¦,C}softmax(q_{H+1}B\Phi_{y}(y_i))$$å…¶ä¸­Bæ˜¯ä¸€ä¸ª$d\times D$çš„å¯è®­ç»ƒçŸ©é˜µï¼Œå½¢çŠ¶è·ŸAä¸€æ ·ã€‚$y_i$å¯ä»¥æ˜¯çŸ¥è¯†åº“ä¸­çš„å®ä½“ï¼Œæˆ–è€…å€™é€‰å¥å­ã€‚</p><p>æ¨¡å‹çš„ç›®æ ‡å‡½æ•°ä¸ºé¢„æµ‹å›å¤$\hat{a}$ä¸çœŸå®å›å¤$a$ä¹‹é—´çš„äº¤å‰ç†µï¼Œç”¨æ¢¯åº¦ä¸‹é™çš„æ–¹æ³•æ¥æ›´æ–°æ¨¡å‹å‚æ•°ï¼š$A,B,R_1,â€¦,R_H$</p><div align="center"><img src="/images/key-value-memory.png" width="150%" height="150%"></div><div align="center"><font color="grey" size="2">Fig.7. é—®ç­”ç³»ç»Ÿkey-value memory networksçš„æ¨¡å‹æ¡†æ¶</font><br><a href="https://arxiv.org/abs/1606.03126" target="_blank" rel="noopener"><font color="grey" size="2">æ¥æº:Alexander Miller2016</font></a></div><h4 id="key-valueçš„é€‰æ‹©ä¸ç¼–ç æ–¹å¼"><a href="#key-valueçš„é€‰æ‹©ä¸ç¼–ç æ–¹å¼" class="headerlink" title="key-valueçš„é€‰æ‹©ä¸ç¼–ç æ–¹å¼"></a>key-valueçš„é€‰æ‹©ä¸ç¼–ç æ–¹å¼</h4><p>è®ºæ–‡æ ¹æ®ä¸åŒå½¢å¼çš„å…ˆéªŒçŸ¥è¯†ï¼Œæå‡ºäº†key-valueä¸åŒçš„ç¼–ç æ–¹å¼ï¼š</p><ul><li>çŸ¥è¯†åº“ä¸‰å…ƒç»„ã€‚ä¸‰å…ƒç»„å½¢å¼ä¸ºâ€subject-relation-objectâ€ï¼Œå°†â€subject-relationâ€ä½œä¸ºå¯»å€çš„keyï¼Œå°†â€objectâ€ä½œä¸ºè®°å¿†çš„valueã€‚</li><li>sentence levelã€‚ç›´æ¥å°†å¥å­çš„è¯è¢‹å‘é‡è¡¨ç¤ºä½œä¸ºkeyå’Œvalueï¼Œkeyå’Œvalueæ˜¯ä¸€æ ·çš„ã€‚æ¯ä¸ªmemory slotå­˜ä¸€ä¸ªå¥å­ã€‚</li><li>window levelã€‚ä»¥å¤§å°ä¸ºWçš„çª—å£å¯¹æ–‡æ¡£è¿›è¡Œåˆ†å‰²ï¼ˆåªä¿ç•™ä¸­å¿ƒè¯ä¸ºå®ä½“çš„çª—å£ï¼‰ï¼Œå°†å•ä¸ªçª—å£å†…çš„è¯ä½œä¸ºå¯»å€çš„keyï¼Œå°†çª—å£çš„ä¸­å¿ƒè¯ä½œä¸ºvalueã€‚</li></ul><h3 id="å‚è€ƒé“¾æ¥-1"><a href="#å‚è€ƒé“¾æ¥-1" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h3><ul><li><a href="https://zhuanlan.zhihu.com/c_129532277" target="_blank" rel="noopener">è®°å¿†ç½‘ç»œ-Memory Network</a></li><li><a href="https://jhui.github.io/2017/03/15/Memory-network/" target="_blank" rel="noopener">Memory network (MemNN) &amp; End to end memory network (MemN2N), Dynamic memory network</a></li><li><a href="http://thespermwhale.com/jaseweston/icml2016/" target="_blank" rel="noopener">Memory Networks for Language Understanding, ICML Tutorial 2016</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ä»‹ç»Memory Networksã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Neural Turing Machines" scheme="http://yoursite.com/tags/Neural-Turing-Machines/"/>
    
      <category term="Memory Network" scheme="http://yoursite.com/tags/Memory-Network/"/>
    
  </entry>
  
  <entry>
    <title>attention? attention!</title>
    <link href="http://yoursite.com/2019/07/23/attention-attention/"/>
    <id>http://yoursite.com/2019/07/23/attention-attention/</id>
    <published>2019-07-23T08:20:18.000Z</published>
    <updated>2019-08-28T09:38:20.000Z</updated>
    
    <content type="html"><![CDATA[<p>è¯»äº†åšä¸»<a href="https://lilianweng.github.io/lil-log/contact.html" target="_blank" rel="noopener">Weng, Lilian</a>çš„æ–‡ç« <a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#neural-turing-machines" target="_blank" rel="noopener">attention? attention!</a>ï¼Œæ˜¯ä¸€ç¯‡å¾ˆå¥½çš„æ–‡ç« ã€‚æ‰“ç®—æŒ‰ç…§è¿™ç¯‡æ–‡ç« çš„æ€è·¯ï¼Œè¿›è¡Œç¿»è¯‘ï¼Œå¹¶æ·»åŠ è‡ªå·±çš„ç†è§£ã€‚<br>attentionæœºåˆ¶åœ¨æ·±åº¦å­¦ä¹ ä¸­è¢«å¹¿ä¸ºä½¿ç”¨ï¼Œæœ¬æ–‡ä»‹ç»attentionæœºåˆ¶çš„æå‡ºï¼Œä¸åŒçš„attentionæœºåˆ¶ï¼ŒåŠattentionæœºåˆ¶çš„è¿›ä¸€æ­¥æ¢ç´¢å’Œåº”ç”¨ã€‚</p><a id="more"></a><h3 id="why-we-need-attention-ä»seq2seqæ¨¡å‹è°ˆèµ·"><a href="#why-we-need-attention-ä»seq2seqæ¨¡å‹è°ˆèµ·" class="headerlink" title="why we need attention?ä»seq2seqæ¨¡å‹è°ˆèµ·"></a>why we need attention?ä»seq2seqæ¨¡å‹è°ˆèµ·</h3><p><strong>seq2seqæ¨¡å‹</strong>ä¸14å¹´æå‡º(<a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" target="_blank" rel="noopener">Sutskever, et al. 2014</a>)ï¼Œå®ç°è¾“å…¥åºåˆ—(source sequence)åˆ°è¾“å‡ºåºåˆ—(target sequence)çš„æ˜ å°„ï¼Œè¿™ä¸¤ä¸ªåºåˆ—çš„é•¿åº¦éƒ½æ˜¯å¯å˜çš„ã€‚åºåˆ—åˆ°åºåˆ—æ˜ å°„çš„ä»»åŠ¡åŒ…æ‹¬æœºå™¨ç¿»è¯‘ã€é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç³»ç»Ÿã€æ‘˜è¦ç”Ÿæˆç­‰ã€‚</p><p>ç”¨æ•°å­¦è¯­è¨€æ¥å®šä¹‰åºåˆ—åˆ°åºåˆ—çš„ä»»åŠ¡ï¼Œç»™å®šè¾“å…¥åºåˆ—(source sequence) $X = \lbrace{ x_1,x_2,â€¦,x_n \rbrace}$ï¼Œéœ€è¦ç”Ÿæˆè¾“å‡ºåºåˆ—(target sequence) $Y = \lbrace{ y_1,y_2,â€¦,y_m \rbrace}$ï¼Œå…¶ä¸­source sequenceé•¿åº¦ä¸º$n$,target sequenceé•¿åº¦ä¸º$m$ã€‚</p><p><strong>seq2seqæ¨¡å‹</strong>åŸºäºencoder-decoderæ¡†æ¶ï¼ŒåŒ…æ‹¬2ä¸ªéƒ¨åˆ†ï¼š</p><ol><li><p><strong>encoder</strong>å°†source sequenceç¼–ç ï¼ˆæ˜ å°„ï¼‰ä¸ºä¸€ä¸ªå›ºå®šç»´åº¦çš„å‘é‡è¡¨ç¤º(context vector,æˆ–ç§°ä¸ºsentence embedding)ï¼Œæˆ‘ä»¬å¸Œæœ›è¿™ä¸ªå‘é‡è¡¨ç¤ºå¯ä»¥å¾ˆå¥½çš„è¡¨ç¤ºsource sequenceçš„æ„æ€ã€‚<br> encoderå¯ä»¥é‡‡ç”¨å·ç§¯ç¥ç»ç½‘ç»œCNNï¼Œä¹Ÿå¯ä»¥é‡‡ç”¨å¾ªç¯ç¥ç»ç½‘ç»œRNNï¼Œä½†ç”¨çš„æ›´å¤šçš„æ•ˆæœä¹Ÿæ›´å¥½çš„è¿˜æ˜¯RNNã€‚é€šå¸¸ä½¿ç”¨<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">LSTM æˆ– GRU</a>ã€‚<br> encoder RNNçš„éšè—çŠ¶æ€æ›´æ–°å…¬å¼ä¸ºï¼š$$\begin{gather}h_t = f(h_{t-1},x_t)\end{gather}$$å…¶ä¸­$h_t$ä¸ºRNNåœ¨æ—¶é—´æ­¥tçš„éšè—çŠ¶æ€ï¼Œfä¸ºLSTM æˆ–GRU.<br> å¯¹äºé•¿åº¦ä¸ºnçš„source sequenceï¼Œä¸€ä¸ªè¯æ¥ä¸€ä¸ªè¯åœ°è¾“å…¥RNNåï¼Œå¯ä»¥å¾—åˆ°nä¸ªéšè—çŠ¶æ€$(h_1,h_2,â€¦,h_n)$ï¼Œé€šå¸¸å°†æœ€åä¸€ä¸ªæ—¶é—´æ­¥æœ€åä¸€ä¸ªè¯å¯¹åº”çš„éšè—çŠ¶æ€$h_t$ä½œä¸ºsource sequenceçš„å‘é‡è¡¨ç¤ºï¼Œä¹Ÿå°±æ˜¯context vectorï¼Œè®°ä¸º$c$ã€‚</p></li><li><p><strong>decoder</strong>æ ¹æ®source sequenceçš„å‘é‡è¡¨ç¤ºcontext vectorï¼Œæ¥ä¸€ä¸ªè¯ä¸€ä¸ªè¯çš„ç”Ÿæˆtarget sequenceã€‚<br> decoderé‡‡ç”¨å•å‘RNNï¼Œdecoder RNNéšè—çŠ¶æ€çš„æ›´æ–°å…¬å¼ä¸º:$$\begin{gather}s_t = f(s_{t-1},y_{t-1},c)\end{gather}$$å…¶ä¸­$s_t$ä¸ºdecoderåœ¨æ—¶é—´æ­¥tçš„éšè—çŠ¶æ€ï¼Œ$y_{t-1}$ä¸ºtarget sequenceä¸­çš„ä¸Šä¸€ä¸ªè¯ï¼Œåœ¨trainé˜¶æ®µï¼Œ$y_{n-1}$ä¸ºçœŸå®target sequenceä¸­çš„ä¸Šä¸€ä¸ªè¯ï¼Œåœ¨inferé˜¶æ®µï¼Œ$y_{t-1}$ä¸ºé¢„æµ‹è¾“å‡ºçš„ä¸Šä¸€ä¸ªè¯ï¼›cä¸ºcontext vectorã€‚<br> æ—¶é—´æ­¥tï¼Œéšè—çŠ¶æ€$s_t$å†ç»è¿‡çº¿æ€§å±‚å’Œsoftmaxå¾—åˆ°åœ¨è¯è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒï¼Œå°†æ¦‚ç‡æœ€å¤§çš„è¯ä½œä¸ºprediction word $y_t$ã€‚è¿­ä»£å¾ªç¯ç›´åˆ°è¾“å‡ºæ•´ä¸ªtarget sequenceã€‚</p></li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/43.png" alt="Fig.1. seq2seqæ¨¡å‹çš„æ¡†æ¶å›¾" title>                </div>                <div class="image-caption">Fig.1. seq2seqæ¨¡å‹çš„æ¡†æ¶å›¾</div>            </figure><p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å½“ç”Ÿæˆä¸åŒçš„$y_t$æ—¶ï¼Œæ‰€ä¾æ®çš„context vectoréƒ½æ˜¯å›ºå®šä¸å˜çš„ã€‚å›ºå®šçš„context vectoræœ‰ä¸€ä¸ªç¼ºç‚¹æ˜¯ï¼šå½“encoderç¼–ç å®Œæ•´ä¸ªsource sequenceæ—¶ï¼Œä¼šåå‘äºæœ€è¿‘çš„è¯ï¼Œè€Œé—å¿˜äº†è·ç¦»æ›´è¿œçš„æœ€å¼€å§‹çš„ä¸€äº›è¯ã€‚<a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">(Bahdanau et al., 2015)</a>æå‡ºäº†attentionæœºåˆ¶æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</p><h3 id="attentionæœºåˆ¶-born-for-Translation"><a href="#attentionæœºåˆ¶-born-for-Translation" class="headerlink" title="attentionæœºåˆ¶:born for Translation"></a>attentionæœºåˆ¶:born for Translation</h3><p>attentionæœºåˆ¶æœ€å…ˆåœ¨æœºå™¨ç¿»è¯‘(neural machine translation,NMT)ä»»åŠ¡ä¸Šæå‡ºã€‚ä»è§£å†³é•¿æœŸä¾èµ–é—®é¢˜çš„è§’åº¦ï¼Œattentionå¯ä»¥å®ç°é•¿è·ç¦»çš„è®°å¿†ï¼›ä»æ³¨æ„åŠ›çš„è§’åº¦ï¼Œattentionæœºåˆ¶å¯ä»¥å®ç°å¯¹é½(alignment)ï¼Œç”¨æ›´å¤šçš„æ³¨æ„åŠ›å…³æ³¨åˆ°ç›¸å…³çš„éƒ¨åˆ†ï¼Œè€Œå¿½ç•¥æˆ–ä½æ³¨æ„åŠ›å…³æ³¨åˆ°ä¸ç›¸å…³çš„éƒ¨åˆ†ã€‚</p><p>ä¸Šæ–‡ä¸­æåˆ°ï¼Œåœ¨ç”Ÿæˆä¸åŒçš„$y_t$æ—¶ï¼Œç›´æ¥å°†encoderæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€$h_n$ä½œä¸ºå›ºå®šcontext vectorã€‚ä¸åŒäºè¿™ç§æ–¹æ³•ï¼Œattentionæœºåˆ¶å°†æ‰€æœ‰encoderéšè—çŠ¶æ€$\lbrace{ h_1,h_2,â€¦,h_n }\rbrace$çš„åŠ æƒå’Œä½œä¸ºcontext vectorï¼Œè¿™æ ·åœ¨æ¯ä¸ªæ—¶é—´æ­¥tç”Ÿæˆ$y_t$æ—¶ï¼Œæ‰€ä¾æ®çš„context vectoréƒ½æ˜¯ä¸“é—¨é’ˆå¯¹äº$y_t$çš„ã€‚<br>ä¸€æ–¹é¢ï¼Œcontext vectorå¯ä»¥è·å–åˆ°æ‰€æœ‰éšè—çŠ¶æ€ï¼Œä¹Ÿå°±æ˜¯æ•´ä¸ªsource sequenceçš„ä¿¡æ¯ï¼Œè¿™æ ·å°±å¯ä»¥å®ç°é•¿è·ç¦»çš„è®°å¿†ã€‚å¦ä¸€æ–¹é¢ï¼Œsource sequence ä¸target sequenceä¹‹é—´çš„è¯­ä¹‰å¯¹é½(aligenment)æ˜¯ä¹Ÿæ˜¯é€šè¿‡context vectorå®ç°çš„ã€‚åœ¨è®¡ç®—æ—¶é—´æ­¥tç”Ÿæˆ$y_t$å¯¹åº”çš„context vector $c_t$çš„è®¡ç®—éœ€è¦ä¸‰ä¸ªéƒ¨åˆ†çš„ä¿¡æ¯ï¼š</p><ul><li>æ‰€æœ‰çš„encoderéšè—çŠ¶æ€ï¼š $\lbrace{ h_1,h_2,â€¦,h_n }\rbrace$</li><li>ä¸Šä¸ªæ—¶é—´æ­¥t-1çš„decoder éšè—çŠ¶æ€ï¼š $s_{t-1}$</li><li>sourceä¸targetä¹‹é—´çš„alignment.<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/44.png" alt="Fig.2.æœ‰attentionæœºåˆ¶çš„encoder-decoderæ¨¡å‹ï¼Œæ¥æº:[Bahdanau et al., 2015.](https://arxiv.org/pdf/1409.0473.pdf)" title>                </div>                <div class="image-caption">Fig.2.æœ‰attentionæœºåˆ¶çš„encoder-decoderæ¨¡å‹ï¼Œæ¥æº:[Bahdanau et al., 2015.](https://arxiv.org/pdf/1409.0473.pdf)</div>            </figure></li></ul><h4 id="attentionçš„æ•°å­¦å®šä¹‰"><a href="#attentionçš„æ•°å­¦å®šä¹‰" class="headerlink" title="attentionçš„æ•°å­¦å®šä¹‰"></a>attentionçš„æ•°å­¦å®šä¹‰</h4><p>åœ¨è®¡ç®—æ—¶é—´æ­¥tç”Ÿæˆ$y_t$å¯¹åº”çš„context vector $c_t$æ—¶ï¼Œencoderçš„æ‰€æœ‰éšè—çŠ¶æ€ä¸º $\lbrace{ h_1,h_2,â€¦,h_n }\rbrace$ï¼Œæ—¶é—´æ­¥t-1çš„decoderéšè—çŠ¶æ€ä¸º $s_{t-1}$ï¼Œdecoder RNNçš„éšè—çŠ¶æ€æ›´æ–°å…¬å¼å˜ä¸ºï¼š$$\begin{gather}s_t = f(s_{t-1},y_{t-1},c_t)\end{gather}$$ context vector $c_t$ä¸ºencoder hidden stateçš„åŠ æƒå’Œï¼š<br>$$c_t = \sum_{i=1}^{n}\alpha_{t,i}h_i$$ $$\alpha_{t,i} = softmax(\beta_{t,i}) = \frac{exp(\beta_{t,i})}{\sum_{j = 1}^{n}exp(\beta_{t,j})}$$ $$\beta_{t,i} = score(s_{t-1},h_i)$$<br>å…¶ä¸­æƒé‡$\alpha_{t,i}$æ˜¯æ—¶é—´æ­¥tç”Ÿæˆ$y_t$ä¸éšè—çŠ¶æ€$h_i$ä¹‹é—´çš„scoreï¼Œä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œ$h_i$å¯ä»¥çœ‹ä½œæ˜¯$x_i$çš„è¡¨ç¤ºï¼Œä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯$\lbrace{x_1,x_2,â€¦,x_{i}}\rbrace$çš„è¡¨ç¤ºã€‚å› æ­¤ï¼Œ$\alpha_{t,i}$å¯ä»¥çœ‹ä½œæ˜¯$y_t$ä¸$x_i$ä¹‹é—´è”ç³»ï¼ˆç›¸å…³æ€§ï¼‰çš„scoreã€‚æ‰€æœ‰æƒé‡$\lbrace{\alpha_{t,1},\alpha_{t,2},â€¦,\alpha_{t,n}}\rbrace$è¡¡é‡äº†ç”Ÿæˆ$y_t$æ—¶åº”è¯¥å¦‚ä½•å…³æ³¨åˆ°æ‰€æœ‰çš„encoder hidden stateã€‚</p><p>score()ä¸ºæ‰“åˆ†å‡½æ•°ï¼Œæœ‰å¤šç§è®¡ç®—æ–¹æ³•ï¼Œä¸‹æ–‡ä¼šè¯¦ç»†ä»‹ç»ã€‚åœ¨<a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">Bahdanau et al., 2015.</a>ä¸­ï¼Œscore()é‡‡ç”¨å‰é¦ˆç¥ç»ç½‘ç»œï¼Œé‡‡ç”¨éçº¿æ€§æ¿€æ´»å‡½æ•°$tanh()$,score()çš„æ•°å­¦å½¢å¼ä¸ºï¼š$$score(s_{t},h_i) = v_a^\top tanh(W_a[s_t;h_i])$$<br>å…¶ä¸­$v_a,W_a$æ˜¯å¯è®­ç»ƒå‚æ•°ã€‚<br>attentionæƒé‡å¯è§†åŒ–çŸ©é˜µå¾ˆç›´è§‚åœ°è¡¨æ˜äº†source wordsä¸target wordsä¹‹é—´çš„å…³è”å…³ç³»:</p><div align="center"><img src="/images/45.png" width="60%" height="60%"></div><div align="center"><font color="grey" size="2">Fig.3.æ¥æº:[Bahdanau et al., 2015.](https://arxiv.org/pdf/1409.0473.pdf)</font></div><h3 id="å„ç§attentionæœºåˆ¶"><a href="#å„ç§attentionæœºåˆ¶" class="headerlink" title="å„ç§attentionæœºåˆ¶"></a>å„ç§attentionæœºåˆ¶</h3><h4 id="æ±‡æ€»"><a href="#æ±‡æ€»" class="headerlink" title="æ±‡æ€»"></a>æ±‡æ€»</h4><p>ä¸‹è¡¨æ€»ç»“äº†ä½¿ç”¨æ¯”è¾ƒå¹¿æ³›çš„attentionæœºåˆ¶ï¼ŒåŠå…¶å¯¹åº”çš„alignment score functionã€‚</p><table class="table table-bordered table-striped table-condensed">   <tr>      <th width="25">åå­—</th>      <th>alignment score funtion</th>      <th width="25">æ¥æº</th>   </tr>   <tr>      <td>content-based attention</td>      <td>$score(s_t,h_i) = cosine(s_t,h_i)$</td>      <td><a href="https://arxiv.org/abs/1410.5401" target="_blank" rel="noopener">Graves2014</a></td>   </tr>   <tr>      <td>concat/additive</td>      <td>$score(s_{t},h_i) = v_a^\top tanh(W_a[s_t;h_i])$</td>      <td><a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">Bahdanau2015</a></td>   </tr>   <tr>      <td>location-based</td>      <td>$\alpha_{t,i} = softmax(W_as_t)$<br><font color="grey" size="2">å°†alignmentç®€åŒ–ä¸ºåªä¾èµ–äºtarget position</font></td>      <td><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a></td>   </tr>   <tr>      <td>general</td>      <td>$score(s_{t},h_i) = s_t^\top W_ah_i$</td>      <td><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a></td>   </tr>   <tr>      <td>dot-product</td>      <td>$score(s_{t},h_i) = s_t^\top h_i$<br><font color="grey" size="2">note:å½“general attentionçš„$W_a$ä¸ºå•ä½çŸ©é˜µæ—¶ï¼Œå°±é€€å‡ºä¸ºdot-product attention</font></td>      <td><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a></td>   </tr>   <tr>      <td>scaled <br>dot-product(*)</td>      <td>$score(s_{t},h_i) = \frac{s_t^\top h_i}{\sqrt{n}}$<br><font color="grey" size="2">note:è·Ÿdot-product attentionå¾ˆåƒï¼Œnæ˜¯encoder hidden state $h_i$çš„ç»´åº¦</font></td>      <td><a href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noopener">Vaswani2017</a></td>   </tr></table>(*)scaled dot-product attentionæœºåˆ¶æ·»åŠ äº†æ¯”ä¾‹å› å­$/frac{1}{/sqrt{n}}$ï¼ŒåŠ¨æœºæ˜¯ï¼šå¯¹äºsoftmax()å‡½æ•°ï¼Œå½“è¾“å…¥å¾ˆå¤§æ—¶ï¼Œå¯¹åº”çš„æ¢¯åº¦å¾ˆå°ï¼ˆæ¢¯åº¦é€æ¸æ¶ˆå¤±ï¼‰ï¼Œéš¾ä»¥è¿›è¡Œé«˜æ•ˆçš„ä¼˜åŒ–å’Œå­¦ä¹ ã€‚å› æ­¤ï¼Œæ·»åŠ æ¯”ä¾‹å› å­å¯ä»¥å‡å°$score(s_t,h_i)$ã€‚<p>ä¸‹è¡¨åˆ—å‡ºäº†æ›´å¹¿èŒƒç•´ä¸Šçš„attentionæœºåˆ¶ã€‚</p><table class="table table-bordered table-striped table-condensed">   <tr>      <th width="25">åå­—</th>      <th>å®šä¹‰</th>      <th width="25">æ¥æº</th>   </tr>   <tr>      <td>self attention(&)</td>      <td><font color="grey" size="2">å°†input sequenceçš„ä¸åŒéƒ¨åˆ†è”ç³»èµ·æ¥ï¼Œåªç”¨åˆ°input sequenceæœ¬èº«ï¼Œè€Œä¸ç”¨target sequenceã€‚<br>å¯ä»¥ä½¿ç”¨ä¸Šè¡¨ä¸­çš„æ‰€æœ‰score functionï¼Œåªè¦å°†target sequenceæ›¿æ¢ä¸ºinput sequenceå³å¯ã€‚</font></td>      <td><a href="https://arxiv.org/pdf/1601.06733.pdf" target="_blank" rel="noopener">Cheng2016</a></td>   </tr>   <tr>      <td>global/soft attention</td>      <td><font color="grey" size="2">context vectoræ˜¯æ•´ä¸ªinput sequenceçš„åŠ æƒå’Œï¼Œæ³¨æ„åˆ°æ•´ä¸ªinput sequence</font></td>      <td><a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank" rel="noopener">Xu2015</a></td>   </tr>   <tr>      <td>local/hard attention</td>      <td><font color="grey" size="2">context vectoræ˜¯å±€éƒ¨input sequenceçš„åŠ æƒå’Œï¼Œæ³¨æ„åˆ°å±€éƒ¨input sequence</font></td>      <td><a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank" rel="noopener">Xu2015</a>ï¼Œ<br><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a></td>   </tr></table>(&)self-attentionåœ¨ä¸€äº›è®ºæ–‡ä¸­ä¹Ÿè¢«ç§°ä¸ºintra-attention.<h4 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a>self-attention</h4><p>self-attention,æœ€å…ˆåœ¨<a href="https://arxiv.org/pdf/1601.06733.pdf" target="_blank" rel="noopener">Cheng2016</a>æå‡ºç§°ä¸ºâ€intra-attentionâ€ï¼Œåæ¥åœ¨å¤§ä½œ<a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener">attention is all you need</a>ä¸­å‘æŒ¥äº†æ›´å¤§çš„å½±å“åŠ›ã€‚self-attentionå°†åŒä¸€ä¸ªsequenceçš„ä¸åŒä½ç½®çš„tokensè”ç³»èµ·æ¥ï¼Œå»ºæ¨¡tokensä¹‹é—´çš„å…³ç³»ï¼Œè®¡ç®—è¿™ä¸ªsequenceçš„å‘é‡è¡¨ç¤ºã€‚[Cheng2016]æå‡ºself-attentionçš„åŠ¨æœºæ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ</p><p>æˆ‘ä»¬å…ˆçœ‹ä»¥ä¸‹LSTMçš„å±€é™ã€‚LSTMåœ¨ç¼–ç sequenceçš„å‘é‡è¡¨ç¤ºæ—¶ï¼Œéšè—çŠ¶æ€æ›´æ–°å…¬å¼ä¸ºï¼š$$h_t = f(h_{t-1},x_t)$$ä»è¿™ä¸ªæ›´æ–°å…¬å¼å¯ä»¥çœ‹åˆ°ï¼šåœ¨ç»™å®š$h_t$çš„æ¡ä»¶ä¸‹ï¼Œ$h_{t+1}$ä¸ä¹‹å‰çš„çŠ¶æ€$\lbrace{h_1,h_2,â€¦,h_{t-1}}\rbrace$åŠä¹‹å‰çš„tokens $\lbrace{x_1,x_2,â€¦,x_t}\rbrace$æ˜¯æ¡ä»¶ç‹¬ç«‹çš„ã€‚LSTMçš„æ½œåœ¨å‡è®¾æ˜¯å½“å‰çŠ¶æ€$h_t$åŒ…å«äº†ä¹‹å‰æ‰€æœ‰tokensçš„ä¿¡æ¯ï¼Œè¿™ç›¸å½“äºå‡è®¾LSTMæœ‰æ— é™å¤§çš„memoryï¼Œè¿™ä¸ªå‡è®¾å®é™…ä¸Šæ˜¯ä¸æˆç«‹çš„ã€‚å®é™…ä¸ŠLSTMä¼šåå‘äºæ›´è¿‘çš„tokensï¼Œè€Œé€æ¸é—å¿˜è·ç¦»æ›´è¿œçš„tokensã€‚å¦ä¸€æ–¹é¢ï¼ŒLSTMåœ¨ç¼–ç tokençš„éšè—çŠ¶æ€æ—¶ï¼Œæ²¡æœ‰å»ºæ¨¡tokensä¹‹é—´çš„å…³ç³»ã€‚è€Œè¿™æ°æ°å°±æ˜¯self-attentionè¦è§£å†³çš„é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯self-attentionçš„æ ¸å¿ƒæ€æƒ³ï¼šåœ¨è®¡ç®—sequenceçš„å‘é‡è¡¨ç¤ºæ—¶ï¼Œå¼•å…¥tokensä¹‹é—´çš„å…³ç³»ã€‚</p><p>æ¥ä¸‹æ¥çœ‹self-attentionçš„æ•°å­¦è¡¨ç¤ºã€‚å¯¹äºsequence $\lbrace{x_1,x_2,â€¦,x_n}\rbrace$ï¼Œæ¯ä¸ªtoken $x_t$åˆ†åˆ«å¯¹åº”ä¸€ä¸ªhidden vector å’Œmemory vectorã€‚å½“å‰çš„memory tape $C_{t-1} = \lbrace{c_1,c_2,â€¦,c_{t-1}}\rbrace$ï¼Œhidden state tapeä¸º$H_{t-1} = \lbrace{h_1,h_2,â€¦,h_{t-1}}\rbrace$ã€‚self-attentionè®¡ç®—$x_t$ä¸$\lbrace{x_1,x_2,â€¦,x_{t-1}}\rbrace$ä¹‹é—´çš„å…³ç³»ï¼š$$\beta_{t,i} = score(x_t,h_i) = v^\top tanh(W_hh_i,W_xx_t,W_{\tilde{h}}\tilde{h_{t-1}})$$ $$\alpha_{t,i} = softmax(\beta_{t,i})  ;i\in[1,t-1]$$</p><p>attentionæƒé‡$\alpha_{t,i}$æ˜¯tæ—¶é—´æ­¥x_tåœ¨ä¹‹å‰çš„tokens $\lbrace{x_1,x_2,â€¦,x_{t-1}}\rbrace$å¯¹åº”çš„hidden vectorä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚<div align="center"><img src="/images/46.png" width="60%" height="60%"></div></p><div align="center"><font color="grey" size="2">Fig.4.çº¢è‰²è¡¨ç¤ºå½“å‰tokenï¼Œè“è‰²çš„æ·±æµ…è¡¨ç¤ºç›¸å…³ç¨‹åº¦ã€‚<br>æ¥æº:[Cheng2016](https://arxiv.org/pdf/1601.06733.pdf)</font></div><p>æ¯”è¾ƒä¸€ä¸‹self-attentionæœºåˆ¶ä¸ä¼ ç»Ÿattentionæœºåˆ¶çš„åŒºåˆ«ï¼š</p><ul><li>ä¼ ç»Ÿçš„attentionæœºåˆ¶æ˜¯å°†target sequenceä¸source sequenceè”ç³»èµ·æ¥ï¼Œattentionæƒé‡$\lbrace{\alpha_{t,1},\alpha_{t,2},â€¦,\alpha_{t,n}}\rbrace$æ˜¯åœ¨encoder hidden states $\lbrace{h_1,h_2,â€¦,h_n}\rbrace$ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚è€Œself-attentionæ˜¯å°†åŒä¸ªsequenceä¸åŒä½ç½®çš„tokensè”ç³»èµ·æ¥ï¼Œattentionæƒé‡$\alpha_{t,i}$æ˜¯tæ—¶é—´æ­¥$x_t$åœ¨ä¹‹å‰çš„tokens $\lbrace{x_1,x_2,â€¦,x_{t-1}}\rbrace$å¯¹åº”çš„hidden vectorä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚</li><li>ä¼ ç»Ÿçš„attentionæœºåˆ¶å¸¸ä¸RNNè”åˆä½¿ç”¨ï¼Œåœ¨transformerä¸­self-attentionå¯ä»¥ä¸RNNè§£è€¦å¼€ï¼ˆä¹Ÿå°±æ˜¯åˆ†å¼€ä½¿ç”¨ï¼‰ï¼Œå•ç‹¬ç”¨self-attentionä¹Ÿå¯ä»¥ç¼–ç sequenceçš„è¡¨ç¤ºå‘é‡ã€‚</li></ul><h4 id="soft-vs-hard-attention"><a href="#soft-vs-hard-attention" class="headerlink" title="soft vs hard attention"></a>soft <em>vs</em> hard attention</h4><p><a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank" rel="noopener">Show, Attend and Tell,Kelvin Xu2015</a>å°†attentionæœºåˆ¶ç”¨åˆ°äº†â€ç»™å›¾ç‰‡ç”Ÿæˆæè¿°â€çš„ä»»åŠ¡ï¼Œç¬¬ä¸€æ¬¡æ˜ç¡®åŒºåˆ†äº†hard attentionä¸soft attentionï¼ŒåŒºåˆ†çš„ä¾æ®æ˜¯attentionæ˜¯å…³æ³¨åˆ°æ•´å¼ å›¾ç‰‡ï¼Œè¿˜æ˜¯å›¾ç‰‡çš„å±€éƒ¨ã€‚</p><ul><li>soft attentionï¼šattentionå…³æ³¨åˆ°æ•´å¼ å›¾ç‰‡ï¼Œæˆ–è€…æ˜¯æ•´ä¸ªåºåˆ—ã€‚alignment æƒé‡$\alpha_{t,i}$æ˜¯åœ¨æ•´ä¸ªåºåˆ—ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚å°±åƒæ™®é€šçš„attentionä¸€æ ·ã€‚<ul><li>å¥½å¤„ï¼šæ¨¡å‹æ˜¯å¯å¾®çš„ã€‚</li><li>åå¤„ï¼šè®¡ç®—é‡æ¯”è¾ƒå¤§ã€‚</li></ul></li><li>hard attentionï¼šattentionå…³æ³¨åˆ°å›¾ç‰‡çš„å±€éƒ¨ï¼Œæˆ–è€…æ˜¯åºåˆ—çš„ä¸€éƒ¨åˆ†ã€‚<ul><li>å¥½å¤„ï¼šå‡å°‘äº†è®¡ç®—é‡ã€‚</li><li>åå¤„ï¼šæ¨¡å‹ä¸å¯å¾®ï¼Œéœ€è¦ç”¨æ›´å¤æ‚çš„æŠ€æœ¯ï¼Œæ¯”å¦‚å¼ºåŒ–å­¦ä¹ æˆ–è€…æ–¹å·®ç¼©å‡æ¥è®­ç»ƒæ¨¡å‹ã€‚<a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a></li></ul></li></ul><h4 id="global-vs-local-attention"><a href="#global-vs-local-attention" class="headerlink" title="global vs local attention"></a>global <em>vs</em> local attention</h4><p><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a>åœ¨NMTä»»åŠ¡ä¸Šæå‡ºäº†global å’Œlocal attentionçš„æ¦‚å¿µã€‚åŒºåˆ†çš„ä¾æ®æ˜¯attentionæ˜¯å…³æ³¨åˆ°æ•´ä¸ªåºåˆ—ï¼Œè¿˜æ˜¯å…³æ³¨åˆ°åºåˆ—çš„ä¸€éƒ¨åˆ†ã€‚</p><ul><li>global attentionã€‚ ç±»ä¼¼äºsoft attentionï¼Œå…³æ³¨åˆ°æ•´ä¸ªåºåˆ—ã€‚è¿™é‡Œæ¯”è¾ƒä¸‹<a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a>çš„global attentionä¸<a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">Bahdanau2015</a>ä¸­attentionçš„åŒºåˆ«ã€‚<ul><li><a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">Bahdanau2015</a>ä¸­attentionçš„è®¡ç®—è·¯å¾„æ˜¯ï¼š$s_{t-1} \to \alpha_{t} \to c_t \to s_t$<br>$$\beta_{t,i} = score(s_{t-1},h_i)$$ $$\alpha_{t,i} = softmax(\beta_{t,i})$$ $$c_t = \sum_{i = 1}^{n}\alpha_{t,i}h_i$$ $$RNNæ›´æ–°å…¬å¼ï¼šs_t = f(s_{t-1},y_{t-1},c_t)$$ $$y_té¢„æµ‹å…¬å¼:p(y_t|y_{&lt; t},x) = g(y_{t-1},c_t,s_t)$$</li><li><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank" rel="noopener">Luong2015</a>çš„global attentionçš„è®¡ç®—è·¯å¾„æ˜¯ï¼š$s_t \to \alpha_{t} \to c_t \to \tilde{s_t}$<br>$$\beta_{t,i} = score(s_{t},h_i)$$ $$\alpha_{t,i} = softmax(\beta_{t,i})$$ $$c_t = \sum_{i = 1}^{n}\alpha_{t,i}h_i$$ $$RNNæ›´æ–°å…¬å¼ï¼šs_t = f(s_{t-1},y_{t-1},c_t)$$ $$\tilde{s_t} = tanh(W_c[c_t,s_t])$$ $$y_té¢„æµ‹å…¬å¼:p(y_t|y_{&lt; t},x) = softmax(W_s\tilde{s_t})$$</li></ul></li><li>local attentionã€‚æ˜¯soft ä¸hard attentionçš„ç»“åˆï¼Œå…³æ³¨åˆ°åºåˆ—çš„ä¸€éƒ¨åˆ†ã€‚å¯¹hard attentionè¿›è¡Œæ”¹è¿›ï¼Œä½¿å¾—æ¨¡å‹å¯å¾®ï¼Œè®­ç»ƒå’Œè®¡ç®—å˜å¾—æ›´å®¹æ˜“ã€‚æ”¹è¿›çš„æ–¹æ³•å¦‚ä¸‹ï¼š<ol><li>å¯¹äºæ—¶é—´æ­¥tçš„target token $y_t$å…ˆç”¨æ¨¡å‹é¢„æµ‹ï¼Œç”Ÿæˆä¸€ä¸ªå¯¹é½çš„ä½ç½®$p_t$ï¼Œ</li><li>å†æ ¹æ®å›ºå®šçª—å£å¤§å°å†…$[p_t - D,p_t + D]$çš„encoder hidden stateæ¥è®¡ç®—context vectorã€‚Dæ˜¯çª—å£å¤§å°ï¼Œæ˜¯æŒ‰ç»éªŒå®šä¹‰å¥½çš„ã€‚</li></ol></li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/47.png" alt="Fig.5. global and local attenion.<br>æ¥æºï¼š[Luong2015](https://arxiv.org/pdf/1508.04025.pdf)" title>                </div>                <div class="image-caption">Fig.5. global and local attenion.<br>æ¥æºï¼š[Luong2015](https://arxiv.org/pdf/1508.04025.pdf)</div>            </figure><h3 id="pointer-network"><a href="#pointer-network" class="headerlink" title="pointer network"></a>pointer network</h3><p>å¯¹äºè¾“å‡ºåºåˆ—çš„ç±»åˆ«æ•°ä¾èµ–äºè¾“å…¥åºåˆ—çš„é•¿åº¦çš„é—®é¢˜ï¼Œseq2seqæ¨¡å‹æˆ–ç¥ç»å›¾çµæœºä¸èƒ½è§£å†³ã€‚å› ä¸ºè¿™ç±»é—®é¢˜ä¸­ï¼Œè¾“å‡ºçš„ç±»åˆ«æ•°æ˜¯å¯å˜çš„ï¼Œè€Œseq2seqæ¨¡å‹çš„decoderåªèƒ½åœ¨å›ºå®šæ•°ç›®çš„ç±»åˆ«ä¸Šç”Ÿæˆä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚<a href="https://arxiv.org/abs/1506.03134" target="_blank" rel="noopener">Vinyals2017</a>æå‡ºäº†pointer networkï¼ˆPr_Netï¼‰æ¥è§£å†³è¾“å‡ºè¯è¡¨å¯å˜çš„é—®é¢˜ã€‚pointer networkå®é™…ä¸Šæ˜¯ä»¥attentionä¸ºåŸºç¡€çš„ã€‚</p><p>æˆ‘ä»¬æ¯”è¾ƒä¸‹attentionæœºåˆ¶ä¸pointer networkçš„åŒºåˆ«ã€‚<br>è®°è¾“å…¥åºåˆ—$X = \lbrace{x_1,â€¦,x_n}\rbrace$,è¾“å‡ºåºåˆ—$Y = {y_1,â€¦,y_m}$ï¼Œ$y_j$æ˜¯Xçš„ä½ç½®ç´¢å¼•ï¼Œ$y_i \in [1,n] $ã€‚<br>encoderçš„æ‰€æœ‰hidden stateä¸º$\lbrace{h_1,h_2,â€¦,h_n}\rbrace$ï¼Œdecoderåœ¨æ—¶é—´æ­¥tçš„éšè—çŠ¶æ€ä¸º$s_t$ï¼Œåˆ™ï¼š</p><ul><li>attentionæœºåˆ¶ç”¨alignmentæƒé‡æ¥è®¡ç®—context vectorï¼š<br> $$\beta_{t,i} = score(s_t,h_i) = v^\top tanh(W_ss_t,W_hh_i); i \in [1,n]$$ $$\alpha_{t,i} = softmax(\beta_{t,i})$$ $$c_t = \sum_{i=1}^{n}\alpha_{t,i}h_i$$</li><li>pointer networkåˆ™ç”¨alignmentæƒé‡åœ¨ä½œä¸ºåœ¨è¾“å…¥åºåˆ—ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒï¼Œå°†è¾“å…¥åºåˆ—ä¸­çš„tokenç›´æ¥å¤åˆ¶åˆ°è¾“å‡ºåºåˆ—ä¸­ï¼š<br> $$\beta_{t,i} = score(s_t,h_i) = v^\top tanh(W_ss_t,W_hh_i); i \in [1,n]$$ $$p(y_i|y_{&lt; i},X) = softmax(\beta_{t,i})$$<div align="center"><img src="/images/49.png" width="60%" height="60%"></div><div align="center"><font color="grey" size="2">Fig.6.Pointer Network model<br>æ¥æº:[Vinyals2017](https://arxiv.org/abs/1506.03134)</font></div></li></ul><h4 id="pointer-networkè§£å†³OOVé—®é¢˜"><a href="#pointer-networkè§£å†³OOVé—®é¢˜" class="headerlink" title="pointer networkè§£å†³OOVé—®é¢˜"></a>pointer networkè§£å†³OOVé—®é¢˜</h4><p>ä»€ä¹ˆæ˜¯OOVï¼ˆout of vocabularyï¼‰é—®é¢˜ï¼Ÿåœ¨åºåˆ—ï¼ˆsource sequenceï¼‰åˆ°åºåˆ—ï¼ˆtarget sequenceï¼‰çš„æ˜ å°„é—®é¢˜ï¼ˆå¯¹è¯ç³»ç»Ÿï¼Œé—®ç­”ç³»ç»Ÿï¼‰ä¸­ï¼Œä¼šæ ¹æ®è®­ç»ƒé›†è¯­æ–™æ¥æ„å»ºè¯è¡¨ï¼Œæ ¹æ®å®Œæˆ$word \to index \to embedding$çš„å‘é‡åŒ–è¡¨ç¤ºã€‚è€Œåœ¨æµ‹è¯•é›†çš„source sequenceä¸­éš¾å…ä¼šå‡ºç°ä¸€äº›è¯è¡¨ä¸­æ²¡æœ‰çš„è¯ï¼Œé€šå¸¸ä¼šå°†è¿™äº›out of vocabularyçš„è¯æ˜ å°„åˆ°ä¸€ä¸ªç‰¹å®šçš„å­—ç¬¦â€UNKâ€ï¼Œè€Œdecoderåœ¨ç”Ÿæˆresponseæ—¶ä¹Ÿå¯èƒ½ç”Ÿæˆâ€UNKâ€è¿™ä¸ªç‰¹æ®Šå­—ç¬¦ã€‚è¿™å°±æ˜¯OOVé—®é¢˜ã€‚</p><p>pointer networkæ˜¯è§£å†³OOVé—®é¢˜çš„æœ‰æ•ˆæ–¹æ³•ã€‚å½“source sequenceä¸­å‡ºç°ä¸åœ¨è¯è¡¨ä¸­çš„è¯æ—¶ï¼Œpointer networkå¯ä»¥ç›´æ¥å°†è¿™ä¸ªç”Ÿè¯ä»è¾“å…¥åºåˆ—å¤åˆ¶åˆ°è¾“å‡ºåºåˆ—ä¸­ã€‚<a href="https://arxiv.org/abs/1704.04368" target="_blank" rel="noopener">Abigail See2017</a>å°±ç”¨äº†pointer networkæ¥è§£å†³OOVé—®é¢˜ã€‚</p><p>è®°æ—¶é—´æ­¥t decoderçš„éšè—çŠ¶æ€ä¸º$s_t$,å¯¹åº”çš„context vectorä¸º$c_t$,alignmentæƒé‡ä¸º$\alpha_{t,i},i \in [1,n]$</p><ol><li>åœ¨è¯æ±‡è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒä¸º:$p_{vocab} = softmax(W[s_t,c_t] + b)$</li><li>åœ¨è¾“å…¥åºåˆ—çš„æ¦‚ç‡åˆ†å¸ƒä¸º:$p_{ptr} = \alpha_{t,i} = softmax(\beta_{t_i})$</li><li>é€‰æ‹©å¼€å…³ä¸º: $p_{gen} = sigmoid(W_ss_t + W_cc_t + W_xx_t + b)$<br>ä¸ºé€»è¾‘å›å½’ï¼Œå–å€¼ä¸º[0,1]</li><li>æœ€ç»ˆåœ¨extend vocabularyä¸Šçš„æ¦‚ç‡åˆ†å¸ƒä¸º:$p(w) = p_{gen}p_{vocab} + (1-p_{gen})p_{ptr}$.<br>å½“$p_{gen}$ä¸º1æ—¶ï¼Œä»è¯æ±‡è¡¨ä¸­ç”Ÿæˆwordï¼›å½“$p_{gen}$ä¸º0æ—¶ï¼Œå°†è¾“å…¥åºåˆ—çš„è¯å¤åˆ¶åˆ°è¾“å‡ºåºåˆ—ä¸­ã€‚</li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/48.png" alt="Fig.7.Pointer-generator model.<br>æ¥æºï¼š[Abigail See2017](https://arxiv.org/abs/1704.04368)" title>                </div>                <div class="image-caption">Fig.7.Pointer-generator model.<br>æ¥æºï¼š[Abigail See2017](https://arxiv.org/abs/1704.04368)</div>            </figure> <p>ç±»ä¼¼çš„è®ºæ–‡è¿˜æœ‰ï¼š<a href="https://arxiv.org/pdf/1603.06393v3.pdf" target="_blank" rel="noopener">CopyNet,Jiatao Gu2016</a></p><h3 id="transformer"><a href="#transformer" class="headerlink" title="transformer"></a>transformer</h3><p><a href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noopener">attention is all you need!</a>(Vaswani, et al., 2017)æå‡ºäº†transformerã€‚transformerä¹Ÿæ˜¯åŸºäºencoder-decoderæ¡†æ¶çš„ï¼Œä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªseq2seqæ¨¡å‹ã€‚ä½†ä¸åŒäºencoderå’Œdecoderéƒ½é‡‡ç”¨RNNçš„seq2seqæ¨¡å‹ï¼Œtransformerå®Œå…¨ä¾èµ–self-attentionæœºåˆ¶æ¥è®¡ç®—inputå’Œoutputçš„å‘é‡è¡¨ç¤ºï¼Œè€Œä¸ä½¿ç”¨RNNæˆ–CNNã€‚ä¸€èˆ¬æ¥è¯´ï¼Œattentionæœºåˆ¶æ˜¯ä¸RNNè”åˆä½¿ç”¨çš„ï¼ŒtransformeræŠŠattentionå’ŒRNNè§£è€¦å¼€äº†ï¼Œåªä½¿ç”¨attentionæœºåˆ¶ã€‚</p><p>ä¸ºä»€ä¹ˆtransformerç”¨self-attentionæ¥ç¼–ç inputå’Œoutputï¼Œè€Œä¸ä½¿ç”¨RNNå‘¢ï¼Ÿ<br>ä¸€æ–¹é¢ï¼Œç”±RNNçš„æ›´æ–°å…¬å¼$s_t = f(s_{t-1},x_t)$å¯ä»¥çœ‹åˆ°ï¼ŒRNNå¤„ç†åºåˆ—æ—¶æ˜¯ä¸²è¡Œè®¡ç®—çš„ï¼Œå°¤å…¶æ˜¯å¤„ç†é•¿åºåˆ—æ—¶æ›´è´¹æ—¶é—´ã€‚ä¸åˆ©äºå¹¶è¡ŒåŒ–ï¼Œè®¡ç®—æ•ˆç‡ä½ã€‚è€Œtransformeré‡‡ç”¨attentionæ¥ç¼–ç è®¡ç®—å‘é‡ï¼Œå¯ä»¥è¿›è¡Œå¹¶è¡ŒåŒ–è®¡ç®—ï¼Œæé«˜è®¡ç®—æ•ˆç‡ã€‚<br>å¦ä¸€æ–¹é¢ï¼ŒRNNåœ¨ç¼–ç é•¿åºåˆ—æ—¶ï¼Œéšç€è·ç¦»çš„å¢å¤§ï¼Œå¾€å¾€ä¼šåå‘äºæœ€è¿‘çš„éƒ¨åˆ†ï¼Œè€Œå­¦ä¹ ä¸åˆ°é•¿æœŸä¾èµ–ã€‚ä½†self-attentionæœºåˆ¶ä¸å—è·ç¦»çš„é™åˆ¶ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ åˆ°é•¿æœŸä¾èµ–ã€‚</p><h4 id="scaled-dot-product-attentionä¸key-value-query"><a href="#scaled-dot-product-attentionä¸key-value-query" class="headerlink" title="scaled dot-product attentionä¸key,value,query"></a>scaled dot-product attentionä¸key,value,query</h4><p>transformerçš„ä¸»è¦ç»„ä»¶æ˜¯<em>multi-heads self-attenion mechanism</em>ï¼Œè¿™ä¸ªç»„ä»¶ç”¨åˆ°äº†scaled dot-product attentionæœºåˆ¶ã€‚ä¸€èˆ¬åœ°ï¼Œattentionæœºåˆ¶å°†queryå’Œ(key,value)æ˜ å°„ä¸ºoutputï¼Œå…¶ä¸­query,key,value,outputéƒ½æ˜¯vectorã€‚outputæ˜¯æ‰€æœ‰valuesçš„åŠ æƒå’Œï¼Œæƒé‡æ˜¯é€šè¿‡è®¡ç®—queryä¸å¯¹åº”keyä¹‹é—´çš„å…³è”åº¦å¾—åˆ°ã€‚</p><p>å…·ä½“æ¥è¯´ï¼Œå°†ä»€ä¹ˆä½œä¸ºkey,value,queryï¼Ÿåˆ†ä¸¤ç§æƒ…å†µï¼Œä»æ¡†å›¾å¯ä»¥ç›´è§‚çš„çœ‹åˆ°ï¼š</p><ul><li>åœ¨encoder-decoderæ¡†æ¶ä¸­ï¼Œè”ç³»encoderä¸decoderçš„attentionæœºåˆ¶é€šå¸¸å°†encoderçš„æ‰€æœ‰hidden statesä¹˜ä»¥ä¸¤ä¸ªä¸åŒçš„çŸ©é˜µ$W^Q,W^K$åˆ†åˆ«ä½œä¸º<em>keys</em>å’Œ<em>values</em>ã€‚å°†decoderä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„hidden stateä½œä¸ºqueryã€‚</li><li>åœ¨encoderæ¨¡å—ï¼Œself-attentionæœºåˆ¶å°†inputè¯çº§åˆ«çš„å‘é‡è¡¨ç¤ºä¹˜ä»¥ä¸‰ä¸ªä¸åŒçš„çŸ©é˜µ$W^Q,W^K,W^V$åˆ†åˆ«ä½œä¸ºquery,key,valueã€‚è¿›è€Œè®¡ç®—inputæ€»çš„å¥å­çº§åˆ«çš„å‘é‡è¡¨ç¤ºã€‚åŒæ ·åœ°ï¼Œåœ¨decoderæ¨¡å—ä¸­self-attentionæœºåˆ¶å°†outputè¯çº§åˆ«çš„å‘é‡è¡¨ç¤ºåˆ†åˆ«ä¹˜ä»¥ä¸‰ä¸ªä¸åŒçŸ©é˜µ$W^Q,W^K,W^V$åˆ†åˆ«ä½œä¸ºquery,key,valueã€‚è¿›è€Œè®¡ç®—outputæ€»çš„å¥å­çº§åˆ«çš„å‘é‡è¡¨ç¤ºã€‚</li></ul><p>æœ‰äº†å…·ä½“çš„key,value,queryåï¼Œscaled dot-product attentionæœºåˆ¶æ€ä¹ˆæ¥è®¡ç®—outputå‘¢ï¼Ÿ<br>è®°query,key,valueçš„çŸ©é˜µå½¢å¼åˆ†åˆ«ä¸ºQ,K,Vã€‚queryå’Œkeyç»´åº¦ä¸º$d_k$,valueç»´åº¦ä¸º$d_v$ã€‚åˆ™outputçš„è®¡ç®—æ–¹å¼ä¸ºï¼š$$Attention(Q,K,V) = softmax(\frac{QK^\top}{\sqrt{d_k}})V$$</p><p>å¤šç§attentionæœºåˆ¶ä¸­ï¼Œtransformerä¸ºä»€ä¹ˆé€‰æ‹©é‡‡ç”¨scale dot-product attentionæœºåˆ¶å‘¢ï¼Ÿ<br>æœ€å¸¸ç”¨çš„ä¸¤ç§attentionæœºåˆ¶æ˜¯dot-productå’Œadditive attentionæœºåˆ¶ã€‚dot-product attentionç”¨ç‚¹ä¹˜æ¥åšæ‰“åˆ†å‡½æ•°ï¼Œadditive attenionå°†æœ‰ä¸€å±‚éšè—å±‚çš„å‰é¦ˆç½‘ç»œä½œä¸ºæ‰“åˆ†å‡½æ•°ã€‚ç†è®ºä¸Šæ¥è¯´ï¼Œè¿™ä¸¤ç§attentionçš„è®¡ç®—å¤æ‚åº¦æ˜¯ä¸€æ ·çš„ï¼›ä½†å®é™…ä¸Šï¼Œdot-product attentionè®¡ç®—æ›´å¿«ï¼Œå ç”¨å†…å­˜æ›´å°ã€‚å› ä¸ºdot-product attentionæœºåˆ¶å¯ä»¥é‡‡ç”¨é«˜åº¦ä¼˜åŒ–çš„çŸ©é˜µä¹˜æ³•ä»£ç ã€‚<br>å½“ç»´åº¦$d_k$è¾ƒå°æ—¶ï¼Œè¿™ä¸¤ç§attentionæœºåˆ¶çš„æ•ˆæœæ˜¯å·®ä¸å¤šçš„ã€‚å½“ç»´åº¦$d_k$æ›´å¤§æ—¶ï¼Œadditive attentionçš„æ•ˆæœè¦å¥½äºdot-product attentionã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºå½“ç»´åº¦$d_k$å˜å¤§æ—¶ï¼Œç‚¹ä¹˜çš„å€¼å˜å¾—è¿‡å¤§ï¼Œè€Œsoftmax()å‡½æ•°åœ¨å€¼è¿‡å¤§çš„èŒƒå›´æ¢¯åº¦æ˜¯å¾ˆå°çš„ï¼Œç±»ä¼¼äºæ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚å› æ­¤ï¼Œæ·»åŠ æ¯”ä¾‹å› å­$\frac{1}{\sqrt{d_k}}$æ¥å‡å°ç‚¹ä¹˜çš„å€¼ã€‚</p><h4 id="multi-head-attention"><a href="#multi-head-attention" class="headerlink" title="multi-head attention"></a>multi-head attention</h4><p>å¹¶ä¸æ˜¯åªç”¨ä¸€æ¬¡attentionæœºåˆ¶ï¼Œå°†ç»´åº¦ä¸º$d_{model}$çš„key,value,queryæ˜ å°„ä¸ºoutputã€‚è€Œæ˜¯å°†query,key,valueæ˜ å°„åˆ°ç»´åº¦ä¸º$d_k,d_k,d_v$ä¸åŒçš„å­å‘é‡ç©ºé—´ï¼Œå¹¶è¡Œçš„è®¡ç®—$h$æ¬¡ï¼Œåˆ†åˆ«å¾—åˆ°outputåšconcatæ“ä½œï¼Œå¾—åˆ°æ€»çš„outputã€‚$h$ä¸ºheadçš„ä¸ªæ•°ï¼Œä¹Ÿå°±æ˜¯å¹¶è¡Œattention layerçš„å±‚æ•°ã€‚æœ‰å…³ç³»$d_{model} = d_v \cdot h$ï¼Œè®ºæ–‡ä¸­é‡‡ç”¨$d_{model} =512,h=8,d_k = d_v = \frac{d_{model}}{h} = 64$ $$MultiHead(Q,K,V) = concat(head_1,head_2,â€¦,head_h)W^O$$ $$where \quad head_i = Attention(QW_i^Q,KW_i^K,VW_i^V)$$ å…¶ä¸­$W_i^Q \in R^{d_{model} \cdot d_k},W_i^K \in R^{d_{model} \cdot d_k},W_i^V \in R^{d_{model} \cdot d_v},W^O \in R^{hd_{v} \cdot d_{model}}$</p><div align="center"><img src="/images/multi-head-attention.png" width="40%" height="40%"></div><div align="center"><font color="grey" size="2">Fig.7.multi-head scaled dot-product attention</font><br><a href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noopener"><font color="grey" size="2">æ¥æº:Vaswani, et al., 2017</font></a></div><h4 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h4><p>encoderå°†input textç¼–ç ä¸ºåŸºäºattentionçš„åŒ…å«ä½ç½®ä¿¡æ¯çš„å‘é‡è¡¨ç¤ºã€‚</p><ul><li>ç”±6ä¸ªå®Œå…¨ç›¸åŒçš„å±‚å †å èµ·æ¥ã€‚</li><li>æ¯ä¸€å±‚åŒ…å«ä¸¤ä¸ªå­å±‚ã€‚ç¬¬ä¸€å­å±‚æ˜¯multi-head attentionå±‚ï¼Œç¬¬äºŒå±‚æ˜¯ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥å±‚ã€‚</li><li>ä¸¤ä¸ªå­å±‚ä¹‹é—´é‡‡ç”¨<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">æ®‹å·®è¿æ¥</a>ï¼Œå¹¶è¿›è¡Œå½’ä¸€åŒ–ã€‚è¿™æ ·æ‰€æœ‰å­å±‚çš„è¾“å‡ºéƒ½æœ‰ç›¸åŒçš„ç»´åº¦$d_{model} = 512$</li></ul><div align="center"><img src="/images/transformer-encoder.png" width="70%" height="70%"></div><div align="center"><font color="grey" size="2">Fig.9. transformer encoder</font><br><a href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noopener"><font color="grey" size="2">æ¥æº:Vaswani, et al., 2017</font></a></div><h4 id="decoder"><a href="#decoder" class="headerlink" title="decoder"></a>decoder</h4><p>ä»encoder outputå¾—åˆ°æ€»çš„context vectorï¼Œå¹¶æ®æ­¤ç”Ÿæˆresponseã€‚</p><ul><li>ä¸encoderç›¸åŒï¼Œç”±6ä¸ªå®Œå…¨ç›¸åŒçš„å±‚å †å èµ·æ¥ã€‚</li><li>æ¯ä¸€å±‚é™¤äº†encoderä¸­çš„ä¸¤ä¸ªå­å±‚å¤–ï¼Œè¿˜æ’å…¥äº†ä¸€ä¸ªmulti-head layeræ¥åœ¨æ‰€æœ‰encoder outputä¸Šè¿›è¡Œattentionæ“ä½œã€‚</li><li>ä¸¤ä¸ªå­å±‚ä¹‹é—´é‡‡ç”¨<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">æ®‹å·®è¿æ¥</a>ï¼Œå¹¶è¿›è¡Œå½’ä¸€åŒ–ã€‚</li><li>ç¬¬ä¸€ä¸ªmulti-head attention sub-layerè¿›è¡Œmaskæ“ä½œï¼Œmaskæ‰outputå½“å‰æ—¶é—´æ­¥åæ‰€æœ‰çš„tokensã€‚é˜²æ­¢attentionæœºåˆ¶çœ‹åˆ°æœªæ¥çš„ä¿¡æ¯ã€‚</li></ul><div align="center"><img src="/images/transformer-encoder.png" width="70%" height="70%"></div><div align="center"><font color="grey" size="2">Fig.10. transformer decoder</font><br><a href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noopener"><font color="grey" size="2">æ¥æº:Vaswani, et al., 2017</font></a></div><h4 id="transformerçš„æ€»ä½“ç»“æ„"><a href="#transformerçš„æ€»ä½“ç»“æ„" class="headerlink" title="transformerçš„æ€»ä½“ç»“æ„"></a>transformerçš„æ€»ä½“ç»“æ„</h4><ul><li>inputå’Œoutputéƒ½å…ˆç»è¿‡ä¸€ä¸ªembedding layerå¾—åˆ°å„è‡ªçš„å‘é‡è¡¨ç¤ºï¼Œç»´åº¦ä¸º$d_{model} = 512$</li><li>ç”±äºself-attentionä¸èƒ½åƒRNNä¸€æ ·è‡ªåŠ¨åœ°ç¼–ç ä½ç½®ä¿¡æ¯ï¼Œå› æ­¤éœ€è¦é¢å¤–åœ°å°†ä½ç½®ä¿¡æ¯æ·»åŠ åˆ°è¾“å…¥ã€‚</li><li>åœ¨æœ€ådecoderçš„è¾“å‡ºå¤–æ¥ä¸€ä¸ªçº¿æ€§å±‚å’Œsoftmaxå±‚ã€‚</li></ul><div align="center"><img src="/images/transformer.png" width="150%" height="150%"></div><div align="center"><font color="grey" size="2">Fig.11. transformerçš„æ•´ä½“æ¡†æ¶</font><br><a href="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noopener"><font color="grey" size="2">æ¥æº:Vaswani, et al., 2017</font></a></div><h3 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h3><ul><li><a href="http://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">Attention? Attention!</a>  by Weng, Lilian</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;è¯»äº†åšä¸»&lt;a href=&quot;https://lilianweng.github.io/lil-log/contact.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Weng, Lilian&lt;/a&gt;çš„æ–‡ç« &lt;a href=&quot;https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#neural-turing-machines&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;attention? attention!&lt;/a&gt;ï¼Œæ˜¯ä¸€ç¯‡å¾ˆå¥½çš„æ–‡ç« ã€‚æ‰“ç®—æŒ‰ç…§è¿™ç¯‡æ–‡ç« çš„æ€è·¯ï¼Œè¿›è¡Œç¿»è¯‘ï¼Œå¹¶æ·»åŠ è‡ªå·±çš„ç†è§£ã€‚&lt;br&gt;attentionæœºåˆ¶åœ¨æ·±åº¦å­¦ä¹ ä¸­è¢«å¹¿ä¸ºä½¿ç”¨ï¼Œæœ¬æ–‡ä»‹ç»attentionæœºåˆ¶çš„æå‡ºï¼Œä¸åŒçš„attentionæœºåˆ¶ï¼ŒåŠattentionæœºåˆ¶çš„è¿›ä¸€æ­¥æ¢ç´¢å’Œåº”ç”¨ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="æ·±åº¦å­¦ä¹ " scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="rnn" scheme="http://yoursite.com/tags/rnn/"/>
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>pipå®‰è£…pythonæ¨¡å—æŠ¥é”™</title>
    <link href="http://yoursite.com/2019/07/12/pip%E5%AE%89%E8%A3%85python%E6%A8%A1%E5%9D%97%E6%8A%A5%E9%94%99/"/>
    <id>http://yoursite.com/2019/07/12/pipå®‰è£…pythonæ¨¡å—æŠ¥é”™/</id>
    <published>2019-07-12T01:51:58.000Z</published>
    <updated>2019-07-12T02:11:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>åœ¨ä½¿ç”¨<code>pip install</code>å‘½ä»¤å®‰è£…pythonæ¨¡å—æ—¶ï¼ŒæŠ¥é”™ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cannot uninstall &apos;PyYAML&apos;. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="é”™è¯¯åˆ†æ"><a href="#é”™è¯¯åˆ†æ" class="headerlink" title="é”™è¯¯åˆ†æ"></a>é”™è¯¯åˆ†æ</h3><p>æŠ¥é”™ä¿¡æ¯å‘Šè¯‰æˆ‘ä»¬ï¼šâ€œä¸èƒ½å¸è½½â€˜pyyamlâ€™æ¨¡å—ï¼Œå› ä¸ºè¿™ä¸ªæ¨¡å—æ˜¯<code>distutils</code>æ–¹å¼å®‰è£…çš„ï¼Œä¸èƒ½ç¡®å®šå“ªäº›æ–‡ä»¶å±äºè¿™ä¸ªæ¨¡å—ï¼Œå› æ­¤ä¸èƒ½å®Œæ•´åœ°å¸è½½è¿™ä¸ªæ¨¡å—ã€‚â€</p><p><a href="https://cloud.tencent.com/developer/section/1371690" target="_blank" rel="noopener">distutils</a>æ˜¯pythonæœ€åˆçš„æ¨¡å—å®‰è£…å’Œåˆ†å‘ç³»ç»Ÿï¼Œdistutilsä¸ä¼šä¿ç•™å“ªäº›æ–‡ä»¶å±äºå“ªä¸ªå®‰è£…åŒ…çš„ä¿¡æ¯ï¼Œç”šè‡³ä¸ä¼šä¿ç•™å®‰è£…åŒ…ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚ç›´æ¥ä½¿ç”¨<code>distutils</code>çš„æ–¹å¼å·²ç»è¢«æ·˜æ±°ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯<a href="https://setuptools.readthedocs.io/en/latest/" target="_blank" rel="noopener">setuptools</a>.<br>    æ‰€è°“æ¨¡å—çš„åˆ†å‘ï¼Œå°±æ˜¯å¼€å‘è€…æ‰“åŒ…å¹¶å‘å¸ƒè‡ªå·±çš„æ¨¡å—ï¼Œä¾›å…¶ä»–äººä½¿ç”¨ã€‚</p><p>è¿™æ ·æˆ‘ä»¬å°±çŸ¥é“äº†ï¼Œå› ä¸º<code>pyyaml</code>æ¨¡å—æ—¶é€šè¿‡<code>distutils</code>æ–¹å¼å®‰è£…çš„ï¼Œå› æ­¤ä¸èƒ½æ˜ç¡®æ–‡ä»¶ä¸åŒ…ä¹‹é—´çš„éš¶å±å…³ç³»ï¼Œä¸èƒ½æ­£ç¡®å¸è½½ã€‚</p><h3 id="è§£å†³åŠæ³•"><a href="#è§£å†³åŠæ³•" class="headerlink" title="è§£å†³åŠæ³•"></a>è§£å†³åŠæ³•</h3><p>ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤å¿½ç•¥å·²å®‰è£…çš„æ¨¡å—ï¼Œå¼ºåˆ¶å®‰è£…å’Œæ›´æ–°</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install &lt;package-name&gt; --ignore-installed &lt;pyyaml&gt; --upgrade</span><br></pre></td></tr></table></figure><h3 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h3><ul><li><a href="https://www.jianshu.com/p/94caf01dd9a6" target="_blank" rel="noopener">å¼ºåˆ¶å®‰è£…å’Œæ›´æ–°</a></li><li><a href="https://cloud.tencent.com/developer/ask/196670" target="_blank" rel="noopener">å¦‚ä½•åœ¨Windowsæ“ä½œç³»ç»Ÿä¸­å‡çº§/å¸è½½distutilsè½¯ä»¶åŒ…ï¼ˆPyYAMLï¼‰ï¼Ÿ</a></li><li><a href="https://docs.python.org/zh-cn/3/installing/index.html" target="_blank" rel="noopener">pythonå®˜æ–¹æ‰‹å†Œ-å®‰è£…pythonæ¨¡å—</a></li><li><a href="https://cloud.tencent.com/developer/section/1371690" target="_blank" rel="noopener">setuptoolsä¸distutils</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;åœ¨ä½¿ç”¨&lt;code&gt;pip install&lt;/code&gt;å‘½ä»¤å®‰è£…pythonæ¨¡å—æ—¶ï¼ŒæŠ¥é”™ï¼š&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Cannot uninstall &amp;apos;PyYAML&amp;apos;. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>NAACL2019-å¯¹è¯ç³»ç»Ÿ</title>
    <link href="http://yoursite.com/2019/07/10/NAACL2019-%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2019/07/10/NAACL2019-å¯¹è¯ç³»ç»Ÿ/</id>
    <published>2019-07-10T12:55:17.000Z</published>
    <updated>2019-07-21T15:03:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>è®°å½•NAACL2019å¯¹è¯ç³»ç»Ÿç›¸å…³çš„è®ºæ–‡é˜…è¯»ç¬”è®°ã€‚åŒ…æ‹¬ä»»åŠ¡å‹å’Œé—²èŠå¼å¯¹è¯ç³»ç»Ÿï¼Œå¯¹è®ºæ–‡çš„æ€è·¯å’Œæ¨¡å‹åšç®€å•ä»‹ç»ï¼Œå€¼å¾—åå¤ç²¾è¯»çš„è®ºæ–‡ä¼šå•ç‹¬å¼€ä¸€ç¯‡åšæ–‡æ¥å†™ã€‚<br>NAACL2019çš„ä¼šè®®åˆ—è¡¨é“¾æ¥ï¼š<a href="https://naacl2019.org/program/accepted/" target="_blank" rel="noopener">https://naacl2019.org/program/accepted/</a></p><a id="more"></a><h3 id="ã€ŠEvaluating-Coherence-in-Dialogue-Systems-using-Entailmentã€‹"><a href="#ã€ŠEvaluating-Coherence-in-Dialogue-Systems-using-Entailmentã€‹" class="headerlink" title="ã€ŠEvaluating Coherence in Dialogue Systems using Entailmentã€‹"></a>ã€ŠEvaluating Coherence in Dialogue Systems using Entailmentã€‹</h3><p>ã€é“¾æ¥ã€‘<a href="https://arxiv.org/abs/1904.03371" target="_blank" rel="noopener">https://arxiv.org/abs/1904.03371</a><br>ã€ä»£ç ã€‘<a href="https://github.com/nouhadziri/DialogEntailment" target="_blank" rel="noopener">https://github.com/nouhadziri/DialogEntailment</a></p><p>åŠ æ‹¿å¤§é˜¿å°”ä¼¯å¡”å¤§å­¦å‘è¡¨çš„è®ºæ–‡ã€‚è®ºæ–‡æå‡ºäº†ä¸€ç§è¯„ä¼°å¯¹è¯ç³»ç»Ÿç”Ÿæˆå›å¤å¥½åçš„æŒ‡æ ‡ã€‚<br>è¿™ç¯‡è®ºæ–‡çš„æƒ³æ³•æ¥æºäºï¼šå‘è¡¨åœ¨ACL2019ä¸Šçš„è®ºæ–‡<a href="https://arxiv.org/abs/1811.00671" target="_blank" rel="noopener">ã€ŠDialogue Natural Language Inferenceã€‹</a>æå‡ºåˆ©ç”¨NLI(natural language inference)ä»»åŠ¡æ¥æé«˜å¯¹è¯ç³»ç»Ÿç”Ÿæˆå›å¤çš„ä¸€è‡´æ€§ã€‚<br>æœ¬æ–‡çš„ä½œè€…åˆ™æƒ³åˆ°ç”¨NLIä»»åŠ¡æ¥è¯„ä¼°å¯¹è¯ç³»ç»Ÿç”Ÿæˆå›å¤çš„å¥½åã€‚å…·ä½“åœ°ï¼Œè®ºæ–‡ç”¨äº†BERT<a href="https://arxiv.org/abs/1609.06038" target="_blank" rel="noopener">[Devlin et al., 2018]</a>å’ŒThe Enhanced Sequential Inference Model(ESIM)<a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">[Chen et al., 2016]</a> è¿™ä¸¤ç§æ–¹æ³•æ¥è®­ç»ƒNLIæ¨¡å‹ã€‚å¦å¤–è®ºæ–‡è¿˜å…¬å¼€äº†ä¸€ä¸ªç”¨äºNLIä»»åŠ¡çš„æ•°æ®é›†ã€‚</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;è®°å½•NAACL2019å¯¹è¯ç³»ç»Ÿç›¸å…³çš„è®ºæ–‡é˜…è¯»ç¬”è®°ã€‚åŒ…æ‹¬ä»»åŠ¡å‹å’Œé—²èŠå¼å¯¹è¯ç³»ç»Ÿï¼Œå¯¹è®ºæ–‡çš„æ€è·¯å’Œæ¨¡å‹åšç®€å•ä»‹ç»ï¼Œå€¼å¾—åå¤ç²¾è¯»çš„è®ºæ–‡ä¼šå•ç‹¬å¼€ä¸€ç¯‡åšæ–‡æ¥å†™ã€‚&lt;br&gt;NAACL2019çš„ä¼šè®®åˆ—è¡¨é“¾æ¥ï¼š&lt;a href=&quot;https://naacl2019.org/program/accepted/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://naacl2019.org/program/accepted/&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="è®ºæ–‡" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="NAACL2019" scheme="http://yoursite.com/tags/NAACL2019/"/>
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
  </entry>
  
  <entry>
    <title>ACL2019-å¯¹è¯ç³»ç»Ÿ</title>
    <link href="http://yoursite.com/2019/07/07/ACL2019-%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2019/07/07/ACL2019-å¯¹è¯ç³»ç»Ÿ/</id>
    <published>2019-07-07T11:19:27.000Z</published>
    <updated>2019-07-31T03:40:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>è®°å½•ACL2019å¯¹è¯ç³»ç»Ÿç›¸å…³çš„è®ºæ–‡é˜…è¯»ç¬”è®°ã€‚åŒ…æ‹¬ä»»åŠ¡å‹å’Œé—²èŠå¼å¯¹è¯ç³»ç»Ÿï¼Œå¯¹è®ºæ–‡çš„æ€è·¯å’Œæ¨¡å‹åšç®€å•ä»‹ç»ï¼Œå€¼å¾—åå¤ç²¾è¯»çš„è®ºæ–‡ä¼šå•ç‹¬å¼€ä¸€ç¯‡åšæ–‡æ¥å†™ã€‚<br>ACL2019çš„ä¼šè®®åˆ—è¡¨é“¾æ¥ï¼š<a href="http://www.acl2019.org/EN/program.xhtml" target="_blank" rel="noopener">http://www.acl2019.org/EN/program.xhtml</a></p><a id="more"></a><h3 id="ã€ŠMemory-Consolidation-for-Contextual-Spoken-Language-Understanding-with-Dialogue-Logistic-Inferenceã€‹"><a href="#ã€ŠMemory-Consolidation-for-Contextual-Spoken-Language-Understanding-with-Dialogue-Logistic-Inferenceã€‹" class="headerlink" title="ã€ŠMemory Consolidation for Contextual Spoken Language Understanding with Dialogue Logistic Inferenceã€‹"></a>ã€ŠMemory Consolidation for Contextual Spoken Language Understanding with Dialogue Logistic Inferenceã€‹</h3><p>ã€é“¾æ¥ã€‘ï¼š<a href="https://arxiv.org/abs/1906.01788" target="_blank" rel="noopener">https://arxiv.org/abs/1906.01788</a><br>ã€æºç ã€‘ï¼šæ— </p><p>ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€å‘è¡¨çš„çŸ­è®ºæ–‡ã€‚åœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œå¯¹è¯å†å²ï¼ˆcontext informationï¼‰å¯¹å›å¤ï¼ˆresponseï¼‰çš„ç”Ÿæˆæœ‰é‡è¦ä½œç”¨ã€‚ä»»åŠ¡å‹å¯¹è¯ä¸­çš„ç®¡é“æ¨¡å‹åˆ†ä¸º4ä¸ªæ¨¡å—ï¼šNLUã€å¯¹è¯çŠ¶æ€è¿½è¸ªã€å¯¹è¯ç­–ç•¥å­¦ä¹  åŠNLGã€‚å¯¹è¯çŠ¶æ€è¿½è¸ªåˆåŒ…å«ä»»åŠ¡ï¼šdomain classificationã€intent detectionå’Œslot fillingã€‚domain classificationå’Œintent detectionä»»åŠ¡å½“åšåˆ†ç±»ä»»åŠ¡æ¥å¤„ç†ï¼Œå¸¸é‡‡ç”¨SVMæˆ–æ·±åº¦ç¥ç»ç½‘ç»œçš„æ–¹æ³•ï¼›slot fillingä»»åŠ¡è¢«å½“åšåºåˆ—æ ‡æ³¨ä»»åŠ¡æ¥å¤„ç†ï¼Œå¸¸é‡‡ç”¨BiLSTM+CRFæ¨¡å‹ã€‚NLUèƒ½å¦å……åˆ†åˆ©ç”¨context informationï¼Œå¯¹è¿™ä¸‰ä¸ªä¸‹æ¸¸ä»»åŠ¡æœ‰å¾ˆå¤§å½±å“ã€‚<br>ä¸ºäº†æ›´å¥½çš„åˆ©ç”¨context informationï¼Œæœ¬æ–‡æå‡ºäº†å¯¹è¯é€»è¾‘æ¨æ–­ä»»åŠ¡ï¼ˆDLI,dialog logic inferenceï¼‰ï¼Œä»»åŠ¡å®šä¹‰ä¸ºï¼šå°†æ‰“ä¹±é¡ºåºçš„å¤šè½®å¯¹è¯é‡æ–°æ’åºï¼›è¾“å…¥ä¹‹å‰çš„å¯¹è¯ï¼Œä»å‰©ä½™çš„utterance candidatesä¸­é€‰ä¸­ä¸‹ä¸€å¥å¯¹è¯ã€‚NLUä»»åŠ¡é‡‡ç”¨äº†æ‰€è°“çš„memory networkï¼Œå…¶å®å°±æ˜¯é‡‡ç”¨å¤šä¸ªencoderå¯¹context informationè¿›è¡Œç¼–ç ï¼Œå†ç”¨attentionæœºåˆ¶æˆ–åˆ«çš„æ–¹æ³•å¾—åˆ°context informationæ€»çš„å‘é‡åŒ–è¡¨ç¤ºã€‚æœ¬æ–‡è”åˆè®­ç»ƒDLIä»»åŠ¡å’ŒNLUä»»åŠ¡ï¼Œé€šè¿‡ä¸¤ä¸ªä»»åŠ¡å…±äº«encoderå’Œmemory retrieveæ¨¡å—ï¼Œæ¥è®©NLUä»»åŠ¡æ›´å¥½åœ°åˆ©ç”¨context informationã€‚å…¶å®æ˜¯å¾—åˆ°context informationæ›´åˆç†çš„å‘é‡åŒ–è¡¨ç¤ºï¼Œæ¥ä½œä¸ºä¸‹æ¸¸domain classificationã€intent detectionå’Œslot fillingä»»åŠ¡çš„è¾“å…¥ã€‚</p><p>è®ºæ–‡æå‡ºçš„å°†æ‰“ä¹±é¡ºåºçš„å¯¹è¯é‡æ–°æ’åºçš„DLIä»»åŠ¡ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ·±å…¥ï¼Œå°†å¥å­åˆ‡åˆ†ä¸ºå‡ æ®µæ‰“ä¹±é¡ºåºå†é‡æ–°æ’åºï¼›å¯ä»¥åº”ç”¨åˆ°é—²èŠå¼å¯¹è¯ç³»ç»Ÿä¸­ã€‚</p><h3 id="ã€ŠDialogue-Natural-Language-Inferenceã€‹"><a href="#ã€ŠDialogue-Natural-Language-Inferenceã€‹" class="headerlink" title="ã€ŠDialogue Natural Language Inferenceã€‹"></a>ã€ŠDialogue Natural Language Inferenceã€‹</h3><p>ã€é“¾æ¥ã€‘ï¼š<a href="https://arxiv.org/abs/1811.00671" target="_blank" rel="noopener">https://arxiv.org/abs/1811.00671</a><br>ã€ä»£ç ã€‘ï¼šæ— <br>ã€æ•°æ®é›†ã€‘ï¼š<a href="https://wellecks.github.io/dialogue_nli/" target="_blank" rel="noopener">https://wellecks.github.io/dialogue_nli/</a></p><p>åŠ åˆ©ç¦å°¼äºšå¤§å­¦ã€Facebook AI Labå‘è¡¨çš„è®ºæ–‡ã€‚æ ¸å¿ƒæ˜¯æå‡ºç”¨NLI(natural language inference)ä»»åŠ¡æ¥æé«˜persona-based dialog systemçš„ä¸€è‡´æ€§ã€‚è¿™é‡Œå°±è¦å…ˆææ¸…æ¥šNLIä»»åŠ¡å’Œä¸€è‡´æ€§é—®é¢˜ä¸¤ä¸ªæ¦‚å¿µã€‚</p><ul><li><p>å…ˆä»é—®é¢˜å‡ºå‘ï¼Œæ‰€è°“å¯¹è¯çš„ä¸€è‡´æ€§é—®é¢˜ã€‚å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼š</p><ul><li><p>logical contradictionï¼Œé€»è¾‘çŸ›ç›¾ã€‚æ¯”å¦‚åŒä¸€ä¸ªäººçš„ä¸¤å¥è¯:â€æˆ‘æœ‰ä¸€åªç‹—â€ï¼Œâ€æˆ‘æ²¡å…»è¿‡ç‹—â€ã€‚å°±æ˜¯é€»è¾‘çŸ›ç›¾çš„ã€‚</p></li><li><p>æ¯”è¾ƒæ¨¡ç³Šçš„éé€»è¾‘çŸ›ç›¾ã€‚åŒä¸€ä¸ªäººä¸å¯èƒ½è¯´å‡ºçš„ä¸¤å¥è¯ï¼šâ€œæˆ‘ä»æ¥ä¸è¿åŠ¨â€ï¼Œâ€œæˆ‘å»ç¯®çƒäº†â€ã€‚å°±æ˜¯è¿™ç§éé€»è¾‘çŸ›ç›¾ã€‚çœŸé¦™è­¦å‘Šã€‚</p><p>è‡³äºpersonaä¸€è‡´æ€§é—®é¢˜ï¼Œå°±æ˜¯å›å¤çš„utteranceä¸èƒ½ä¸è¯´è¯äººçš„personaçŸ›ç›¾ï¼Œä¹Ÿä¸èƒ½ä¸ä¹‹å‰çš„å›å¤æœ‰çŸ›ç›¾ã€‚</p></li></ul></li><li><p>å…·ä½“ä»‹ç»NLIä»»åŠ¡ã€‚è¿™å…¶å®æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ã€‚è®ºæ–‡å…¬å¼€äº†ä¸€ä¸ªè‡ªå·±æ ‡æ³¨çš„NLIæ•°æ®é›†ã€‚</p><ul><li>è®­ç»ƒé˜¶æ®µï¼šè®­ç»ƒé›†å½¢å¼æ˜¯ {$ï¼ˆs_1,s_2ï¼‰$,label }ï¼Œå¯¹åº”labels $\in$ï¼ˆä¸€è‡´ã€æ— å…³ã€çŸ›ç›¾ï¼‰ã€‚</li><li>åœ¨testé˜¶æ®µï¼Œç»™å®šä¸€ä¸ªå¥å­å¯¹ï¼ˆå¥å­1ï¼Œå¥å­2ï¼‰æ¥åˆ¤æ–­å¯¹åº”çš„labelã€‚</li></ul></li></ul><p>è®ºæ–‡çš„æœ€ç»ˆç›®çš„æ˜¯é€šè¿‡NLIä»»åŠ¡è®­ç»ƒçš„æ¨¡å‹æ¥æé«˜persona dialog systemçš„ä¸€è‡´æ€§ã€‚è¿™æ˜¯å¦‚ä½•æ¥å®ç°çš„å‘¢ï¼Ÿå¯¹äºä¸€ä¸ªdialog systemï¼Œç»™å®šå¯¹è¯å†å²$ï¼ˆu_1,u_2,â€¦,u_tï¼‰$ åŠè¯´è¯äººçš„personaæ–‡æœ¬æè¿°$ï¼ˆp_1,p_2,â€¦,p_nï¼‰$,ä»response candidates$ï¼ˆy_1,y_2,â€¦,y_mï¼‰$ä¸­é€‰æ‹©ä¸€ä¸ª$u_{t+1}$ï¼ˆå¦‚ä½•ç”Ÿæˆå¤šä¸ªresponsesä¸æ˜¯è¿™ç¯‡è®ºæ–‡è¦è§£å†³çš„ï¼‰ã€‚<br>ç”¨NLIä»»åŠ¡çš„æ¨¡å‹æ¥é¢„æµ‹$(y_i,u_j),(y_i,p_k)å…¶ä¸­ï¼ši\in [1,m],j\in [1,t],k \in [1,n]$å¯¹åº”çš„labelï¼Œå¦‚æœå¥å­ä¹‹é—´æ˜¯çŸ›ç›¾çš„ï¼Œåˆ™æ·»åŠ æƒ©ç½šé¡¹ã€‚ä»è€Œå¾—åˆ°ä¸€è‡´æ€§æœ€å¥½çš„utteranceä½œä¸ºresponseã€‚</p><h3 id="ã€ŠReCoSa-Detecting-the-Relevant-Contexts-with-Self-Attention-for-Multi-turn-Dialogue-Generationã€‹"><a href="#ã€ŠReCoSa-Detecting-the-Relevant-Contexts-with-Self-Attention-for-Multi-turn-Dialogue-Generationã€‹" class="headerlink" title="ã€ŠReCoSa: Detecting the Relevant Contexts with Self-Attention for Multi-turn Dialogue Generationã€‹"></a>ã€ŠReCoSa: Detecting the Relevant Contexts with Self-Attention for Multi-turn Dialogue Generationã€‹</h3><p>ã€é“¾æ¥ã€‘ï¼š<a href="https://arxiv.org/abs/1907.05339" target="_blank" rel="noopener">https://arxiv.org/abs/1907.05339</a><br>ã€æ•°æ®é›†ã€‘ï¼š<a href="https://github.com/rkadlec/ubuntu-ranking-dataset-creator" target="_blank" rel="noopener">English Ubuntu dialogue corpus</a><br>ã€ä»£ç ã€‘ï¼š<a href="https://github.com/zhanghainan/ReCoSa" target="_blank" rel="noopener">https://github.com/zhanghainan/ReCoSa</a></p><p>ä¸­ç§‘é™¢å‘è¡¨çš„è®ºæ–‡ã€‚<br>åœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œç”Ÿæˆresponseæ—¶ï¼Œå¯¹è¯å†å²ä¸­æœ€ç›¸å…³çš„éƒ¨åˆ†èµ·ç€é‡è¦çš„ä½œç”¨ã€‚è®ºæ–‡è¦è§£å†³çš„é—®é¢˜ï¼šå¦‚ä½•æ›´å‡†ç¡®åœ°æ‰¾åˆ°å¹¶åˆ©ç”¨relevant contextæ¥ç”Ÿæˆresponseã€‚<br>å¤šè½®å¯¹è¯ä¸­å¹¿æ³›ä½¿ç”¨çš„HREDæ¨¡å‹,[<a href="https://arxiv.org/abs/1507.04808" target="_blank" rel="noopener">(Serban et al.,2016;</a>,<a href="https://arxiv.org/abs/1507.02221" target="_blank" rel="noopener">Sordoni et al., 2015</a>]æ— å·®åˆ«åœ°åˆ©ç”¨context informationï¼Œå¿½ç•¥äº†relevant contextã€‚è™½ç„¶æœ‰åˆ©ç”¨relevant contextçš„ç›¸å…³å·¥ä½œï¼Œä½†è¿™äº›å·¥ä½œéƒ½æœ‰å„è‡ªçš„é—®é¢˜ã€‚[<a href="https://www.aclweb.org/anthology/P17-2036" target="_blank" rel="noopener">Tian et al., 2017</a>]æå‡ºè®¡ç®—context ä¸postä¹‹é—´çš„cosine similarityæ¥è¡¡é‡context relevanceï¼Œå…¶å‡è®¾æ˜¯contextä¸responseä¹‹é—´çš„relevanceç­‰ä»·äºpostä¸responseä¹‹é—´çš„relevanceï¼Œè¿™ä¸ªå‡è®¾æ˜¯ç«™ä¸ä½è„šçš„ã€‚[<a href>Xing et al., 2018</a>]å‘HREDæ¨¡å‹å¼•å…¥äº†attentionæœºåˆ¶ï¼Œä½†attentionæœºåˆ¶å®šä½relevant contextæ—¶ä¼šäº§ç”Ÿåå·®ï¼Œå› ä¸ºåŸºäºRNNçš„attentionæœºåˆ¶å€¾å‘äºæœ€é è¿‘çš„contextï¼ˆclose contextï¼‰ã€‚è®ºæ–‡æå‡ºäº†è‡ªå·±çš„è§£å†³åŠæ³•ï¼Œç”¨self-attentionæœºåˆ¶æ¥è¡¡é‡contextäºresponseä¹‹é—´çš„relevanceã€‚self-attentionæœºåˆ¶çš„ä¼˜ç‚¹æ˜¯å¯ä»¥æœ‰æ•ˆæ•æ‰åˆ°é•¿è·ç¦»çš„ä¾èµ–å…³ç³»ã€‚</p><p>æ¨¡å‹åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼š<br>contextåŒ…å«Nè½®å¯¹è¯ï¼š ${s_1,s_2,â€¦,s_N}$å…¶ä¸­ï¼Œ$s_i = {x_1,x_2,â€¦,x_M}$ï¼ŒMä¸ºå¥å­é•¿åº¦ã€‚<br>responseä¸º$Y = {y_1,y_2,â€¦,y_M}$</p><ol><li><strong>context representation encoder</strong>ï¼š<br> å°†context encodeä¸ºvectorã€‚<ol><li>word-level encoderï¼š<br> ç”¨LSTMå¯¹sentenceç¼–ç ï¼Œå°†LSTMæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„hidden stateä½œä¸ºsentence representation: $h^{s_i}$ï¼›<br> ç”±äºself-attentionæœºåˆ¶ä¸èƒ½åŒºåˆ†wordä½ç½®ä¿¡æ¯ï¼Œè¿˜éœ€è¦æ·»åŠ position embedding: $p^{s_i}$,<br> æŠŠä¸¤ä¸ªå‘é‡åšconcatenateæ“ä½œï¼Œå¾—åˆ°æ€»å¾—sentence representation:$(h^{s_i},p^{s_i})$ã€‚<br> å¯¹äºcontextä¸­çš„Nä¸ªå¥å­æœ‰${(h^{s_1},p^{s_1}),â€¦,(h^{s_N},p^{s_N})}$</li><li>context self-attention:<br> é‡‡ç”¨multi-head self-attentionæœºåˆ¶ï¼Œå°†${(h^{s_1},p^{s_1}),â€¦,(h^{s_N},p^{s_N})}$ç»è¿‡ä¸åŒçš„çº¿æ€§å˜æ¢ä½œä¸ºqueryã€keysã€values matrix,ç”±Nä¸ªsentence representationå¾—åˆ°æ€»çš„context representation $O_s$ã€‚</li></ol></li><li><strong>response representation encoder</strong><br> åŒæ ·ç”¨multi-head self-attentionæœºåˆ¶,å°†responseçš„word embeddingåŠposition embedding ${(w_1,p_1),â€¦,(w_{t-1},p_{t-1})}$ç»è¿‡ä¸åŒçš„çº¿æ€§å˜æ¢ä½œä¸ºqueryã€keysã€values matrixï¼Œå¾—åˆ°response representation $O_r$ã€‚<ol><li>åœ¨trainé˜¶æ®µ<br> é‡‡ç”¨maskæ“ä½œï¼Œåœ¨æ—¶é—´æ­¥tå¯¹äºword $y_t$ï¼Œmaskæ‰${y_t,y_{t+1},â€¦,y_M}$ï¼Œåªä¿ç•™${y_1,y_2,â€¦,y_{t-1}}$æ¥è®¡ç®—response representationã€‚</li><li>åœ¨inferé˜¶æ®µ<br> åœ¨ç”Ÿæˆresponseçš„æ—¶é—´æ­¥tï¼Œå°†ç”Ÿæˆçš„response ${g_1,â€¦,g_{t-1}}$ï¼Œæ¥ä½œä¸ºresponse representationã€‚</li></ol></li><li><strong>context-response attention decoder</strong><br> é‡‡ç”¨multi-head self-attentionæœºåˆ¶ï¼Œå°†context attention representation $O_s$ä½œä¸ºkeysã€values matrixï¼Œå°†response hidden representation $O_r$ä½œä¸ºquery matrixã€‚å¾—åˆ°è¾“å‡º$O_d$. <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/42.png" alt="æ¨¡å‹æ¡†æ¶å›¾" title>                </div>                <div class="image-caption">æ¨¡å‹æ¡†æ¶å›¾</div>            </figure></li></ol><h3 id="ã€ŠPersuasion-for-Good-Towards-a-Personalized-Persuasive-Dialogue-System-for-Social-Goodã€‹"><a href="#ã€ŠPersuasion-for-Good-Towards-a-Personalized-Persuasive-Dialogue-System-for-Social-Goodã€‹" class="headerlink" title="ã€ŠPersuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Goodã€‹"></a>ã€ŠPersuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Goodã€‹</h3><p>ã€é“¾æ¥ã€‘ï¼š<a href="https://arxiv.org/abs/1906.06725" target="_blank" rel="noopener">https://arxiv.org/abs/1906.06725</a><br>ã€ä»£ç ã€æ•°æ®é›†ã€‘ï¼š<a href="https://gitlab.com/ucdavisnlp/persuasionforgood/tree/master" target="_blank" rel="noopener">https://gitlab.com/ucdavisnlp/persuasionforgood/tree/master</a></p><p>æµ™æ±Ÿå¤§å­¦ã€åŠ åˆ©ç¦å°¼äºšå¤§å­¦å‘è¡¨ã€‚è·å¾—ACL2019 best paperæåã€‚<br>è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯å…¬å¼€äº†ä¸€ä¸ªåŒ…å«è¯´è¯äººä¸ªäººä¿¡æ¯çš„åŠè¯´æ•°æ®é›†ï¼Œåœ¨å­é›†ä¸Šæ ‡æ³¨äº†åç§ä¸åŒçš„åŠè¯´ç­–ç•¥ã€‚å¹¶è®­ç»ƒäº†ç”¨äºåˆ†ç±»ä¸åŒåŠè¯´ç­–ç•¥çš„åˆ†ç±»å™¨ã€‚</p><h3 id="ã€ŠDo-Neural-Dialog-Systems-Use-the-Conversation-History-Effectively-An-Empirical-Studyã€‹"><a href="#ã€ŠDo-Neural-Dialog-Systems-Use-the-Conversation-History-Effectively-An-Empirical-Studyã€‹" class="headerlink" title="ã€ŠDo Neural Dialog Systems Use the Conversation History Effectively? An Empirical Studyã€‹"></a>ã€ŠDo Neural Dialog Systems Use the Conversation History Effectively? An Empirical Studyã€‹</h3><p>ã€é“¾æ¥ã€‘ï¼š<a href="https://arxiv.org/abs/1906.01603" target="_blank" rel="noopener">https://arxiv.org/abs/1906.01603</a><br>ã€ä»£ç ã€‘ï¼š<a href="https://github.com/chinnadhurai/ParlAI/" target="_blank" rel="noopener">https://github.com/chinnadhurai/ParlAI/</a></p><p>è®ºæ–‡è·å¾—ACL2019 best short paperæåã€‚<br>è®ºæ–‡çš„ç ”ç©¶ç‚¹æ˜¯ï¼šç”Ÿæˆå¼å¯¹è¯ç³»ç»Ÿæ˜¯å¦æœ‰æ•ˆåˆ©ç”¨æˆ–æ­£ç¡®ç†è§£äº†å¯¹è¯å†å²ï¼Ÿè®ºæ–‡é€šè¿‡å‘å¯¹è¯å†å²ä¸­å¼•å…¥ä¸åŒç±»å‹çš„æ‰°åŠ¨ï¼Œæ¥ç ”ç©¶ç”Ÿæˆå¼å¯¹è¯ç³»ç»Ÿç”Ÿæˆå›å¤çš„å›°æƒ‘åº¦å˜åŒ–ã€‚è¿™ä¸ªæ–¹æ³•çš„ä¸€ä¸ªå‰ææ˜¯å¦‚æœç”Ÿæˆå¼å¯¹è¯ç³»ç»Ÿå¯¹æŸç§ä¿¡æ¯çš„æ‰°åŠ¨ä¸æ•æ„Ÿï¼Œé‚£ä¹ˆå®ƒæ²¡æœ‰æœ‰æ•ˆåˆ©ç”¨è¿™ç§ä¿¡æ¯ã€‚</p><p>è®ºæ–‡åœ¨æ¯”è¾ƒäº†ä¸‰ç§æ¨¡å‹ã€‚</p><ul><li>åŸºäºLSTMçš„seq2seqæ¨¡å‹ã€‚</li><li>åŸºäºLSTMçš„seq2seqæ¨¡å‹ + attentionæœºåˆ¶ã€‚</li><li>åŸºäºtransformerçš„seq2seqæ¨¡å‹ã€‚</li></ul><p>è®ºæ–‡åœ¨å››ä¸ªå¤šè½®å¯¹è¯æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒã€‚</p><ul><li>bAbI dialogã€‚<a href="https://arxiv.org/abs/1605.07683" target="_blank" rel="noopener">(Bordes and Weston, 2016)</a></li><li>Persona Chatã€‚<a href="https://www.aclweb.org/anthology/papers/P/P18/P18-1205/" target="_blank" rel="noopener">(Zhang et al., 2018)</a></li><li>Dailydialogã€‚ <a href="https://arxiv.org/abs/1710.03957" target="_blank" rel="noopener">(Li et al., 2017)</a></li><li>MutualFriendsã€‚<a href="https://arxiv.org/abs/1704.07130" target="_blank" rel="noopener">(He et al., 2017)</a></li></ul><p>è®ºæ–‡å‘å¯¹è¯å†å²å¼•å…¥äº†ä¸åŒçš„æ‰°åŠ¨ã€‚</p><ul><li>å¥å­çº§åˆ«çš„æ‰°åŠ¨ï¼š<ul><li>éšæœºæ‰“ä¹±å¯¹è¯å†å²ä¸­å¥å­çš„é¡ºåºã€‚</li><li>å€’åºå¯¹è¯å†å²ä¸­å¥å­çš„é¡ºåºã€‚</li><li>éšæœºå»æ‰å¯¹è¯å†å²ä¸­ç‰¹å®šçš„å¥å­ã€‚</li><li>å¯¹è¯å†å²ä¸­æœ‰nä¸ªå¥å­ï¼Œåªä¿ç•™æœ€è¿‘çš„kä¸ªå¥å­$(k \le n)$ã€‚</li></ul></li><li>è¯çº§åˆ«çš„æ‰°åŠ¨ï¼š<ul><li>éšæœºæ‰“ä¹±ä¸€ä¸ªå¥å­ä¸­è¯çš„é¡ºåºã€‚</li><li>å€’åºä¸€ä¸ªå¥å­ä¸­è¯çš„é¡ºåºã€‚</li><li>éšæœºå»æ‰å¯¹è¯å†å²ä¸­30%çš„è¯ã€‚</li><li>å»æ‰æ‰€æœ‰çš„åè¯ã€‚</li><li>å»æ‰æ‰€æœ‰çš„åŠ¨è¯ã€‚</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;è®°å½•ACL2019å¯¹è¯ç³»ç»Ÿç›¸å…³çš„è®ºæ–‡é˜…è¯»ç¬”è®°ã€‚åŒ…æ‹¬ä»»åŠ¡å‹å’Œé—²èŠå¼å¯¹è¯ç³»ç»Ÿï¼Œå¯¹è®ºæ–‡çš„æ€è·¯å’Œæ¨¡å‹åšç®€å•ä»‹ç»ï¼Œå€¼å¾—åå¤ç²¾è¯»çš„è®ºæ–‡ä¼šå•ç‹¬å¼€ä¸€ç¯‡åšæ–‡æ¥å†™ã€‚&lt;br&gt;ACL2019çš„ä¼šè®®åˆ—è¡¨é“¾æ¥ï¼š&lt;a href=&quot;http://www.acl2019.org/EN/program.xhtml&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.acl2019.org/EN/program.xhtml&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="è®ºæ–‡" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="dialog system" scheme="http://yoursite.com/tags/dialog-system/"/>
    
      <category term="ACL2019" scheme="http://yoursite.com/tags/ACL2019/"/>
    
  </entry>
  
  <entry>
    <title>è‡ªç„¶è¯­è¨€å¤„ç†---ä¼šè®®åˆ—è¡¨</title>
    <link href="http://yoursite.com/2019/04/24/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-%E4%BC%9A%E8%AE%AE%E5%88%97%E8%A1%A8/"/>
    <id>http://yoursite.com/2019/04/24/è‡ªç„¶è¯­è¨€å¤„ç†-ä¼šè®®åˆ—è¡¨/</id>
    <published>2019-04-24T06:55:43.000Z</published>
    <updated>2019-07-07T09:00:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>è®°å½•è‡ªç„¶è¯­è¨€å¤„ç†æ–¹å‘çš„å›½é™…ä¼šè®®åˆ—è¡¨ã€‚</p><a id="more"></a><h2 id="Aç±»ä¼šè®®"><a href="#Aç±»ä¼šè®®" class="headerlink" title="Aç±»ä¼šè®®"></a>Aç±»ä¼šè®®</h2><p><a href="http://www.aaai.org/" target="_blank" rel="noopener">AAAI</a>ï¼ŒAssociation for the Advancement of Artificial Intelligence</p><h2 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h2><p><a href="https://iclr.cc/" target="_blank" rel="noopener">ICLR</a>ï¼ŒThe International Conference on Learning Representationsï¼Œå›½é™…å­¦ä¹ è¡¨å¾ä¼šè®®<br>2013å¹´æ‰åˆšåˆšæˆç«‹äº†ç¬¬ä¸€å±Šã€‚è¿™ä¸ªä¸€å¹´ä¸€åº¦çš„ä¼šè®®å·²ç»è¢«å­¦æœ¯ç ”ç©¶è€…ä»¬å¹¿æ³›è®¤å¯ï¼Œè¢«è®¤ä¸ºã€Œæ·±åº¦å­¦ä¹ çš„é¡¶çº§ä¼šè®®ã€ã€‚<br>è¿™ä¸ªä¼šè®®çš„æ¥å¤´ä¸å°ï¼Œç”±ä½åˆ—æ·±åº¦å­¦ä¹ ä¸‰å¤§å·¨å¤´ä¹‹äºŒçš„ Yoshua Bengio å’Œ Yann LeCun ç‰µå¤´åˆ›åŠã€‚Yoshua Bengio æ˜¯è’™ç‰¹åˆ©å°”å¤§å­¦æ•™æˆï¼Œæ·±åº¦å­¦ä¹ ä¸‰å·¨å¤´ä¹‹ä¸€ï¼Œä»–é¢†å¯¼è’™ç‰¹åˆ©å°”å¤§å­¦çš„äººå·¥æ™ºèƒ½å®éªŒå®¤ï¼ˆMILAï¼‰è¿›è¡Œ AI æŠ€æœ¯çš„å­¦æœ¯ç ”ç©¶ã€‚MILA æ˜¯ä¸–ç•Œä¸Šæœ€å¤§çš„äººå·¥æ™ºèƒ½ç ”ç©¶ä¸­å¿ƒä¹‹ä¸€ï¼Œä¸è°·æ­Œä¹Ÿæœ‰ç€å¯†åˆ‡çš„åˆä½œã€‚è€Œ Yann LeCun å°±è‡ªä¸ç”¨æï¼ŒåŒä¸ºæ·±åº¦å­¦ä¹ ä¸‰å·¨å¤´ä¹‹ä¸€çš„ä»–ç°ä»» Facebook äººå·¥æ™ºèƒ½ç ”ç©¶é™¢ï¼ˆFAIRï¼‰é™¢é•¿ã€çº½çº¦å¤§å­¦æ•™æˆã€‚ä½œä¸ºå·ç§¯ç¥ç»ç½‘ç»œä¹‹çˆ¶ï¼Œä»–ä¸ºæ·±åº¦å­¦ä¹ çš„å‘å±•å’Œåˆ›æ–°ä½œå‡ºäº†é‡è¦è´¡çŒ®ã€‚</p><h2 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h2><ul><li><a href="https://www.ccf.org.cn/xspj/gyml/" target="_blank" rel="noopener">ä¸­å›½è®¡ç®—æœºå­¦ä¼šæ¨èå›½é™…å­¦æœ¯ä¼šè®®å’ŒæœŸåˆŠç›®å½•</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;è®°å½•è‡ªç„¶è¯­è¨€å¤„ç†æ–¹å‘çš„å›½é™…ä¼šè®®åˆ—è¡¨ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="è®ºæ–‡" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="ä¼šè®®åˆ—è¡¨" scheme="http://yoursite.com/tags/%E4%BC%9A%E8%AE%AE%E5%88%97%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>pythonè¯»å†™csvæ–‡ä»¶</title>
    <link href="http://yoursite.com/2019/04/19/python%E8%AF%BB%E5%86%99csv%E6%96%87%E4%BB%B6/"/>
    <id>http://yoursite.com/2019/04/19/pythonè¯»å†™csvæ–‡ä»¶/</id>
    <published>2019-04-19T10:32:22.000Z</published>
    <updated>2019-07-21T15:22:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>ä»‹ç»csvæ–‡ä»¶çš„è¯»å†™ã€‚</p><a id="more"></a><h2 id="csvæ¨¡å—"><a href="#csvæ¨¡å—" class="headerlink" title="csvæ¨¡å—"></a>csvæ¨¡å—</h2><h3 id="csv-writer-csvfile"><a href="#csv-writer-csvfile" class="headerlink" title="csv.writer(csvfile)"></a>csv.writer(csvfile)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import csv </span><br><span class="line">row = [&apos;Symbol&apos;,&apos;Price&apos;,&apos;Date&apos;,&apos;Time&apos;,&apos;Change&apos;,&apos;Volume&apos;]</span><br><span class="line">rows = [(&apos;AA&apos;, 39.48, &apos;6/11/2007&apos;, &apos;9:36am&apos;, -0.18, 181800),</span><br><span class="line">         (&apos;AIG&apos;, 71.38, &apos;6/11/2007&apos;, &apos;9:36am&apos;, -0.15, 195500),</span><br><span class="line">         (&apos;AXP&apos;, 62.58, &apos;6/11/2007&apos;, &apos;9:36am&apos;, -0.46, 935000),</span><br><span class="line">       ]</span><br><span class="line">with open(&apos;name.csv&apos;,&apos;w&apos;) as csvfile:</span><br><span class="line">    writer = csv.writer(csvfile,delimiter = &apos;\t&apos;,lineterminator = &apos;\n&apos;) #delimiterå’Œlineterminatoråˆ†åˆ«æ˜¯åˆ†éš”ç¬¦ï¼Œè¡Œç»“æŸç¬¦</span><br><span class="line">    writer.writerow(row) #å†™å…¥å•è¡Œ</span><br><span class="line">    writer.writerows(rows) #å†™å…¥å¤šè¡Œ</span><br></pre></td></tr></table></figure><h3 id="csv-reader-csvfile"><a href="#csv-reader-csvfile" class="headerlink" title="csv.reader(csvfile)"></a>csv.reader(csvfile)</h3><p>è¯¥å‡½æ•°æ¥æ”¶ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼Œè¿”å›å¯¹è±¡<code>reader</code>æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œä¸èƒ½ç›´æ¥ç”¨ä¸‹æ ‡è®¿é—®ã€‚å¯ä»¥ç”¨forå¾ªç¯å’Œnext()å‡½æ•°è®¿é—®ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with open(&apos;name.csv&apos;,&apos;r&apos;) as csvfile:</span><br><span class="line">    reader = csv.reader(csvfile,delimiter = &apos;\t&apos;) #è¿­ä»£å™¨</span><br><span class="line">    rows = [row for row in reader] #ç”¨forå¾ªç¯è®¿é—®ï¼š</span><br><span class="line">for row in rows:</span><br><span class="line">    print(row)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºç»“æœä¸ºï¼š<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/36.png" alt title>                </div>                <div class="image-caption"></div>            </figure>å¦‚æœè¦è¯»å–csvæ–‡ä»¶çš„æŸåˆ—ï¼Œå¯ä»¥çœ‹ä¸‹é¢çš„ä¾‹å­</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">with open(&apos;name.csv&apos;,&apos;r&apos;) as csvfile:</span><br><span class="line">    reader = csv.reader(csvfile,delimiter = &apos;\t&apos;) #è¿­ä»£å™¨</span><br><span class="line">    column = [row[2] for row in reader] #ç”¨forå¾ªç¯è®¿é—®ï¼š</span><br><span class="line">print(column)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºç»“æœä¸ºï¼š<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/37.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h3 id="csv-DictReader-csvfile"><a href="#csv-DictReader-csvfile" class="headerlink" title="csv.DictReader(csvfile)"></a>csv.DictReader(csvfile)</h3><p>ä¸csv.reader()å‡½æ•°ç›¸åŒï¼Œæ¥æ”¶ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼Œè¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ã€‚ä¸åŒä¹‹å¤„æ˜¯ï¼Œè¿”å›çš„æ¯ä¸ªå•å…ƒæ ¼æ”¾åœ¨å­—å…¸çš„å€¼ä¸­ï¼Œå­—å…¸çš„é”®å°±æ˜¯è¿™ä¸ªå•å…ƒæ ¼çš„åˆ—å¤´ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with open(&apos;./name.csv&apos;,&apos;r&apos;) as f:</span><br><span class="line">    reader = csv.DictReader(f,delimiter = &apos;\t&apos;)</span><br><span class="line">    rows = [row for row in reader]</span><br><span class="line">for row in rows:</span><br><span class="line">    print(rows)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºç»“æœä¸ºï¼š<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/38.png" alt title>                </div>                <div class="image-caption"></div>            </figure>å¦‚æœè¦è¯»å–csvæ–‡ä»¶çš„æŸåˆ—ï¼Œå¯ä»¥çœ‹ä¸‹é¢çš„ä¾‹å­:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">with open(&apos;./name.csv&apos;,&apos;r&apos;) as f:</span><br><span class="line">    reader = csv.DictReader(f,delimiter = &apos;\t&apos;)</span><br><span class="line">    column = [row[&apos;Time&apos;] for row in reader]</span><br><span class="line">print(column)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºç»“æœä¸ºï¼š<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/39.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h3 id="csv-DictWriter-csvfile"><a href="#csv-DictWriter-csvfile" class="headerlink" title="csv.DictWriter(csvfile)"></a>csv.DictWriter(csvfile)</h3><h2 id="pandasè¯»å†™csv"><a href="#pandasè¯»å†™csv" class="headerlink" title="pandasè¯»å†™csv"></a>pandasè¯»å†™csv</h2><p>ä¹Ÿå¯ä»¥ç›´æ¥ç”¨pandasçš„å‡½æ•°<code>read_csv()</code>æ¥è¯»å–csvæ–‡ä»¶çš„åˆ—ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">f = pd.read_csv(&apos;name.csv&apos;,delimiter = &apos;\t&apos;)</span><br><span class="line">time = f.Time</span><br><span class="line">print(time)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºç»“æœä¸ºï¼š<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/40.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h2><ul><li><a href="https://docs.python.org/zh-cn/3/library/csv.html" target="_blank" rel="noopener">pythonå®˜æ–¹æ–‡æ¡£-csvæ¨¡å—</a></li><li><a href="https://python3-cookbook.readthedocs.io/zh_CN/latest/c06/p01_read_write_csv_data.html" target="_blank" rel="noopener">è¯»å†™csvæ•°æ®</a></li><li><a href="https://blog.csdn.net/Allyli0022/article/details/79125672" target="_blank" rel="noopener">ä½¿ç”¨pythonè·å–csvæ–‡æœ¬çš„æŸè¡Œæˆ–æŸåˆ—æ•°æ®</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ä»‹ç»csvæ–‡ä»¶çš„è¯»å†™ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="csv" scheme="http://yoursite.com/tags/csv/"/>
    
      <category term="panda" scheme="http://yoursite.com/tags/panda/"/>
    
  </entry>
  
  <entry>
    <title>torch.cuda.is_available()è¿”å›False,ä½†nvidia-smiæ­£å¸¸</title>
    <link href="http://yoursite.com/2019/04/16/torch-cuda-is-available-%E8%BF%94%E5%9B%9EFalse-%E4%BD%86nvidia-smi%E6%AD%A3%E5%B8%B8/"/>
    <id>http://yoursite.com/2019/04/16/torch-cuda-is-available-è¿”å›False-ä½†nvidia-smiæ­£å¸¸/</id>
    <published>2019-04-16T09:04:44.000Z</published>
    <updated>2019-07-22T01:27:54.000Z</updated>
    
    <content type="html"><![CDATA[<p><code>torch.cuda.is_available()</code>è¿”å›False,ä½†nvidia-smiå¯ä»¥æ­£å¸¸è¿è¡Œã€‚</p><a id="more"></a><h2 id="é—®é¢˜æè¿°"><a href="#é—®é¢˜æè¿°" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h2><p>åœ¨pytorchç”¨GPUæ¥åŠ é€Ÿè®¡ç®—æ—¶å‘ç°ã€‚<code>torch.cuda.is_available()</code>è¿”å›False,ä½†nvidia-smiå¯ä»¥æ­£å¸¸è¿è¡Œã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; torch.cuda.is_available()</span><br><span class="line">False</span><br></pre></td></tr></table></figure><p>æ­¤æ—¶ï¼Œ<code>nvidia-smi</code>å¯ä»¥æ­£å¸¸è¿è¡Œã€‚<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/34.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="å¯èƒ½åŸå› "><a href="#å¯èƒ½åŸå› " class="headerlink" title="å¯èƒ½åŸå› "></a>å¯èƒ½åŸå› </h2><p>åœ¨<code>nvidia-smi</code>çš„è¿è¡Œç»“æœä¸­å¯ä»¥çœ‹åˆ°ï¼Œdriver versionæ˜¯<code>390.xx</code>ã€‚å¯èƒ½æ˜¯driver versionç‰ˆæœ¬å¤ªä½ï¼Œé€ æˆäº†è¿™ä¸ªé—®é¢˜ï¼Œå®é™…ä¸Šä¹Ÿæ˜¯å¦‚æ­¤ã€‚<br>driver versionçš„å¸¸è§ç‰ˆæœ¬æ˜¯<code>384.xx</code>,<code>390.xx</code>,<code>396.xx</code>ã€‚æ¥ä¸‹æ¥ï¼ŒæŠŠdriver versionå‡çº§åˆ°<code>396.xx</code>çœ‹èƒ½ä¸èƒ½è§£å†³é—®é¢˜ã€‚</p><h2 id="å‡çº§nvidia-driver-version"><a href="#å‡çº§nvidia-driver-version" class="headerlink" title="å‡çº§nvidia driver version"></a>å‡çº§nvidia driver version</h2><ol><li><p>å¸è½½æ—§ç‰ˆæœ¬çš„NVIDIA driver </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove --purge nvidia-\*</span><br></pre></td></tr></table></figure></li><li><p>æ·»åŠ NVIDIAçš„ppaæº.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</span><br></pre></td></tr></table></figure></li><li><p>å®‰è£…æ–°ç‰ˆæœ¬çš„NVIDIA driver </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install nvidia-driver-396</span><br></pre></td></tr></table></figure></li></ol><p>æ­¤æ—¶ï¼Œè¿è¡Œ<code>nvidia-smi</code>ï¼Œä¼šæŠ¥ä»¥ä¸‹é”™è¯¯ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failed to initialize NVML: Driver/library version mismatch</span><br></pre></td></tr></table></figure><p>è¿™æ˜¯æ›´æ–°NVIDIA driverç‰ˆæœ¬åçš„å¸¸è§é—®é¢˜ã€‚è¿™ä¸ªé—®é¢˜å‡ºç°çš„åŸå› æ˜¯kernel modçš„NVIDIA driverç‰ˆæœ¬æ²¡æœ‰æ›´æ–°ã€‚<br>æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯ä»¥æŸ¥çœ‹nvidia kernel modçš„versionã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/driver/nvidia/version</span><br></pre></td></tr></table></figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/32.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>å¯ä»¥çœ‹åˆ°å·²ç»åŠ è½½çš„nvidia kernel modçš„ç‰ˆæœ¬æ˜¯è¿˜æ˜¯æ—§ç‰ˆæœ¬<code>390.xx</code>ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œé‡å¯æœåŠ¡å™¨å°±èƒ½è§£å†³é—®é¢˜ã€‚<br>å¦‚æœç”±äºæŸäº›åŸå› ä¸èƒ½é‡å¯ï¼Œå¯ä»¥é‡æ–°åŠ è½½kernel modã€‚æ€è·¯æ˜¯å…ˆunload kernel modï¼Œå†reload kernel mod. è¯¦è§<a href="https://comzyh.com/blog/archives/967/" target="_blank" rel="noopener">è§£å†³Driver/library version mismatch</a><br><code>nvidia-smi</code>å¯ä»¥æ­£å¸¸è¿è¡Œåï¼Œé—®é¢˜å°±è§£å†³äº†ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; torch.cuda.is_available()</span><br><span class="line">True</span><br></pre></td></tr></table></figure><h2 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h2><ul><li><a href="https://discuss.pytorch.org/t/torch-cuda-is-available-returns-false-nvidia-smi-is-working/20614" target="_blank" rel="noopener">Torch.cuda.is_available() returns False, nvidia-smi is working</a></li><li><a href="https://askubuntu.com/questions/1063871/how-can-i-update-the-nvidia-drivers-to-version-390-77" target="_blank" rel="noopener">How can I update the NVIDIA drivers to version 390.77?</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;torch.cuda.is_available()&lt;/code&gt;è¿”å›False,ä½†nvidia-smiå¯ä»¥æ­£å¸¸è¿è¡Œã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="nvidia-smi" scheme="http://yoursite.com/tags/nvidia-smi/"/>
    
      <category term="GPU" scheme="http://yoursite.com/tags/GPU/"/>
    
      <category term="cuda" scheme="http://yoursite.com/tags/cuda/"/>
    
  </entry>
  
  <entry>
    <title>nvidia-smiè¿”å›é”™è¯¯ä¿¡æ¯â€˜Failed to initialize NVML: Driver/library version mismatchâ€™</title>
    <link href="http://yoursite.com/2019/03/29/nvidia-smi%E8%BF%94%E5%9B%9E%E9%94%99%E8%AF%AF%E4%BF%A1%E6%81%AF%E2%80%98Failed-to-initialize-NVML-Driver-library-version-mismatch%E2%80%99/"/>
    <id>http://yoursite.com/2019/03/29/nvidia-smiè¿”å›é”™è¯¯ä¿¡æ¯â€˜Failed-to-initialize-NVML-Driver-library-version-mismatchâ€™/</id>
    <published>2019-03-29T11:47:03.000Z</published>
    <updated>2019-07-21T15:23:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>Ubuntuè¿è¡Œå‘½ä»¤<code>nvidia-smi</code>å‡ºé”™ã€‚</p><a id="more"></a> <h2 id="é—®é¢˜æè¿°"><a href="#é—®é¢˜æè¿°" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h2><p>åœ¨Ubuntu18.04çš„å‘½ä»¤è¡Œä¸­è¿è¡Œå‘½ä»¤<code>nvidia-smi</code>ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failed to initialize NVML: Driver/library version mismatch</span><br></pre></td></tr></table></figure><h2 id="æ–¹æ³•1ï¼šé‡å¯è§£å†³å¤§éƒ¨åˆ†é—®é¢˜"><a href="#æ–¹æ³•1ï¼šé‡å¯è§£å†³å¤§éƒ¨åˆ†é—®é¢˜" class="headerlink" title="æ–¹æ³•1ï¼šé‡å¯è§£å†³å¤§éƒ¨åˆ†é—®é¢˜"></a>æ–¹æ³•1ï¼šé‡å¯è§£å†³å¤§éƒ¨åˆ†é—®é¢˜</h2><p>åšå®¢<a href="https://comzyh.com/blog/archives/967/" target="_blank" rel="noopener">è§£å†³Driver/library version mismatch</a>è®²è¿°çš„å¾ˆæ¸…æ¥šï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°ã€‚<br>æˆ–è€…å‚è€ƒå¤§å‹äº¤å‹ç½‘ç«™stack overflowçš„é—®é¢˜<a href="https://stackoverflow.com/questions/43022843/nvidia-nvml-driver-library-version-mismatch/45319156" target="_blank" rel="noopener">NVIDIA NVML Driver/library version mismatch</a></p><h2 id="æ–¹æ³•2ï¼šé‡è£…é©±åŠ¨"><a href="#æ–¹æ³•2ï¼šé‡è£…é©±åŠ¨" class="headerlink" title="æ–¹æ³•2ï¼šé‡è£…é©±åŠ¨"></a>æ–¹æ³•2ï¼šé‡è£…é©±åŠ¨</h2><p>çœ‹è¿”å›çš„é”™è¯¯ä¿¡æ¯ï¼Œè¿™ä¸ªé—®é¢˜å‡ºç°çš„åŸå› æ˜¯NVIDIA Driverçš„ç‰ˆæœ¬ä¸åŒ¹é…ã€‚å¦‚æœé‡å¯ä¸èƒ½è§£å†³é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦å¸è½½é‡è£…NVIDIA driverã€‚</p><ol><li><strong>æŸ¥çœ‹é©±åŠ¨ç¨‹åºç‰ˆæœ¬</strong></li></ol><ul><li><code>dpkg -l | grep nvidia</code> <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/31.png" alt title>                </div>                <div class="image-caption"></div>            </figure>å¯ä»¥çœ‹åˆ°é©±åŠ¨ç‰ˆæœ¬æ˜¯<code>390.116</code></li><li><code>cat /proc/driver/nvidia/version</code> <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/32.png" alt title>                </div>                <div class="image-caption"></div>            </figure>è¿™é‡ŒNVRMçš„ç‰ˆæœ¬æ˜¯<code>390.87</code>ã€‚é”™è¯¯ä¿¡æ¯å°±æ˜¯è¿™ä¸¤ä¸ªç‰ˆæœ¬ä¸åŒ¹é…é€ æˆçš„ã€‚æ¥ä¸‹æ¥å…ˆå¸è½½NVIDIA driverï¼Œå†é‡æ–°å®‰è£…ã€‚</li></ul><ol start="2"><li><p><strong>å¸è½½æ—§ç‰ˆæœ¬çš„NVIDIA driver</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove --purge nvidia-\*</span><br></pre></td></tr></table></figure></li><li><p><strong>æ·»åŠ NVIDIAçš„ppaæº</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</span><br></pre></td></tr></table></figure></li><li><p><strong>é‡æ–°å®‰è£…NVIDIAçš„é©±åŠ¨</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install nvidia-390</span><br></pre></td></tr></table></figure><p> ç”¨ä½ è‡ªå·±çš„ç‰ˆæœ¬å·æ›¿æ¢<code>390</code>ã€‚</p></li></ol><p>è¿™æ—¶å†ç”¨<code>cat /proc/driver/nvidia/version</code>æŸ¥çœ‹NVIDIA driverçš„é©±åŠ¨ã€‚<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/33.png" alt title>                </div>                <div class="image-caption"></div>            </figure> å¯ä»¥çœ‹åˆ°NVRMçš„ç‰ˆæœ¬æ˜¯<code>390.116</code>ï¼Œè¿™æ—¶ç‰ˆæœ¬å°±åŒ¹é…äº†ã€‚<br>å†æ¬¡æ‰§è¡Œ<code>nvidia-smi</code>,ç»ˆäºçœ‹åˆ°<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/34.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><p>åœ¨<a href="https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa" target="_blank" rel="noopener">nvidia driverå„ç‰ˆæœ¬æ€»è§ˆ</a>å¯ä»¥çœ‹åˆ°NVIDIA driverçš„å„ä¸ªç‰ˆæœ¬ã€‚</p><h2 id="é¢å¤–çš„ï¼šupdate-ä¸-upgrade"><a href="#é¢å¤–çš„ï¼šupdate-ä¸-upgrade" class="headerlink" title="é¢å¤–çš„ï¼šupdate ä¸ upgrade"></a>é¢å¤–çš„ï¼šupdate ä¸ upgrade</h2><p>è®°å½•ä¸‹<code>sudo apt-get update</code>ä¸<code>sudo apt-get upgrade</code>çš„åŒºåˆ«ã€‚<br>åœ¨windowsç³»ç»Ÿä¸­å®‰è£…è½¯ä»¶ï¼Œåªéœ€è¦æœ‰exeæ–‡ä»¶ï¼ŒåŒå‡»å³å¯å®‰è£…äº†ã€‚Linuxç³»ç»Ÿä¸­åˆ™ä¸åŒï¼ŒLinuxä¼šç»´æŠ¤ä¸€ä¸ªè‡ªå·±çš„è½¯ä»¶ä»“åº“ï¼Œå‡ ä¹æ‰€æœ‰è½¯ä»¶éƒ½åœ¨è¿™ä¸ªä»“åº“é‡Œï¼Œè€Œä¸”é‡Œé¢çš„è½¯ä»¶å®Œå…¨å®‰å…¨ï¼Œç»å¯¹å¯ä»¥å®‰è£…ã€‚<br>æˆ‘ä»¬è‡ªå·±çš„UbuntuæœåŠ¡å™¨ä¸Šï¼Œç»´æŠ¤ä¸€ä¸ªè½¯ä»¶æºåˆ—è¡¨æ–‡ä»¶<code>/etc/apt/sources.list</code>,é‡Œé¢éƒ½æ˜¯ä¸€äº›ç½‘å€ä¿¡æ¯ï¼Œæ¯ä¸ªç½‘å€å°±æ˜¯ä¸€ä¸ªè½¯ä»¶æºï¼Œè¿™ä¸ªåœ°å€æŒ‡å‘çš„æ•°æ®æ ‡è¯†ç€æœ‰å“ªäº›è½¯ä»¶å¯ä»¥å®‰è£…ä½¿ç”¨ã€‚</p><ol><li><p>æŸ¥çœ‹æºåˆ—è¡¨ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/apt/sources.list</span><br></pre></td></tr></table></figure></li><li><p>æ›´æ–°è½¯ä»¶åˆ—è¡¨</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure><p> è¿™ä¸ªå‘½ä»¤å¯¹è®¿é—®æºåˆ—è¡¨é‡Œçš„æ¯ä¸ªç½‘å€ï¼Œè¯»å–è½¯ä»¶åˆ—è¡¨ï¼Œä¿å­˜åˆ°æœ¬åœ°ç”µè„‘ã€‚</p></li><li><p>æ›´æ–°è½¯ä»¶</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get upgrade</span><br></pre></td></tr></table></figure><p> è¿™ä¸ªå‘½ä»¤ä¼šæŠŠæœ¬åœ°å·²å®‰è£…çš„è½¯ä»¶ï¼Œä¸è½¯ä»¶åˆ—è¡¨é‡Œå¯¹åº”è½¯ä»¶åšå¯¹æ¯”ï¼Œå¦‚æœæœ‰å¯æ›´æ–°ç‰ˆæœ¬å°±æ›´æ–°è½¯ä»¶ã€‚<br>æ€»çš„æ¥è¯´ï¼Œ<code>sudo apt-get update</code>æ˜¯æ›´æ–°è½¯ä»¶åˆ—è¡¨ï¼Œ<code>sudo apt-get upgrade</code>æ˜¯æ›´æ–°è½¯ä»¶ã€‚</p></li></ol><h2 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h2><ul><li><a href="https://comzyh.com/blog/archives/967/" target="_blank" rel="noopener">è§£å†³Driver/library version mismatch</a></li><li><a href="https://www.cnblogs.com/yizhichun/p/6397168.html" target="_blank" rel="noopener">Ubuntué…ç½®GPU+CUDA+CAFFE</a></li><li><a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---Tensorflow-gpu%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85.html" target="_blank" rel="noopener">ubuntuä¸‹å®‰è£…å®‰è£…CUDAã€cuDNNå’Œtensotflow-gpuç‰ˆæœ¬æµç¨‹å’Œé—®é¢˜æ€»ç»“</a></li><li><a href="https://wiki.ubuntu.org.cn/NVIDIA#PPA.E6.BA.90" target="_blank" rel="noopener">NVIDIAçš„wiki</a></li><li><a href="https://www.cnblogs.com/darkknightzh/p/5638185.html" target="_blank" rel="noopener">ï¼ˆåŸï¼‰Ubuntu16ä¸­å®‰è£…nvidiaçš„æ˜¾å¡é©±åŠ¨</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Ubuntuè¿è¡Œå‘½ä»¤&lt;code&gt;nvidia-smi&lt;/code&gt;å‡ºé”™ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="æŠ€æœ¯èµ„æ–™" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E8%B5%84%E6%96%99/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
      <category term="ubuntu" scheme="http://yoursite.com/tags/ubuntu/"/>
    
      <category term="nvidia-smi" scheme="http://yoursite.com/tags/nvidia-smi/"/>
    
  </entry>
  
  <entry>
    <title>æ¡ä»¶éšæœºåœºCRF</title>
    <link href="http://yoursite.com/2019/03/23/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF/"/>
    <id>http://yoursite.com/2019/03/23/æ¡ä»¶éšæœºåœºCRF/</id>
    <published>2019-03-23T05:50:20.000Z</published>
    <updated>2019-07-22T01:26:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>æœ€è¿‘å­¦ä¹ äº†æ¡ä»¶éšæœºåœºCRFï¼Œåšä¸‹æ€»ç»“ã€‚ä¸»è¦å‚è€ƒ<a href="https://createmomo.github.io/2017/09/12/CRF_Layer_on_the_Top_of_BiLSTM_1/" target="_blank" rel="noopener">BiLSTM+CRFæ¨¡å‹ä¸­çš„CRFå±‚</a>ä¸ºä¸»çº¿ï¼Œç»“åˆæèˆªè€å¸ˆçš„ã€Šç»Ÿè®¡æœºå™¨å­¦ä¹ ã€‹ï¼Œè®°å½•è‡ªå·±å¯¹CRFçš„ç†è§£ã€‚</p><a id="more"></a> <h2 id="ä»é©¬å°”ç§‘å¤«éšæœºåœºåˆ°çº¿æ€§é“¾æ¡ä»¶éšæœºåœº"><a href="#ä»é©¬å°”ç§‘å¤«éšæœºåœºåˆ°çº¿æ€§é“¾æ¡ä»¶éšæœºåœº" class="headerlink" title="ä»é©¬å°”ç§‘å¤«éšæœºåœºåˆ°çº¿æ€§é“¾æ¡ä»¶éšæœºåœº"></a>ä»é©¬å°”ç§‘å¤«éšæœºåœºåˆ°çº¿æ€§é“¾æ¡ä»¶éšæœºåœº</h2><ol><li><p><strong>æ¦‚ç‡å›¾æ¨¡å‹</strong><br> æ¦‚ç‡å›¾æ¨¡å‹æ˜¯ç”¨å›¾G = (V,E)æ¥è¡¨ç¤ºæ¦‚ç‡åˆ†å¸ƒã€‚è®¾æœ‰è”åˆæ¦‚ç‡åˆ†å¸ƒP(Y)ï¼ŒYæ˜¯ä¸€ç»„éšæœºå˜é‡ã€‚æˆ‘ä»¬å¯ä»¥ç”¨æ— å‘å›¾G = (V,E)æ¥è¡¨ç¤ºè”åˆæ¦‚ç‡åˆ†å¸ƒP(Y),èŠ‚ç‚¹$v \in V$è¡¨ç¤ºéšæœºå˜é‡$Y_v$ï¼Œè¾¹$e \in E$è¡¨ç¤ºéšæœºå˜é‡ä¹‹é—´çš„æ¦‚ç‡ä¾èµ–å…³ç³»ã€‚</p></li><li><p><strong>æ¦‚ç‡æ— å‘å›¾æ¨¡å‹ï¼Œå³é©¬å°”ç§‘å¤«éšæœºåœº</strong><br> è®¾æœ‰è”åˆæ¦‚ç‡åˆ†å¸ƒP(Y),ç”±æ— å‘å›¾G=(V,E)è¡¨ç¤ºã€‚å¦‚æœæ¦‚ç‡åˆ†å¸ƒP(Y)æ»¡è¶³<code>æˆå¯¹ã€å±€éƒ¨ã€å…¨å±€é©¬å°”ç§‘å¤«æ€§</code>ï¼Œé‚£ä¹ˆç§° è¿™ä¸ªè”åˆæ¦‚ç‡åˆ†å¸ƒp(Y)ä¸ºæ¦‚ç‡æ— å‘å›¾æ¨¡å‹ï¼Œæˆ–é©¬å°”ç§‘å¤«éšæœºåœº(Markov random field)ã€‚</p><p> æˆå¯¹é©¬å°”ç§‘å¤«æ€§ã€å±€éƒ¨é©¬å°”å¯å¤«æ€§ã€å…¨éƒ¨é©¬å°”ç§‘å¤«æ€§è¦è¡¨è¾¾çš„å°±æ˜¯ï¼šåœ¨æ— å‘å›¾ä¸­ï¼Œæ²¡æœ‰è¾¹è¿æ¥çš„èŠ‚ç‚¹ä¹‹é—´æ²¡æœ‰æ¦‚ç‡ä¾èµ–å…³ç³»ï¼Œä¹Ÿå°±æ˜¯æ²¡æœ‰è¾¹è¿æ¥çš„èŠ‚ç‚¹ä»£è¡¨çš„éšæœºå˜é‡ä¹‹é—´æ˜¯æ¡ä»¶ç‹¬ç«‹çš„ã€‚</p></li><li><p><strong>æ¡ä»¶éšæœºåœº</strong><br> è®¾Xå’ŒYæ˜¯éšæœºå˜é‡ï¼ŒP(Y|X)æ˜¯ç»™å®šXçš„æ¡ä»¶ä¸‹Yçš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚è‹¥ç»™å®šXçš„æ¡ä»¶ä¸‹ï¼ŒYæ„æˆä¸€ä¸ªé©¬å°”ç§‘å¤«éšæœºåœºã€‚åˆ™ç§°æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒP(Y|X)ä¸ºæ¡ä»¶éšæœºåœºã€‚<br> æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œé©¬å°”ç§‘å¤«éšæœºåœºæ˜¯è”åˆæ¦‚ç‡åˆ†å¸ƒP(Y),è€Œæ¡ä»¶éšæœºåœºæ˜¯æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒP(Y|X)ã€‚è¿™æ˜¯ä¸€ç‚¹ä¸åŒã€‚</p></li><li><p><strong>çº¿æ€§é“¾æ¡ä»¶éšæœºåœº</strong><br> è®¾$X =(X_1,X_2,â€¦,X_n), Y =(Y_1,Y_2,â€¦,Y_n)$æ˜¯çº¿æ€§é“¾è¡¨ç¤ºçš„éšæœºå˜é‡åºåˆ—ã€‚è‹¥åœ¨ç»™å®šéšæœºå˜é‡åºåˆ—Xçš„æ¡ä»¶ä¸‹ï¼Œéšæœºå˜é‡åºåˆ—Yçš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒP(Y|X)æ„æˆæ¡ä»¶éšæœºåœºï¼Œå³æ»¡è¶³é©¬å°”å¯å¤«æ€§ï¼š$$P(Y_i|X,Y_1,Y_2,â€¦,Y_{i-1},Y_{i+1},â€¦,Y_n) = P(Y_i|X,Y_{i-1},Y_{i+1})$$ ã€‚åˆ™ç§°æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒp(Y|X)ä¸ºçº¿æ€§é“¾æ¡ä»¶éšæœºåœºã€‚<br> <img src="/images/21.png" alt><br> çº¿æ€§é“¾æ¡ä»¶éšæœºåœºå’Œéšé©¬å°”å¯å¤«æ¨¡å‹éƒ½æ˜¯åºåˆ—æ¨¡å‹ï¼Œå¯ä»¥ç”¨äºæ ‡æ³¨é—®é¢˜ã€‚è¿™æ—¶ï¼Œæ¡ä»¶æ¦‚ç‡æ¨¡å‹P(Y|X)ä¸­ï¼ŒXæ˜¯è¾“å…¥å˜é‡åºåˆ—ï¼Œè¡¨ç¤ºéœ€è¦æ ‡æ³¨çš„è§‚æµ‹åºåˆ—ï¼›Yæ˜¯è¾“å‡ºå˜é‡ï¼Œè¡¨ç¤ºæ ‡è®°åºåˆ—ï¼Œæˆ–ç§°çŠ¶æ€åºåˆ—ã€‚</p></li></ol><h2 id="BiLSTM-CRFæ¨¡å‹"><a href="#BiLSTM-CRFæ¨¡å‹" class="headerlink" title="BiLSTM+CRFæ¨¡å‹"></a>BiLSTM+CRFæ¨¡å‹</h2><p>BiLSTM+CRFæ¨¡å‹æ˜¯å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡çš„å¸¸ç”¨æ¨¡å‹ã€‚<br>å‡è®¾æˆ‘ä»¬è®­ç»ƒé›†ä¸­æœ‰ä¸ªç”±äº”ä¸ªè¯ç»„æˆçš„å¥å­$X = (w_0,w_1,w_2,w_3,w_4)$,å¯¹åº”æ ‡ç­¾ä¸º$Y = [B-Personï¼ŒI-Person,O,B-Organization,O]$ã€‚æ•°æ®é›†ä¸­æœ‰äº”ç±»æ ‡ç­¾ï¼š </p><table><thead><tr><th>ç±»åˆ«</th><th align="center">B-Person</th><th align="center">I-Person</th><th align="center">B-Organization</th><th align="center">I-Organization</th><th align="center">O</th></tr></thead><tbody><tr><td>å«ä¹‰</td><td align="center">äººåçš„å¼€å§‹éƒ¨åˆ†</td><td align="center">äººåçš„ä¸­é—´éƒ¨åˆ†</td><td align="center">ç»„ç»‡æœºæ„çš„å¼€å§‹éƒ¨åˆ†</td><td align="center">ç»„ç»‡æœºæ„çš„ä¸­é—´éƒ¨åˆ†</td><td align="center">éå®ä½“ä¿¡æ¯</td></tr></tbody></table><p>å…ˆç®€å•ä»‹ç»ä¸‹BiLSTM+CRFæ¨¡å‹çš„ç»“æ„ã€‚LSTMå±‚çš„è¾“å…¥ä¸€èˆ¬ä¸ºæ¯ä¸ªè¯çš„Word-embeddingï¼Œè¾“å‡ºä¸ºæ¯ä¸ªè¯wordåœ¨ç±»åˆ«ç©ºé—´tag_spaceä¸Šçš„éå½’ä¸€åŒ–æ¦‚ç‡ï¼Œä¹Ÿå°±æ˜¯åœ¨å•è¯å¯¹åº”æ¯ä¸ªç±»åˆ«çš„å¾—åˆ†scoreã€‚è¿™äº›scoreä½œä¸ºCRFå±‚çš„è¾“å…¥ã€‚<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/22.png" alt title>                </div>                <div class="image-caption"></div>            </figure></p><h2 id="CRFçš„æŸå¤±å‡½æ•°"><a href="#CRFçš„æŸå¤±å‡½æ•°" class="headerlink" title="CRFçš„æŸå¤±å‡½æ•°"></a>CRFçš„æŸå¤±å‡½æ•°</h2><p>æ¡ä»¶éšæœºåœºä¸­æœ‰ä¸¤ä¸ªé‡è¦çš„çŸ©é˜µï¼Œè½¬ç§»æ¦‚ç‡çŸ©é˜µå’ŒçŠ¶æ€æ¦‚ç‡çŸ©é˜µï¼Œåˆ†åˆ«å¯¹åº”è½¬ç§»ç‰¹å¾å’ŒçŠ¶æ€ç‰¹å¾ã€‚</p><ul><li>çŠ¶æ€æ¦‚ç‡çŸ©é˜µã€‚å°±æ˜¯LSTMå±‚çš„è¾“å‡ºï¼Œä½œä¸ºCRFå±‚çš„è¾“å…¥ã€‚çŸ©é˜µçš„å½¢çŠ¶ä¸º[N,M],Nä¸ºå¥å­é•¿åº¦ï¼ŒMä¸ºå¯èƒ½çŠ¶æ€æ•°ã€‚</li><li>è½¬ç§»æ¦‚ç‡çŸ©é˜µã€‚çŸ©é˜µå½¢çŠ¶ä¸º[M,M]ï¼ŒMä¸ºå¯èƒ½çŠ¶æ€æ•°ã€‚è½¬ç§»çŸ©é˜µæ˜¯æ¨¡å‹å‚æ•°ï¼Œæ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­æ›´æ–°ä¼˜åŒ–ã€‚</li></ul><p>ç»™å®šè½¬ç§»çŸ©é˜µTï¼Œéšæœºå˜é‡åºåˆ—Xå–å€¼ä¸ºxçš„æ¡ä»¶ä¸‹ï¼Œéšæœºå˜é‡åºåˆ—å–å€¼ä¸ºyçš„ä¼¼ç„¶å‡½æ•°ä¸ºï¼š$$Likelihood(y|x,T) = \frac{ \sum_{i=0}^{n} P(x_i|y_i)T(y_i|y_{i-1})}{\sum_{y^<em>}\biggl(\sum_{i=0}^{n}P(x_i|y_i^</em>)T(y_i^<em>|y_{i-1}^</em>)\biggr)}  \cdots\cdots\cdots\cdots\cdots  (1)$$<br>ä¸Šå¼ä¸­,</p><ul><li>$P(x_i|y_i)$è¡¨ç¤ºå½“å‰çŠ¶æ€ä¸º$y_i$æ—¶ï¼Œäº§ç”Ÿè§‚æµ‹å€¼$x_i$çš„æ¦‚ç‡ã€‚å¯¹åº”çŠ¶æ€åˆ†æ•°ã€‚</li><li>$T(y_i|y_{i-1})$è¡¨ç¤ºä»ä¸Šä¸€ä¸ªçŠ¶æ€$y_{i-1}$è½¬æ¢åˆ°å½“å‰çŠ¶æ€$y_i$çš„æ¦‚ç‡ã€‚å¯¹åº”è½¬ç§»åˆ†æ•°ã€‚æˆ‘ä»¬å¯ä»¥ä»è½¬ç§»çŸ©é˜µä¸­è¯»å‡ºè¿™ä¸ªæ¦‚ç‡ã€‚</li><li>åˆ†å­è¡¨ç¤ºäº†å•æ¡è·¯å¾„y=[y_0,y_1,â€¦,y_n]çš„åˆ†æ•°scoreæˆ–æ¦‚ç‡ã€‚</li><li>åˆ†æ¯è¡¨ç¤ºäº†æ‰€æœ‰å¯èƒ½è·¯å¾„$y^*$çš„æ€»åˆ†ã€‚æ³¨æ„è®¡ç®—åˆ†æ¯æ—¶ï¼Œæˆ‘ä»¬è¦è®¡ç®—æ‰€æœ‰å¯èƒ½è·¯å¾„å¹¶æ±‚å’Œã€‚è‹¥åºåˆ—é•¿åº¦ä¸ºN,çŠ¶æ€å¯èƒ½æ•°ä¸ºM,åˆ™æ‰€æœ‰å¯èƒ½è·¯å¾„æ•°ä¸º$M^N$,è¿™ä¸ªæ•°é‡æ˜¯æŒ‡æ•°çº§çš„ï¼Œéå¸¸å¤§ã€‚æˆ‘ä»¬çš„ç§˜å¯†æ­¦å™¨æ˜¯<code>å‰å‘åå‘ç®—æ³•</code>æ¥é«˜æ•ˆåœ°è®¡ç®—åˆ†æ¯ã€‚</li></ul><p>è¿›ä¸€æ­¥åœ°ï¼Œè´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°ä¸ºï¼š<br>$$NegLogLikelihood(y|x,T) = \sum_{y^<em>}\biggl( \sum_{i=0}^{n} log(P(x_i|y_i^</em>)T(y^<em>_i|y^</em><em>{i-1}))\biggr) - \sum</em>{i=0}^{n}log(P(x_i|y_i)T(y_i|y_{i-1})) \cdots\cdots\cdots\cdots (2)$$</p><p>ä»å¼å­(1)åˆ°å¼å­(2)ï¼Œç›´æ¥å¯¹å¼å­(1)å–è´Ÿå¯¹æ•°æ˜¯å¾—åˆ°å¼å­(2)å¯èƒ½æ¯”è¾ƒä»¤äººè´¹è§£ã€‚<br>éœ€è¦ç•™æ„çš„æ˜¯ï¼šè½¬ç§»æ¦‚ç‡çŸ©é˜µå’ŒçŠ¶æ€æ¦‚ç‡çŸ©é˜µä¸­çš„æ¦‚ç‡éƒ½æ˜¯å¯¹æ•°æ¦‚ç‡ï¼ˆè¿™å¾ˆé‡è¦ï¼‰ï¼Œè¿™æ ·è®¡ç®—è·¯å¾„æ¦‚ç‡æ—¶éƒ½æ˜¯åŠ æ³•ã€‚å¯¹å¯¹æ•°æ¦‚ç‡åŠ ä¸Šexp()è¿ç®—æˆ‘ä»¬èƒ½å¾—åˆ°æ­£å¸¸æ¦‚ç‡ã€‚<br>ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ä¹¦ä¸­è¯´ï¼Œçº¿æ€§é“¾æ¡ä»¶éšæœºåœºæ˜¯å¯¹æ•°çº¿æ€§æ¨¡å‹ï¼Œåœ¨å¯¹æ•°ç©ºé—´ä¸­ï¼Œå¯¹æ•°æ¦‚ç‡å¯ä»¥ç›´æ¥ç›¸åŠ ï¼Œå¸¦æ¥å¾ˆå¤§çš„æ–¹ä¾¿ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹ï¼šçœŸå®è·¯å¾„çš„åˆ†æ•°å’Œæ‰€æœ‰è·¯å¾„çš„æ€»åˆ†æ˜¯æ€ä¹ˆè®¡ç®—çš„ï¼Ÿ</p><h3 id="çœŸå®è·¯å¾„åˆ†æ•°"><a href="#çœŸå®è·¯å¾„åˆ†æ•°" class="headerlink" title="çœŸå®è·¯å¾„åˆ†æ•°"></a>çœŸå®è·¯å¾„åˆ†æ•°</h3><p>æ•°æ®é›†ä¸­æœ‰äº”ç±»æ ‡ç­¾ï¼Œå†å¼•å…¥startå’Œendä½œä¸ºåºåˆ—å¼€å§‹å’Œç»“æŸæ ‡å¿—ã€‚</p><table><thead><tr><th>ç±»åˆ«</th><th align="center">B-Person</th><th align="center">I-Person</th><th align="center">B-Organization</th><th align="center">I-Organization</th><th align="center">O</th><th align="center">start</th><th align="center">end</th></tr></thead><tbody><tr><td>ç´¢å¼•</td><td align="center">0</td><td align="center">1</td><td align="center">2</td><td align="center">3</td><td align="center">4</td><td align="center">5</td><td align="center">6</td></tr></tbody></table><p>é•¿åº¦ä¸º5çš„åºåˆ—ï¼Œ$X = (w_0,w_1,w_2,w_3,w_4)$,<br>å¯¹åº”ç±»åˆ«ä¸º$Y = [B-Personï¼ŒI-Person,O,B-Organization,O]$ï¼Œ<br>æ ‡æ³¨åºåˆ—ï¼Œä¹Ÿå°±æ˜¯çœŸå®è·¯å¾„ä¸ºä¸ºy = [0,1,4,3,4]ã€‚<br>çœŸå®è·¯å¾„çš„åˆ†æ•°ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼ŒçŠ¶æ€åˆ†æ•°å’Œè½¬ç§»åˆ†æ•°ã€‚çŠ¶æ€çŸ©é˜µå°±æ˜¯LSTMå±‚çš„è¾“å‡ºã€‚è½¬ç§»çŸ©é˜µæ˜¯æ¨¡å‹å‚æ•°ï¼Œä¸º$$[t_{ij}],i,j\in [0,6];i\neq 6,j\neq 5$$å…¶ä¸­$t_ij$è¡¨ç¤ºä»ä¸Šä¸€çŠ¶æ€è½¬æ¢åˆ°å½“å‰çŠ¶æ€çš„æ¦‚ç‡ã€‚è½¬ç§»æ—¶ï¼Œä¸èƒ½è½¬ç§»åˆ°startï¼Œä¸èƒ½ä»endè½¬ç§»ã€‚<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/23.png" alt title>                </div>                <div class="image-caption"></div>            </figure>åˆ™çœŸå®è·¯å¾„çš„åˆ†æ•° = è½¬ç§»åˆ†æ•° + çŠ¶æ€åˆ†æ•° = $1.5+0.4+0.1+0.2+0.5+t_{51}+t_{01}+t_{14}+t_{42}+t_{24}+t_{46}$</p><h3 id="æ‰€æœ‰è·¯å¾„åˆ†æ•°-å‰å‘åå‘ç®—æ³•"><a href="#æ‰€æœ‰è·¯å¾„åˆ†æ•°-å‰å‘åå‘ç®—æ³•" class="headerlink" title="æ‰€æœ‰è·¯å¾„åˆ†æ•°-å‰å‘åå‘ç®—æ³•"></a>æ‰€æœ‰è·¯å¾„åˆ†æ•°-å‰å‘åå‘ç®—æ³•</h3><p>è®¡ç®—æ‰€æœ‰è·¯å¾„çš„æ€»åˆ†é¢å¯¹çš„éš¾é¢˜æ˜¯è¦ä¸è¦ç©·ä¸¾æ‰€æœ‰è·¯å¾„ã€‚å¯¹äºä¸€ä¸ªé•¿åº¦ä¸ºNçš„åºåˆ—ï¼Œå¯èƒ½çŠ¶æ€æ•°ä¸ºMï¼Œæ‰€æœ‰å¯èƒ½è·¯å¾„æ•°ä¸º$M^N$ï¼Œè¿™æ˜¯ä¸€ä¸ªæŒ‡æ•°çº§çš„è®¡ç®—é‡ã€‚è®¡ç®—æ¯æ¡è·¯å¾„åˆ†æ•°çš„è®¡ç®—é‡æ˜¯$O(N)$,ç›´æ¥ç”¨ç©·ä¸¾æ³•è®¡ç®—æ‰€æœ‰è·¯å¾„æ€»åˆ†çš„è®¡ç®—é‡æ˜¯$O(N\cdot M^N)$ã€‚è¿™ä¸ªè®¡ç®—é‡æ˜¯æ— æ³•æ¥å—çš„ã€‚<br>ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹p176å†™ï¼Œå‰å‘ç®—æ³•æ˜¯åŸºäºâ€œè·¯å¾„ç»“æ„â€é€’æ¨è®¡ç®—æ‰€æœ‰è·¯å¾„åˆ†æ•°ã€‚å‰å‘ç®—æ³•é«˜æ•ˆçš„å…³é”®æ˜¯å±€éƒ¨è®¡ç®—å‰å‘æ¦‚ç‡ï¼Œå†é€’æ¨åˆ°å…¨å±€ã€‚å‰å‘ç®—æ³•çš„è®¡ç®—é‡æ˜¯$O(N\cdot M^2)$ï¼Œå‰å‘ç®—æ³•å‡å°‘è®¡ç®—é‡çš„åŸå› æ˜¯ï¼šæ¯ä¸€æ¬¡é€’æ¨è®¡ç®—ç›´æ¥åˆ©ç”¨äº†å‰ä¸€ä¸ªæ—¶åˆ»çš„è®¡ç®—ç»“æœï¼Œé¿å…äº†é‡å¤è®¡ç®—ã€‚</p><p>å¯¹äº$w_0 \to w_1$çš„å±€éƒ¨è·¯å¾„ã€‚<br>å…ˆè®¡ç®—$w_0$æ‰€æœ‰çŠ¶æ€åˆ°$w_1$å•ä¸ªçŠ¶æ€0çš„åˆ†æ•°ä¹‹å’Œï¼Œå¹¶æ›´æ–°$w_1$çš„çŠ¶æ€0çš„çŠ¶æ€åˆ†æ•°ã€‚æœ‰Mæ¡å±€éƒ¨è·¯å¾„ï¼Œè®¡ç®—é‡æ˜¯$O(M)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/24.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>ç”¨åŒæ ·çš„æ–¹æ³•æ›´æ–°$w_1$æ‰€æœ‰çŠ¶æ€çš„çŠ¶æ€åˆ†æ•°ï¼Œè¿™å°±æ˜¯æ‰€æœ‰å±€éƒ¨è·¯å¾„çš„åˆ†æ•°ã€‚è¦è®¡ç®—Mä¸ªçŠ¶æ€ï¼Œè®¡ç®—é‡æ˜¯$O(M^2)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/25.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>ä¾æ¬¡é€’æ¨åˆ°å…¨å±€ã€‚åºåˆ—é•¿åº¦ä¸ºN,æ€»çš„è®¡ç®—é‡æ˜¯$O(N \cdot M^2)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/26.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>ä»å›¾çš„è§’åº¦è§£é‡Šäº†å‰å‘ç®—æ³•ï¼Œæˆ‘ä»¬å†ä»æ•°å­¦è®¡ç®—çš„è§’åº¦æ¥çœ‹å‰å‘ç®—æ³•ã€‚ç®€åŒ–ä¸€ä¸‹é—®é¢˜ï¼Œå‡è®¾å¥å­é•¿åº¦ä¸º3ï¼Œ$X = [w_0,w_1,w_2]$,åªæœ‰2ä¸ªç±»åˆ«[1,2]<br>æˆ‘ä»¬å¼•å…¥ä¸¤ä¸ªå˜é‡<code>previous</code>å’Œ<code>obs</code>ã€‚<code>previous</code>å­˜å‚¨å‰ä¸€æ—¶åˆ»çš„è®¡ç®—ç»“æœï¼Œ<code>obs</code>å­˜å‚¨å½“å‰çŠ¶æ€åˆ†æ•°ã€‚<br>å¯¹äº$w_0$:$$obs = [x_{01},x_{02}];previous = none$$<br>å¯¹äº$w_0 \to w_1:$,$$previous = [x_{01},x_{02}],obs = [x_{11},x_{12}]$$<br>å…ˆæ‰©å±•<code>previous</code>å’Œ<code>obs</code>ï¼š$$previous = \begin{pmatrix} x_{01}&amp;x_{01}\x_{02}&amp;x_{02} \end{pmatrix} \quad$$$$obs = \begin{pmatrix} x_{11}&amp;x_{12}\x_{11}&amp;x_{12} \end{pmatrix} \quad$$å°†<code>previous</code>å’Œ<code>obs</code>å’Œè½¬ç§»çŸ©é˜µç›¸åŠ ï¼š$$score =\begin{pmatrix} x_{01}&amp;x_{01}\x_{02}&amp;x_{02} \end{pmatrix} +\begin{pmatrix} x_{11}&amp;x_{12}\x_{11}&amp;x_{12} \end{pmatrix}+\begin{pmatrix} t_{11}&amp;t_{12}\t_{21}&amp;t_{22} \end{pmatrix}$$$$  = \begin{pmatrix} x_{01}+x_{11}+t_{11}&amp;x_{01}+x_{12}+t_{12}\x_{02}+x_{11}+t_{21}&amp;x_{02}+x_{12}+t_{22} \end{pmatrix}$$<br>scoreåŒåˆ—ç›¸åŠ ï¼Œæ›´æ–°<code>previous</code>:$$previous = [x_{01}+x_{11}+t_{11}+x_{02}+x_{11}+t_{21},x_{01}+x_{12}+t_{12}+x_{02}+x_{12}+t_{22}]$$<br>è¿™æ ·ç¬¬äºŒæ¬¡è¿­ä»£å°±å®Œæˆäº†ã€‚ç”¨å›¾æ¥è¡¨ç¤ºåˆ°ç›®å‰ä¸ºæ­¢çš„è®¡ç®—ï¼š</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/27.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>ç”¨åŒæ ·çš„æ–¹æ³•è¿­ä»£é€’æ¨ï¼Œå°±å¯ä»¥å¾—åˆ°æ‰€æœ‰è·¯å¾„çš„åˆ†æ•°ã€‚</p><p>è¿™æ ·æˆ‘ä»¬å°±è®¡ç®—å‡ºäº†è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯CRFæ¨¡å‹çš„æŸå¤±å‡½æ•°ã€‚<br>æ¡ä»¶éšæœºåœºçš„ç¬¬äºŒä¸ªåŸºæœ¬é—®é¢˜æ˜¯å­¦ä¹ é—®é¢˜ï¼Œç»™å®šè®­ç»ƒé›†ä¼°è®¡æ¡ä»¶éšæœºåœºçš„æ¨¡å‹å‚æ•°ï¼ˆè½¬ç§»çŸ©é˜µï¼‰ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æœ€å°åŒ–å¯¹æ•°ä¼¼ç„¶å‡½æ•°æ¥æ±‚å‚æ•°æ¨¡å‹ã€‚å¯ä»¥ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥å®ç°ã€‚</p><h2 id="ç»´ç‰¹æ¯”ç®—æ³•è§£ç "><a href="#ç»´ç‰¹æ¯”ç®—æ³•è§£ç " class="headerlink" title="ç»´ç‰¹æ¯”ç®—æ³•è§£ç "></a>ç»´ç‰¹æ¯”ç®—æ³•è§£ç </h2><p>æ¡ä»¶éšæœºåœºçš„ç¬¬ä¸‰ä¸ªåŸºæœ¬é—®é¢˜æ˜¯é¢„æµ‹é—®é¢˜ï¼Œç»™å‡ºæ¡ä»¶éšæœºåœºçš„æ¨¡å‹ å’Œ è¾“å…¥åºåˆ—xï¼Œæ±‚æ¡ä»¶æ¦‚ç‡æœ€å¤§è¾“å‡ºåºåˆ—$y^*$ã€‚ ä¹Ÿå°±æ˜¯æ‰¾å‡ºæ‰€æœ‰è·¯å¾„ä¸­å¾—åˆ†æœ€é«˜çš„é‚£æ¡è·¯å¾„ä½œä¸ºæ ‡æ³¨è·¯å¾„ã€‚ä¸è®¡ç®—æ‰€æœ‰è·¯å¾„æ€»åˆ†ä¸€æ ·ï¼Œæˆ‘ä»¬é¢å¯¹çš„éš¾é¢˜æ˜¯è¦ä¸è¦æ±‚å‡ºæ‰€æœ‰è·¯å¾„çš„åˆ†æ•°ã€‚å½“ç„¶æ˜¯ä¸ç”¨çš„ï¼Œæˆ‘ä»¬ç”¨ç»´ç‰¹æ¯”ç®—æ³•æ¥è§£ç ã€‚<br>é€šä¿¡ä¸“ä¸šçš„åŒå­¦ä¸€å®šçŸ¥é“å¤§åé¼é¼çš„ç»´ç‰¹æ¯”ç®—æ³•ï¼Œå·ç§¯ç çš„è¯‘ç å°±æ˜¯ç”¨çš„ç»´ç‰¹æ¯”ç®—æ³•ã€‚<br>å¯¹äº $w_0 \to w_1$:<br>å…ˆè®¡ç®—$w_0$åˆ°$w_1$çš„çŠ¶æ€1äº”æ¡è·¯å¾„çš„åˆ†æ•°ï¼Œæ‰¾å‡ºåˆ†æ•°æœ€å¤§çš„ä¸€æ¡ä¿ç•™ä¸‹æ¥ï¼Œå…¶ä»–å…¨éƒ½ä¸¢å¼ƒæ‰ã€‚è®¡ç®—é‡ä¸º$O(M)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/28.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>åŒæ ·çš„æ‰¾å‡º$w_1$æ¯ä¸ªçŠ¶æ€åˆ†æ•°æœ€å¤§çš„ä¸€æ¡è·¯å¾„ï¼Œè¦è®¡ç®—$w_1$çš„5ä¸ªçŠ¶æ€ï¼Œè®¡ç®—é‡ä¸º$O(M^2)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/29.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>ä¾æ¬¡é€’æ¨åˆ°å…¨å±€ã€‚åºåˆ—é•¿åº¦ä¸ºN,è®¡ç®—é‡ä¸º$O(N \cdot M^2)$</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/30.png" alt title>                </div>                <div class="image-caption"></div>            </figure><p>æ¯”è¾ƒä¸‹å‰å‘ç®—æ³•ä¸ç»´ç‰¹æ¯”ç®—æ³•çš„å¼‚åŒï¼š<br>ç›¸åŒçš„åœ°æ–¹åœ¨ä»–ä»¬éƒ½é¢ä¸´è¦ä¸è¦è®¡ç®—æ‰€æœ‰è·¯å¾„åˆ†æ•°çš„é—®é¢˜ï¼Œéƒ½æ˜¯åŸºäºè·¯å¾„ç»“æ„ï¼Œç”¨å±€éƒ¨é€’æ¨åˆ°å…¨å±€ã€‚<br>ä¸åŒçš„åœ°æ–¹åœ¨äºå‰å‘ç®—æ³•åœ¨æ›´æ–°previousçš„å•ä¸ªçŠ¶æ€æ—¶æ˜¯åšæ±‚å’Œsumè¿ç®—ï¼Œè€Œç»´ç‰¹æ¯”ç®—æ³•æ˜¯åšmaxè¿ç®—ï¼Œåªä¿ç•™åˆ†æ•°æœ€å¤§çš„ï¼Œä¸¢å¼ƒæ‰å…¶ä»–è·¯å¾„ã€‚æ­¤å¤–ï¼Œç»´ç‰¹æ¯”ç®—æ³•æ‰¾åˆ°åˆ†æ•°æœ€å¤§çš„è·¯å¾„åï¼Œè¿˜è¦åå‘é€’æ¨</p><h2 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h2><ul><li><a href="https://createmomo.github.io/2017/09/12/CRF_Layer_on_the_Top_of_BiLSTM_1/" target="_blank" rel="noopener">CRF Layer on the Top of BiLSTM</a></li><li><a href="https://zhuanlan.zhihu.com/p/44042528" target="_blank" rel="noopener">æœ€é€šä¿—æ˜“æ‡‚çš„BiLSTM-CRFæ¨¡å‹ä¸­çš„CRFå±‚ä»‹ç»</a></li><li><a href="https://mp.weixin.qq.com/s/1KAbFAWC3jgJTE-zp5Qu6g" target="_blank" rel="noopener">å¦‚ä½•ç›´è§‚åœ°ç†è§£æ¡ä»¶éšæœºåœºï¼Œå¹¶é€šè¿‡PyTorchç®€å•åœ°å®ç°</a></li><li><a href="http://www.cnblogs.com/pinard/p/7048333.html" target="_blank" rel="noopener">æ¡ä»¶éšæœºåœºCRFâ€”åˆ˜å»ºå¹³</a></li><li>ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹â€”æèˆª</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;æœ€è¿‘å­¦ä¹ äº†æ¡ä»¶éšæœºåœºCRFï¼Œåšä¸‹æ€»ç»“ã€‚ä¸»è¦å‚è€ƒ&lt;a href=&quot;https://createmomo.github.io/2017/09/12/CRF_Layer_on_the_Top_of_BiLSTM_1/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;BiLSTM+CRFæ¨¡å‹ä¸­çš„CRFå±‚&lt;/a&gt;ä¸ºä¸»çº¿ï¼Œç»“åˆæèˆªè€å¸ˆçš„ã€Šç»Ÿè®¡æœºå™¨å­¦ä¹ ã€‹ï¼Œè®°å½•è‡ªå·±å¯¹CRFçš„ç†è§£ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¹ " scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="æ¡ä»¶éšæœºåœº" scheme="http://yoursite.com/tags/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"/>
    
      <category term="å‰å‘åå‘ç®—æ³•" scheme="http://yoursite.com/tags/%E5%89%8D%E5%90%91%E5%90%8E%E5%90%91%E7%AE%97%E6%B3%95/"/>
    
      <category term="ç»´ç‰¹æ¯”ç®—æ³•" scheme="http://yoursite.com/tags/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>pytorchå®ç°åŸºäºLSTMçš„å¾ªç¯ç¥ç»ç½‘ç»œ</title>
    <link href="http://yoursite.com/2019/03/20/pytorch%E5%AE%9E%E7%8E%B0%E5%9F%BA%E4%BA%8ELSTM%E7%9A%84%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2019/03/20/pytorchå®ç°åŸºäºLSTMçš„å¾ªç¯ç¥ç»ç½‘ç»œ/</id>
    <published>2019-03-20T14:41:10.000Z</published>
    <updated>2019-07-22T01:01:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>ç”¨pytorchå®ç°åŸºäºLSTMçš„å¾ªç¯ç¥ç»ç½‘ç»œã€‚</p><a id="more"></a> <h2 id="æ¶‰åŠå‡½æ•°è¯¦è§£"><a href="#æ¶‰åŠå‡½æ•°è¯¦è§£" class="headerlink" title="æ¶‰åŠå‡½æ•°è¯¦è§£"></a>æ¶‰åŠå‡½æ•°è¯¦è§£</h2><h3 id="class-torch-nn-LSTM-args-kwargs"><a href="#class-torch-nn-LSTM-args-kwargs" class="headerlink" title="class torch.nn.LSTM(args,*kwargs)"></a>class torch.nn.LSTM(args,*kwargs)</h3><ul><li><p>å‚æ•°è¯´æ˜ï¼š</p><ul><li>input_size: è¾“å…¥çš„ç‰¹å¾ç»´åº¦</li><li>output_size: è¾“å‡ºçš„ç‰¹å¾ç»´åº¦</li><li>num_layers: å±‚æ•°ï¼ˆæ³¨æ„ä¸æ—¶åºå±•å¼€åŒºåˆ†ï¼‰</li><li>bidirectional: å¦‚æœä¸º<code>True</code>ï¼Œä¸ºåŒå‘LSTMã€‚é»˜è®¤ä¸º<code>False</code></li></ul></li><li><p>LSTMçš„è¾“å…¥ï¼šinput,$(h_0,c_0)$</p><ul><li>input(seq_len,batch,input_size): åŒ…å«è¾“å…¥ç‰¹å¾çš„<code>tensor</code>,æ³¨æ„è¾“å…¥æ˜¯<code>tensor</code>ã€‚</li><li>$h_0$(num_layers $\cdot$ num_directions,batch,hidden_size): ä¿å­˜åˆå§‹åŒ–éšè—å±‚çŠ¶æ€çš„<code>tensor</code></li><li>$c_0$(num_layers $\cdot$ num_directions,batch,hidden_size): ä¿å­˜åˆå§‹åŒ–ç»†èƒçŠ¶æ€çš„<code>tensor</code></li></ul></li><li><p>LSTMçš„è¾“å‡ºï¼š output,$(h_n,c_n)$</p><ul><li>output(seq_len, batch, hidden_size * num_directions): ä¿å­˜<code>RNN</code>æœ€åä¸€å±‚è¾“å‡ºçš„<code>tensor</code></li><li>$h_n$(num_layers * num_directions,batch,hidden_size): ä¿å­˜<code>RNN</code>æœ€åä¸€ä¸ªæ—¶é—´æ­¥éšè—çŠ¶æ€çš„<code>tensor</code></li><li>$c_n$(num_layers * num_directions,batch,hidden_size): ä¿å­˜<code>RNN</code>æœ€åä¸€ä¸ªæ—¶é—´æ­¥ç»†èƒçŠ¶æ€çš„<code>tensor</code></li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import torch.nn </span><br><span class="line">import torch</span><br><span class="line">lstm = nn.LSTM(embedding_dim,hidden_dim) #å®ä¾‹åŒ–ä¸€ä¸ªLSTMå•å…ƒï¼Œè¯¥å•å…ƒè¾“å…¥ç»´åº¦embedding_dim,è¾“å‡ºç»´åº¦ä¸ºhidden_dim</span><br><span class="line">input = Variable(torch.randn(seq_len,1,embedding_dim)) # è¾“å…¥inputåº”è¯¥æ˜¯ä¸‰ç»´çš„ï¼Œç¬¬ä¸€ç»´åº¦æ˜¯seq-length,ä¹Ÿå°±æ˜¯å¤šä¸ªè¯æ„æˆçš„ä¸€å¥è¯ï¼›ç¬¬äºŒç»´åº¦ä¸º1ï¼Œä¸ç”¨ç®¡ï¼›ç¬¬ä¸‰ä¸ªç»´åº¦æ˜¯ä¸€ä¸ªè¯çš„è¯åµŒå…¥ç»´åº¦ï¼Œå³embedding_dim</span><br><span class="line">h0 = Variable(torch.randn(1,1,hidden_dim)) </span><br><span class="line">c0 = Variable(torch.randn(1,1,hidden_dim))</span><br><span class="line">lstm_out,hidden = lstm(input,(h0,c0))</span><br></pre></td></tr></table></figure><h3 id="class-torch-nn-Linear"><a href="#class-torch-nn-Linear" class="headerlink" title="class torch.nn.Linear()"></a>class torch.nn.Linear()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class torch.nn.Linear(in_features,out_features,bias = True)</span><br></pre></td></tr></table></figure><ul><li>ä½œç”¨ï¼šå¯¹è¾“å…¥æ•°æ®åšçº¿æ€§å˜æ¢ã€‚$y = Ax+b$</li><li>å‚æ•°ï¼š<ul><li>in_featuresï¼šæ¯ä¸ªè¾“å…¥æ ·æœ¬çš„å¤§å°</li><li>out_features: æ¯ä¸ªè¾“å‡ºæ ·æœ¬çš„å¤§å°</li><li>bias: é»˜è®¤å€¼ä¸ºTrueã€‚æ˜¯å¦å­¦ä¹ åç½®ã€‚</li></ul></li><li>å½¢çŠ¶ï¼š<ul><li>è¾“å…¥ï¼š (N,in_features)</li><li>è¾“å‡ºï¼š (N,out_features)</li></ul></li><li>å˜é‡ï¼š<ul><li>weights: å¯å­¦ä¹ çš„æƒé‡ï¼Œå½¢çŠ¶ä¸º(in_features,out_features)</li><li>bias: å¯å­¦ä¹ çš„åç½®ï¼Œå½¢çŠ¶ä¸º(out_features)</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">m = nn.Linear(20,30)</span><br><span class="line">input = torch.randn(128,20)</span><br><span class="line">output = m(input)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure><h2 id="å…ˆçœ‹ä¸ªå°ä¾‹å­"><a href="#å…ˆçœ‹ä¸ªå°ä¾‹å­" class="headerlink" title="å…ˆçœ‹ä¸ªå°ä¾‹å­"></a>å…ˆçœ‹ä¸ªå°ä¾‹å­</h2><p>ç”¨pytorchå®ç°LSTMï¼Œå…ˆå®ä¾‹åŒ–ä¸€ä¸ªLSTMå•å…ƒï¼Œå†ç»™å‡ºtensorç±»å‹çš„è¾“å…¥æ•°æ®inputsåŠåˆå§‹éšè—çŠ¶æ€hidden = $(h_0,c_0)$ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLSTMå•å…ƒçš„è¾“å…¥inputså¿…é¡»æ˜¯ä¸‰ç»´çš„ï¼Œç¬¬ä¸€ç»´æ˜¯seq-lengthï¼Œå³ä¸€å¥è¯ï¼Œå…ƒç´ æ˜¯è¯ã€‚ç¬¬äºŒç»´æ˜¯mini-batch,ä»æ¥ä¸ç”¨ï¼Œè®¾ä¸º1å³å¯ã€‚ç¬¬ä¸‰ç»´æ˜¯embedding-size,å³ä¸€ä¸ªè¯å‘é‡ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">import torch.nn as nn </span><br><span class="line"></span><br><span class="line">lstm = nn.LSTM(4,3) #å®ä¾‹åŒ–ä¸€ä¸ªLSTMå•å…ƒï¼Œå•å…ƒè¾“å…¥ç»´åº¦æ˜¯4ï¼Œè¾“å‡ºç»´åº¦æ˜¯3</span><br><span class="line">inputs = [torch.randn(1,5) for _ in range(5)] #äº§ç”Ÿè¾“å…¥inputsã€‚ä¸ºtensoråºåˆ—ã€‚</span><br><span class="line">hidden = (torch.randn(1,1,3),torch.randn(1,1,3)) #åˆå§‹åŒ–éšè—çŠ¶æ€</span><br></pre></td></tr></table></figure><p>åšå¥½ä¸‰æ­¥å‡†å¤‡ï¼šå®ä¾‹åŒ–ä¸€ä¸ªLSTMå•å…ƒï¼Œå‡†å¤‡å¥½inputsï¼Œåˆå§‹åŒ–éšè—çŠ¶æ€hiddenã€‚æˆ‘ä»¬å°±å¯ä»¥è®¡ç®—LSTMå•å…ƒçš„è¾“å‡ºäº†ã€‚<br>æˆ‘ä»¬æœ‰ä¸¤ç§é€‰æ‹©ï¼Œå°†åºåˆ—ä¸€ä¸ªå…ƒç´ ä¸€ä¸ªå…ƒç´ åœ°é€å…¥LSTMå•å…ƒï¼Œæˆ–æ˜¯å°†æ•´ä¸ªåºåˆ—ä¸€ä¸‹å­å…¨é€å…¥LSTMå•å…ƒã€‚å…ˆçœ‹çœ‹ç¬¬ä¸€ç§ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for x in inputs:</span><br><span class="line">    lstm_out,hidden = lstm(x.view(1,1,-1),hidden) #x.view(1,1,-1)å°†tensoræ•´å½¢ä¸ºä¸‰ç»´ã€‚å‰é¢è¯´è¿‡LSTMå•å…ƒçš„è¾“å…¥å¿…é¡»æ˜¯ä¸‰ç»´çš„ã€‚</span><br><span class="line">print(lstm_out,hidden)</span><br></pre></td></tr></table></figure><p>æ¥ä¸‹æ¥ï¼Œå°†æ•´ä¸ªåºåˆ—é€å…¥LSTMå•å…ƒï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.cat(inputs).view(len(inputs),1,-1) #å°†æ•´ä¸ªåºåˆ—è¿æ¥ä¸ºtensorï¼Œå¹¶æ•´å½¢ä¸ºä¸‰ç»´ã€‚</span><br><span class="line">hidden = (torch.randn(1,1,3),torch.randn(1,1,3)) #æ¸…æ¥šéšè—çŠ¶æ€</span><br><span class="line">lstm_out,hidden = lstm(inputs,hidden)</span><br><span class="line">print(lstm_out,hidden)</span><br></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼š</p><ul><li>lstm_out ä¸­åŒ…å«äº†åºåˆ—æ‰€æœ‰çš„éšè—çŠ¶æ€ã€‚</li><li>hidden ä¸­åŒ…å«äº†æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€å’Œç»†èƒçŠ¶æ€ã€‚å¯ä»¥ä½œä¸ºä¸‹ä¸ªæ—¶é—´æ­¥LSTMå•å…ƒçš„è¾“å…¥å‚æ•°ï¼Œç»§ç»­è¾“å…¥åºåˆ—æˆ–åå‘ä¼ æ’­ã€‚</li></ul><h2 id="ç”¨lstmåšè¯æ€§æ ‡æ³¨"><a href="#ç”¨lstmåšè¯æ€§æ ‡æ³¨" class="headerlink" title="ç”¨lstmåšè¯æ€§æ ‡æ³¨"></a>ç”¨lstmåšè¯æ€§æ ‡æ³¨</h2><p>å…ˆå‡†å¤‡è®­ç»ƒæ•°æ®ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">train_data = [</span><br><span class="line">    (&quot;The dog ate the apple&quot;.split(), [&quot;DET&quot;, &quot;NN&quot;, &quot;V&quot;, &quot;DET&quot;, &quot;NN&quot;]),</span><br><span class="line">    (&quot;Everybody read that book&quot;.split(), [&quot;NN&quot;, &quot;V&quot;, &quot;DET&quot;, &quot;NN&quot;])</span><br><span class="line">]</span><br><span class="line"># è¯æ±‡è¡¨å­—å…¸</span><br><span class="line">word_to_ix = &#123;&#125;</span><br><span class="line">for sent,tags in train_data:</span><br><span class="line">    for word in sent:</span><br><span class="line">        if word not in word_to_ix:</span><br><span class="line">            word_to_ix[word] = len(word_to_ix)</span><br><span class="line"># æ ‡ç­¾é›†å­—å…¸</span><br><span class="line">tag_to_ix = &#123;&quot;DET&quot;: 0, &quot;NN&quot;: 1, &quot;V&quot;: 2&#125;</span><br><span class="line"></span><br><span class="line">EMBEDDING_DIM = 6</span><br><span class="line">HIDDEN_DIM = 6</span><br></pre></td></tr></table></figure><p>æ„å»ºLSTMæ¨¡å‹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">class LSTMtagger(nn.Module):</span><br><span class="line">    def __init__(self,embedding_dim,hidden_dim,vocab_size,tagset_size):</span><br><span class="line">        super(LSTMtagger,self).__init__()</span><br><span class="line">        self.hidden_dim = hidden_dim</span><br><span class="line">        self.word_embeddings = nn.Embedding(vocab_size,embedding_dim) #éšæœºåˆå§‹åŒ–è¯å‘é‡è¡¨ï¼Œæ˜¯ç¥ç»ç½‘ç»œçš„å‚æ•°</span><br><span class="line">        self.lstm = nn.LSTM(embedding_dim,hidden_dim) #å®ä¾‹åŒ–ä¸€ä¸ªLSTMå•å…ƒï¼Œå•å…ƒè¾“å…¥ç»´åº¦æ˜¯embedding_dimï¼Œè¾“å‡ºç»´åº¦æ˜¯hidden_dim</span><br><span class="line">        self.hidden2tag = torch.Linear(hidden_dim,tagset_size) #çº¿æ€§å±‚ä»éšè—çŠ¶æ€ç©ºé—´æ˜ å°„åˆ°æ ‡ç­¾ç©ºé—´</span><br><span class="line">    def forward(self,sentence):</span><br><span class="line">        embeds = self.word_embeddings(sentence) #æŸ¥è¯¢å¥å­çš„è¯å‘é‡è¡¨ç¤ºã€‚è¾“å…¥åº”è¯¥æ˜¯äºŒç»´tensorã€‚</span><br><span class="line">        lstm_out,hidden = self.lstm(embeds.view(len(sentence),1,-1))</span><br><span class="line">        tag_space = self.hidden2tag(lstm_out.view(len(sentence),-1))</span><br><span class="line">        tag_scores = F.log_softmax(tag_space)</span><br></pre></td></tr></table></figure><p>è®­ç»ƒæ¨¡å‹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">model = LSTMtagger(EMBEDDING_DIM,HIDDEN_DIM,len(word_to_ix),len(tag_to_ix))</span><br><span class="line">loss_function = nn.NLLLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(),lr = 0.1)</span><br><span class="line"></span><br><span class="line">def prepare_sequence(seq,to_ix):</span><br><span class="line">    idxs = [to_ix[w] for w in seq]</span><br><span class="line">    return torch.tensor(idxs,dtype = torch.long)</span><br><span class="line"># åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œçœ‹çœ‹æ¨¡å‹é¢„æµ‹ç»“æœ</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    inputs = prepare_sequence(train_data[0][0],word_to_ix)</span><br><span class="line">    tag_scores = model(inputs)</span><br><span class="line">    print(tag_scores)</span><br><span class="line">    predict = np.argmax(tag_scores,axis = 1)</span><br><span class="line">    print(predict)</span><br><span class="line"></span><br><span class="line">for epoch in range(300):</span><br><span class="line">    for sentence,tags in train_data:</span><br><span class="line">        # step 1:pytorchä¼šç´¯ç§¯æ¢¯åº¦ï¼Œè¦æ¸…æ¥šæ‰€æœ‰variableçš„æ¢¯åº¦ã€‚</span><br><span class="line">        model.zero_grad()</span><br><span class="line">        # step 2:å‡†å¤‡å¥½æ•°æ®ï¼Œå˜æˆtensor</span><br><span class="line">        sentence_in = prepare_sequence(sentence,word_to_ix)</span><br><span class="line">        targets = prepare_sequence(tags,tag_to_ix)</span><br><span class="line">        # step 3:å¾—åˆ°è¾“å‡º</span><br><span class="line">        tag_scores = model(sentence_in)</span><br><span class="line">        # step4: è®¡ç®—loss</span><br><span class="line">        loss = loss_function(tag_scores,targets)</span><br><span class="line">        # step5: è®¡ç®—losså¯¹æ‰€æœ‰variableçš„æ¢¯åº¦</span><br><span class="line">        loss.backward()</span><br><span class="line">        # step6ï¼š å•æ­¥ä¼˜åŒ–ï¼Œæ ¹æ®æ¢¯åº¦æ›´æ–°å‚æ•°</span><br><span class="line">        optimizer.step()</span><br><span class="line"># æ¨¡å‹è®­ç»ƒåï¼Œçœ‹çœ‹é¢„æµ‹ç»“æœ</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    inputs = prepare_sequence(train_data[0][0],word_to_ix)</span><br><span class="line">    tag_scores = model(inputs)</span><br><span class="line">    print(tag_scores)</span><br><span class="line">    predict = np.argmax(tag_scores,axis = 1)</span><br><span class="line">    print(predict)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºç»“æœä¸ºï¼š<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/19.png" alt title>                </div>                <div class="image-caption"></div>            </figure>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè®­ç»ƒä¹‹åçš„é¢„æµ‹åºåˆ—ä¸º [0,1,2,0,1]ä¹Ÿå°±æ˜¯[â€œDETâ€, â€œNNâ€, â€œVâ€, â€œDETâ€, â€œNNâ€]</p><h2 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/28448135" target="_blank" rel="noopener">åºåˆ—æ¨¡å‹å’ŒåŸºäºLSTMçš„å¾ªç¯ç¥ç»ç½‘ç»œ</a></li><li><a href="https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html" target="_blank" rel="noopener">Sequence Models and Long-Short Term Memory Networks-å®˜æ–¹</a></li><li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a></li><li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ç”¨pytorchå®ç°åŸºäºLSTMçš„å¾ªç¯ç¥ç»ç½‘ç»œã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
      <category term="å¾ªç¯ç¥ç»ç½‘ç»œ" scheme="http://yoursite.com/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>pytorchå®ç°Word embedding</title>
    <link href="http://yoursite.com/2019/03/20/pytorch%E5%AE%9E%E7%8E%B0Word-embedding/"/>
    <id>http://yoursite.com/2019/03/20/pytorchå®ç°Word-embedding/</id>
    <published>2019-03-20T12:16:21.000Z</published>
    <updated>2019-07-07T07:11:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>word embeddingæ˜¯ç¨ å¯†çš„å®æ•°å‘é‡ã€‚Word embeddingæ˜¯ä¸€ä¸ªè¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œæœ‰æ•ˆåœ°ç¼–ç äº†è¯çš„è¯­ä¹‰ä¿¡æ¯ã€‚</p><a id="more"></a> <h2 id="one-hotç¼–ç "><a href="#one-hotç¼–ç " class="headerlink" title="one-hotç¼–ç "></a>one-hotç¼–ç </h2><p>åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å¸¸å¸¸è¦ä¸è¯æ‰“äº¤é“ã€‚é‚£ä¹ˆåœ¨è®¡ç®—æœºä¸Šï¼Œæˆ‘ä»¬æ€ä¹ˆè¡¨ç¤ºä¸€ä¸ªå•è¯å‘¢ï¼Ÿä¸€ç§æ€è·¯æ˜¯one-hotç¼–ç ã€‚å‡è®¾è¯æ±‡è¡¨ä¸º$V$,è¯æ±‡è¡¨å¤§å°(vocab_size)ä¸º$N_V$ã€‚æˆ‘ä»¬å¯ä»¥ç”¨å‘é‡$N_V$ç»´å‘é‡$[1,0,0â€¦,0,0]$æ¥è¡¨ç¤ºç¬¬ä¸€ä¸ªè¯ã€‚ä»¥æ­¤ç±»æ¨ï¼Œæ¥è¡¨ç¤ºæ‰€æœ‰çš„è¯ã€‚<br>è¿™ç§æ–¹æ³•æœ‰è‡´å‘½çš„å¼±ç‚¹ã€‚é¦–å…ˆæ˜¯å‘é‡ç»´åº¦å¤ªå¤§ï¼Œå¤ªç¨€ç–ï¼Œæ•ˆç‡å¤ªä½ã€‚æ›´è¦å‘½çš„æ˜¯ï¼Œone-hotç¼–ç æŠŠè¯ä¸è¯é—´çœ‹åšå®Œå…¨ç‹¬ç«‹çš„ï¼Œæ²¡æœ‰è¡¨è¾¾å‡ºè¯ä¸è¯ä¹‹é—´çš„è”ç³»å’Œç›¸ä¼¼æ€§ã€‚è€Œè¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚<br>ä¸¾ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬æƒ³è¦æ„å»ºä¸€ä¸ªè¯­è¨€æ¨¡å‹ã€‚æœ‰ä»¥ä¸‹ä¸‰ä¸ªå¥å­</p><ul><li>æ•°å­¦å®¶å¾…åœ¨å®éªŒå®¤é‡Œã€‚</li><li>ç‰©ç†å­¦å®¶å¾…åœ¨å®éªŒå®¤é‡Œã€‚</li><li>æ•°å­¦å®¶è§£å†³äº†ä¸€ä¸ªéš¾é¢˜ã€‚</li></ul><p>æˆ‘ä»¬åˆçœ‹åˆ°ä¸€ä¸ªæ–°çš„å¥å­ï¼š</p><ul><li>ç‰©ç†å­¦å®¶è§£å†³äº†ä¸€ä¸ªéš¾é¢˜ã€‚</li></ul><p>æˆ‘ä»¬å¸Œæœ›è¯­è¨€æ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°ä»¥ä¸‹ç‰¹ç‚¹ï¼š</p><ul><li><code>æ•°å­¦å®¶</code>å’Œ<code>ç‰©ç†å­¦å®¶</code>åœ¨ä¸€ä¸ªå¥å­ä¸­åŒæ ·çš„ä½ç½®å‡ºç°ã€‚è¿™ä¸¤ä¸ªè¯ä¹‹é—´æœ‰æŸç§è¯­ä¹‰ä¸Šçš„è”ç³»</li><li><code>æ•°å­¦å®¶</code>æ›¾ç»å‡ºç°åœ¨æˆ‘ä»¬çœ‹åˆ°çš„è¿™ä¸ªæ–°å¥å­ä¸­<code>ç‰©ç†å­¦å®¶</code>å‡ºç°çš„ä½ç½®ã€‚</li></ul><p>è¿™å°±æ˜¯<strong>è¯­ä¹‰ç›¸ä¼¼æ€§</strong>æƒ³è¡¨è¾¾çš„ã€‚è¯­ä¹‰ç›¸ä¼¼æ€§å¯ä»¥å°†æ²¡è§è¿‡çš„æ•°æ®ä¸å·²ç»è§è¿‡çš„æ•°æ®è”ç³»èµ·æ¥ï¼Œæ¥è§£å†³è¯­è¨€æ•°æ®çš„ç¨€ç–æ€§é—®é¢˜ã€‚è¿™ä¸ªä¾‹å­åŸºäºä¸€ä¸ªåŸºæœ¬çš„è¯­ä¹‰å­¦å‡è®¾ï¼šå‡ºç°åœ¨ç›¸ä¼¼æ–‡æœ¬ä¸­çš„è¯æ±‡åœ¨è¯­ä¹‰ä¸Šæ˜¯ç›¸äº’è”ç³»çš„ã€‚è¿™ç§°ä¸º<strong>distributional hypothesis</strong><br>å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œone-hotç¼–ç å¾ˆé€‚åˆç”¨åœ¨ç±»åˆ«çš„ç¼–ç ä¸Šã€‚</p><h2 id="word-embedding"><a href="#word-embedding" class="headerlink" title="word embedding"></a>word embedding</h2><p>æˆ‘ä»¬æ€æ ·ç¼–ç æ¥è¡¨è¾¾è¯æ±‡çš„è¯­ä¹‰ç›¸ä¼¼æ€§å‘¢ï¼Ÿæˆ‘ä»¬è€ƒè™‘è¯æ±‡çš„semantic attributesã€‚ä¾‹å¦‚ï¼Œç‰©ç†å­¦å®¶å’Œæ•°å­¦å®¶å­¦å¯èƒ½[å¤´å‘ä¸å¤šï¼Œçˆ±å–å’–å•¡ï¼Œä¼šçœ‹è®ºæ–‡ï¼Œä¼šè¯´è‹±è¯­]ã€‚æˆ‘ä»¬å¯ä»¥ç”¨è¿™å››ä¸ªå±æ€§æ¥ç¼–ç <code>ç‰©ç†å­¦å®¶</code>å’Œ<code>æ•°å­¦å®¶</code>ã€‚$$q_ç‰© = [0.9,0.8,0.98,0.8]$$$$q_æ•° = [0.91,0.89,0.9,0.85]$$<br>æˆ‘ä»¬å¯ä»¥è¡¡é‡è¿™ä¸¤ä¸ªè¯ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼š$$similarity(q_ç‰©,q_æ•°) = \frac{q_ç‰©\cdot q_æ•°}{|q_ç‰©| \cdot |q_æ•°|}=cos(\phi)    å…¶ä¸­\phiæ˜¯ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„å¤¹è§’ã€‚$$<br>ä½†æˆ‘ä»¬å¦‚ä½•é€‰æ‹©å±æ€§ç‰¹å¾ï¼Œå¹¶å†³å®šæ¯ä¸ªå±æ€§çš„å€¼å‘¢ï¼Ÿæ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³æ˜¯ç¥ç»ç½‘ç»œå­¦ä¹ ç‰¹å¾è¡¨ç¤ºï¼Œè€Œä¸ç”¨äººä¸ºæŒ‡å®šç‰¹å¾ã€‚æˆ‘ä»¬å¹²è„†å°†Word embeddingä½œä¸ºç¥ç»ç½‘ç»œçš„å‚æ•°ï¼Œè®©ç¥ç»ç½‘ç»œåœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­å­¦ä¹ Word embeddingã€‚<br>ç¥ç»ç½‘ç»œå­¦åˆ°çš„Word embeddingæ˜¯æ½œåœ¨è¯­ä¹‰å±æ€§ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœä¸¤ä¸ªè¯åœ¨æŸä¸ªç»´åº¦ä¸Šéƒ½æœ‰å¤§çš„å€¼ï¼Œæˆ‘ä»¬å¹¶ä¸çŸ¥é“è¿™ä¸ªç»´åº¦ä»£è¡¨äº†ä»€ä¹ˆå±æ€§ï¼Œè¿™ä¸èƒ½äººä¸ºè§£é‡Šã€‚è¿™å°±æ˜¯æ½œåœ¨è¯­ä¹‰å±æ€§çš„å«ä¹‰ã€‚<br>æ€»çš„æ¥è¯´ï¼ŒWord embeddingæ˜¯ä¸€ä¸ªè¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œæœ‰æ•ˆåœ°ç¼–ç äº†è¯çš„è¯­ä¹‰ä¿¡æ¯ã€‚</p><h2 id="PyTorchå®ç°word-embedding"><a href="#PyTorchå®ç°word-embedding" class="headerlink" title="PyTorchå®ç°word embedding"></a>PyTorchå®ç°word embedding</h2><p>ä»£ç å¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"># è¯æ±‡è¡¨å­—å…¸</span><br><span class="line">word_to_ix = &#123;&apos;The&apos;: 0, &apos;dog&apos;: 1, &apos;ate&apos;: 2, &apos;the&apos;: 3, &apos;apple&apos;: 4, &apos;Everybody&apos;: 5, &apos;read&apos;: 6, &apos;that&apos;: 7, &apos;book&apos;: 8&#125;</span><br><span class="line">vocab_size = len(word_to_ix) </span><br><span class="line">embedding_dim = 15</span><br><span class="line">word_embeddings = nn.Embedding(vocab_size,embedding_dim)</span><br></pre></td></tr></table></figure><p><code>nn.Embedding()</code>éšæœºåˆå§‹åŒ–äº†ä¸€ä¸ªå½¢çŠ¶ä¸º[vocab_size,embedding_dim]çš„è¯å‘é‡çŸ©é˜µï¼Œæ˜¯ç¥ç»ç½‘ç»œçš„å‚æ•°ã€‚<br>æ¥ä¸‹æ¥æˆ‘ä»¬æŸ¥è¯¢â€dogâ€è¿™ä¸ªè¯çš„å‘é‡è¡¨ç¤ºã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dog_idx = torch.LongTensor([word_to_ix[&apos;dog&apos;]]) #æ³¨æ„è¾“å…¥åº”è¯¥æ˜¯ä¸€ç»´æ•°ç»„ã€‚</span><br><span class="line">dog_idx = Variable(dog_idx)</span><br><span class="line">dog_embed = word_embeddings(dog_idx) #æ³¨æ„ä¸æ˜¯ç´¢å¼•</span><br><span class="line">print(dog_embed)</span><br></pre></td></tr></table></figure><p>ä¸Šè¿°ä»£ç ä¸­ï¼Œè¦è®¿é—®<code>dog</code>çš„è¯å‘é‡ï¼Œè¦å¾—åˆ°ä¸€ä¸ªVariableã€‚word_embeddingsçš„è¾“å…¥åº”è¯¥æ˜¯ä¸€ä¸ªä¸€ç»´tensorã€‚<br>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æŸ¥è¯¢ä¸€å¥è¯çš„å‘é‡è¡¨ç¤ºã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sent = &apos;The dog ate the apple&apos;.split()</span><br><span class="line">sent_idxs = [word_to_ix[w] for w in sent]</span><br><span class="line">sent_idxs = torch.LongTensor(sent_idxs)</span><br><span class="line">sent_idxs = Variable(sent_idxs)</span><br><span class="line">sent_embeds = embeds(sent_idxs) </span><br><span class="line">print(sent_embeds)</span><br></pre></td></tr></table></figure><h2 id="pytorchåŠ è½½é¢„è®­ç»ƒè¯å‘é‡"><a href="#pytorchåŠ è½½é¢„è®­ç»ƒè¯å‘é‡" class="headerlink" title="pytorchåŠ è½½é¢„è®­ç»ƒè¯å‘é‡"></a>pytorchåŠ è½½é¢„è®­ç»ƒè¯å‘é‡</h2><p>ä¹‹å‰çš„æ–¹æ³•ä¸­ï¼Œè¯å‘é‡æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œä½œä¸ºæ¨¡å‹å‚æ•°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­ä¼˜åŒ–ã€‚é€šå¸¸æˆ‘ä»¬è¦ç”¨åˆ°é¢„è®­ç»ƒçš„è¯å‘é‡ï¼Œè¿™æ ·å¯ä»¥èŠ‚çœè®­ç»ƒæ—¶é—´ï¼Œå¹¶å¯èƒ½å–å¾—æ›´å¥½çš„è®­ç»ƒç»“æœã€‚ä¸‹é¢ä»‹ç»ä¸¤ç§åŠ è½½é¢„è®­ç»ƒè¯å‘é‡çš„æ–¹å¼ã€‚<br>æ–¹å¼ä¸€ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">word_embeddings = torch.nn.Embedding(vocab_size,embedding_dim) #åˆ›å»ºä¸€ä¸ªè¯å‘é‡çŸ©é˜µ</span><br><span class="line">pretrain_embedding  = np.array(np.load(np_path),dtype = &apos;float32&apos;) #np_pathæ˜¯ä¸€ä¸ªå­˜å‚¨é¢„è®­ç»ƒè¯å‘é‡çš„æ–‡ä»¶è·¯å¾„</span><br><span class="line">word_embeddings.weight.data.copy_(troch.from_numpy(pretrain_embedding)) #æ€è·¯æ˜¯å°†np.ndarrayå½¢å¼çš„è¯å‘é‡è½¬æ¢ä¸ºpytorchçš„tensorï¼Œå†å¤åˆ¶åˆ°åŸæ¥åˆ›å»ºçš„è¯å‘é‡çŸ©é˜µä¸­</span><br></pre></td></tr></table></figure><p>æ–¹å¼äºŒï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">word_embeddings = torch.nn.Embedding(vocab_size,embedding_dim) #åˆ›å»ºä¸€ä¸ªè¯å‘é‡çŸ©é˜µ</span><br><span class="line">word_embeddings.weight = nn.Parameter(torch.FloatTensor(pretrain_embedding))</span><br></pre></td></tr></table></figure><h3 id="æ¶‰åŠå‡½æ•°è¯¦è§£"><a href="#æ¶‰åŠå‡½æ•°è¯¦è§£" class="headerlink" title="æ¶‰åŠå‡½æ•°è¯¦è§£"></a>æ¶‰åŠå‡½æ•°è¯¦è§£</h3><h4 id="numpy-ä¸from-numpy"><a href="#numpy-ä¸from-numpy" class="headerlink" title="numpy()ä¸from_numpy()"></a>numpy()ä¸from_numpy()</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.from_numpy(ndarray) $\to$ tensor</span><br></pre></td></tr></table></figure><ul><li>ä½œç”¨ï¼šnumpyæ¡¥ï¼Œå°†<code>numpy.ndarray</code>è½¬æ¢ä¸ºpytorchçš„<code>tensor</code>.è¿”å›çš„å¼ é‡ä¸numpy.ndarrayå…±äº«åŒä¸€å†…å­˜ç©ºé—´ï¼Œä¿®æ”¹ä¸€ä¸ªå¦ä¸€ä¸ªä¹Ÿä¼šè¢«ä¿®æ”¹ã€‚</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor.numpy()</span><br></pre></td></tr></table></figure><ul><li>ä½œç”¨ï¼šnumpyæ¡¥ï¼Œå°†pytorchçš„<code>tensor</code>è½¬æ¢ä¸º<code>numpy.ndarray</code>.äºŒè€…å…±äº«åŒä¸€å†…å­˜ç©ºé—´ï¼Œä¿®æ”¹ä¸€ä¸ªå¦ä¸€ä¸ªä¹Ÿä¼šè¢«ä¿®æ”¹ã€‚</li></ul><p>ä¸¾ä¸ªä¾‹å­ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(5)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">c = b.numpy()</span><br></pre></td></tr></table></figure><h4 id="tensor-copy-src"><a href="#tensor-copy-src" class="headerlink" title="tensor.copy_(src)"></a>tensor.copy_(src)</h4><ul><li>ä½œç”¨ï¼šå°†<code>src</code>ä¸­çš„å…ƒç´ å¤åˆ¶åˆ°tensorå¹¶è¿”å›ã€‚ä¸¤ä¸ªtensoråº”è¯¥æœ‰ç›¸åŒæ•°ç›®çš„å…ƒç´ å’Œå½¢çŠ¶ï¼Œå¯ä»¥æ˜¯ä¸åŒæ•°æ®ç±»å‹æˆ–å­˜å‚¨åœ¨ä¸åŒè®¾å¤‡ä¸Šã€‚</li></ul><p>ä¸¾ä¸ªä¾‹å­ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(1,5)</span><br><span class="line">b = torch.randn(1,5)</span><br><span class="line">b.copy_(a)</span><br></pre></td></tr></table></figure><h2 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h2><ul><li><a href="https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html?highlight=embed" target="_blank" rel="noopener">Word Embeddings: Encoding Lexical Semantics</a></li><li><a href="https://ptorch.com/news/11.html" target="_blank" rel="noopener">PyTorchå¿«é€Ÿå…¥é—¨æ•™ç¨‹ä¸ƒï¼ˆRNNåšè‡ªç„¶è¯­è¨€å¤„ç†ï¼‰</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;word embeddingæ˜¯ç¨ å¯†çš„å®æ•°å‘é‡ã€‚Word embeddingæ˜¯ä¸€ä¸ªè¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œæœ‰æ•ˆåœ°ç¼–ç äº†è¯çš„è¯­ä¹‰ä¿¡æ¯ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
      <category term="word embedding" scheme="http://yoursite.com/tags/word-embedding/"/>
    
  </entry>
  
  <entry>
    <title>å»æ–°è—çº¿ä¸Šéª‘è½¦</title>
    <link href="http://yoursite.com/2019/03/14/%E5%8E%BB%E6%96%B0%E8%97%8F%E7%BA%BF%E4%B8%8A%E9%AA%91%E8%BD%A6/"/>
    <id>http://yoursite.com/2019/03/14/å»æ–°è—çº¿ä¸Šéª‘è½¦/</id>
    <published>2019-03-14T09:49:34.000Z</published>
    <updated>2019-07-22T00:58:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>18å¹´çš„å¤å¤©ï¼Œçƒ­çƒˆçš„é˜³å…‰é€è¿‡æµ“å¯†çš„å¶å­ç…§åœ¨çª—å°çš„ç›†æ ½ä¸Šï¼Œæœ‰ç€ä¸ä¸çš„é£ã€‚å°±åœ¨è¿™ç¾ä¸½çš„å­£èŠ‚é‡Œï¼Œæˆ‘ä»¬æ¯•ä¸šäº†ã€‚æ¯•ä¸šåçš„æš‘å‡ï¼Œæˆ‘ç»ˆäºåšåˆ°äº†æˆ‘æƒ³åšçš„ä¸€ä»¶äº‹ï¼Œéª‘è½¦å»é‚£å°å°çš„å°¼æ³Šå°”ã€‚</p><a id="more"></a><p>è¯¥è¯´è¯´å‡ºå‘çš„åŠ¨æœºå’Œæƒ…æ™¯ã€‚æˆ‘æ›¾ç»äº§ç”Ÿè¿™æ ·çš„å¿µå¤´ï¼šâ€œéª‘è½¦å‡ºå›½ï¼Œæ¨ªç©¿æ•´ä¸ªæ¬§äºšå¤§é™†ï¼Œæ˜¯ä»¶äº†ä¸èµ·çš„äº‹å•Šï¼â€ç›´åˆ°æ—ºå“¥åœ¨è®ºå›ä¸Šå‘å¸–å¾æ–°è—çº¿çš„é˜Ÿå‹ï¼Œè¿™ä¸ªå¿µå¤´ä¿ƒä½¿æˆ‘ä¸‹äº†å†³å¿ƒå»æ–°è—çº¿ä¸Šéª‘è½¦ã€‚å‡ºå‘å‰è¿˜éœ€è¦åšäº›å‡†å¤‡ï¼Œå…‹æœä¸€äº›é˜»åŠ›ã€‚æˆ‘å›å®¶åŠäº†æŠ¤ç…§å’Œè¾¹é˜²è¯ï¼Œåœ¨åŒ—äº¬åŠå¥½äº†å°¼æ³Šå°”çš„ç­¾è¯ï¼Œåœ¨å­¦æ ¡åšå¥½è·¯ä¹¦å’Œé«˜ç¨‹å›¾ï¼Œå‡†å¤‡å¥½äº†è¡£æœè£…å¤‡ã€‚å‡ºå‘å‰ï¼Œè¶…å“¥ã€å¤§èƒ–å„¿å’Œç‹—å­å¸®æˆ‘ä¿®ç†äº†æˆ‘é‚£è¾†éš¾éª‘çš„è½¦ã€‚æˆ‘æ›¾æ€€ç–‘æˆ‘è¿™ä¸ªå¿µå¤´æ˜¯ä¸æ˜¯å¿ƒè¡€æ¥æ½®ï¼Œæˆ‘é—®å¼Ÿå¼Ÿï¼šâ€œæˆ‘éª‘è½¦å¤ªå¤šäº†ï¼Œæ˜¯ä¸æ˜¯æœ‰ç‚¹ä¸åŠ¡æ­£ä¸šå•Šï¼Ÿâ€å¼Ÿå¼Ÿè·Ÿæˆ‘è¯´ï¼šâ€œè¿™æ˜¯ä½ å–œæ¬¢åšçš„äº‹æƒ…å˜›ï¼â€å®¶äººå’Œæœ‹å‹ç»™äº†æˆ‘å¾ˆå¤šçš„å¸®åŠ©å’Œæ”¯æŒï¼Œæˆ‘æ‰å¾—ä»¥åšå¥½å‡ºå‘çš„å‡†å¤‡ã€‚</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/14.jpg" alt title>                </div>                <div class="image-caption"></div>            </figure><p>7æœˆ21æ—¥-24æ—¥ï¼Œè¥¿è¡Œçš„ç«è½¦ç»è¿‡57ä¸ªå°æ—¶çš„é¢ ç°¸ï¼Œè½½ç€æˆ‘åˆ°äº†æ–°ç–†å–€ä»€ï¼Œæˆ‘å’Œæ—ºå“¥çº¦å¥½äº†ä»è¿™å‡ºå‘ã€‚å–€ä»€å¸‚æ˜¯ä¸€ä¸ªä¸å¤§çš„åŸå¸‚ï¼Œåˆ†ä¸ºæ—§åŸåŒºå’Œæ–°åŸåŒºï¼Œé™¤äº†ç»´å¾å°”æ—ï¼Œè¿˜æœ‰ä¸å°‘å®šå±…åœ¨è¿™çš„æ±‰æ—äººã€‚æ­£å¼å‡ºå‘å‰çš„ä¸€å¤©ï¼Œæˆ‘å’Œæ—ºå“¥å»é€›äº†æ—§åŸåŒºï¼Œå¸¸å¯ä»¥è§åˆ°åœ¨å°å··å­é‡Œã€åœ¨ç©ºåœ°ä¸Šè¸¢è¶³çƒçš„å°ç”·å­©ã€‚ç¬¬ä¸€å¤©çš„ç›®çš„åœ°æ˜¯èè½¦å¿ï¼Œè¡Œç¨‹çº¦190å…¬é‡Œï¼ŒåŠ ä¸Šä¸­åˆçš„é…·çƒ­ï¼Œä¸‹åˆçš„é€†é£ï¼Œåˆ°èè½¦å¿å®‰é¡¿ä¸‹æ¥å·²ç»æ˜¯æ™šä¸Šä¹ç‚¹ï¼Œä¸€è·¯ä¸Šå‡ è¿‘å´©æºƒï¼Œèº«ä½“å·²ç»è¢«æç©ºã€‚ç”¨é²è±«å¯¹äºè°¦çš„è®¿è°ˆå†…å®¹æ¥å½¢å®¹ç¬¬ä¸€å¤©çš„éª‘è¡Œæ°å¦‚å…¶åˆ†ã€‚</p><ul><li>é²è±«ï¼šæˆåä¹‹å‰ï¼Œä½ å’Œéƒ­å¾·çº²ç»å¸¸æ•´å¤©æ•´å¤©åœ°è¡¨æ¼”ç›¸å£°ï¼Œå¾ˆå°‘æœ‰ä¼‘æ¯æ—¶é—´ã€‚é‚£æ®µæ—¥å­å¿«ä¹å—ï¼Ÿ</li><li>äºè°¦ï¼šå¿«æ­»äº†ï¼</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/15.jpg" alt title>                </div>                <div class="image-caption"></div>            </figure><p>æ–°ç–†åœ°å¹¿äººç¨€ï¼Œå¤§ç‰‡çš„åœ°æ–¹æ˜¯æ²¡æœ‰äººçƒŸçš„è’æ¼ ï¼Œæœ‰äººçƒŸçš„æ‘è½å¸¸éš”ç€å‡ åç”šè‡³ä¸Šç™¾å…¬é‡Œè¿œï¼Œè‡³äºåŸé•‡åˆ™æ›´å°‘ã€‚æ–°è—çº¿å·®ä¸å¤šå·²ç»æ˜¯æˆ‘å›½è¾¹ç–†åŒºåŸŸï¼Œæœ‰ç€å¾ˆå¤šâ€œåœ°æ–¹ç‰¹è‰²â€ã€‚åŸé‡Œçš„é“¶è¡Œã€é‚®å±€ã€è¯åº—ï¼Œè¿›å‡ºéƒ½è¦åˆ·èº«ä»½è¯ç™»è®°ã€‚æ›¾åœ¨å¿åŸé‡Œçœ‹åˆ°ä¸€åœºæµ©å¤§çš„é˜µåŠ¿ï¼Œä¸€è¾†è£…ç”²è½¦å¼€è·¯ï¼Œåé¢è·Ÿç€ä¸¤æ’å…¬å®‰å·¡é€»è½¦ï¼Œå¾—æœ‰äºŒåå¤šè¾†ï¼Œæ•´æ•´é½é½ã€‚å‡ºè‹±å‰æ²™å¿åŸåŒºçš„è·¯ä¸Šï¼Œæœ‰æ®µè·¯æœ‰è®¸å¤šé˜²æš´çš„è­¦å¯Ÿï¼Œä¸ªä¸ªå…¨å‰¯æ­¦è£…ï¼Œå¤´æˆ´é»‘è‰²å¤´ç›”ï¼Œèº«ç€é»‘è‰²åˆ¶æœï¼Œå¤–é¢å†å¥—ä¸Šé»‘é©¬ç”²ï¼Œä¸Šé¢å†™ç€â€œè­¦å¯Ÿ policeâ€ã€‚è¿™äº›è­¦å¯Ÿå¤§å¤šæ˜¯ç»´æ—é’å£®å¹´ï¼Œæ‰‹æ‰§çš„æ­¦å™¨å˜åŒ–å¤šç«¯ï¼Œæœ‰ä¸€äººé«˜çš„é»‘è‰²é•¿æ£ï¼ŒåŠäººé«˜å‰ç«¯é…æœ‰åˆºåˆ€çš„æ£å­ï¼Œé˜²æš´å‰ï¼Œå†²é”‹æªâ€¦â€¦.çœŸæ˜¯åå…«èˆ¬å…µå™¨ï¼Œä»¤äººçœ¼èŠ±ç¼­ä¹±ã€‚ç¨³å®šæ˜¯å‘å±•çš„å‰æï¼Œè¿™ä¹Ÿæ˜¯æƒ…æœ‰å¯åŸçš„äº‹ã€‚æ–°ç–†çš„æ²»å®‰ååˆ†ä¸¥æ ¼ï¼Œè¿™é‡Œå†™ä¸€åˆ™è¶£äº‹ã€‚è¶åƒåˆé¥­çš„ç©ºæ¡£ï¼Œæˆ‘éª‘è½¦å»é‚®å±€ç›–é‚®æˆ³ï¼Œå›é¥­åº—çš„è·¯ä¸Šå·æ‡’é€†è¡Œäº†ä¸€æ®µè·¯ã€‚ä¸€ä¸ªè­¦å¯ŸæŒ¥æŒ¥æ‰‹ç¤ºæ„æˆ‘åœä¸‹æ¥ï¼Œæ¥ç€ä¾¿ä¸€é¡¿è®­æ–¥â€œä¸èµ°äººè¡Œé“ï¼Œé€†è¡Œï¼Œå•Šï¼èƒ½ä¸èƒ½æœ‰ç‚¹ç´ è´¨ï¼â€æˆ‘èµ¶å¿™è®¤é”™ï¼Œç­‰å€™å‘è½ï¼Œç­‰äº†ä¸€ä¼šï¼Œä»–æ²¡å†ç†æˆ‘ï¼Œæˆ‘æ‰ç°æºœæºœåœ°èµ°å¼€äº†ã€‚</p><p>ç¬¬ä¸‰å¤©çš„è¡Œç¨‹æ˜¯å¶åŸåˆ°é˜¿å…‹ç¾å…¶ç‰¹æ‘ã€‚å¶åŸæ˜¯219å›½é“çš„0å…¬é‡Œæ‰€åœ¨ï¼Œæ–°è—çº¿çœŸæ­£çš„èµ·ç‚¹ã€‚219å›½é“çš„é›¶å…¬é‡Œå¤„æœ‰ä¸ªå¤§æ‹±é—¨ï¼Œå·¦å³å„å†™ï¼šâ€œå¤©è·¯é›¶å…¬é‡Œâ€ï¼Œâ€œæ˜†ä»‘ç¬¬ä¸€åŸâ€ï¼Œæ¨ªæ‰¹å°±æ˜¯ä¸€ä¸ªå¤§å¤§çš„â€œ0â€ã€‚å¶åŸä¹‹åå°±å¾ˆå°‘æœ‰åŸé•‡äº†ï¼Œå¤§å¤šæ˜¯æ‘è½ï¼Œç‰©èµ„è¡¥ç»™å°±æ¯”è¾ƒå›°éš¾äº†ã€‚æˆ‘å’Œæ—ºå“¥çš„åè´§æ¶è½½å¾—æ»¡æ»¡çš„ï¼Œåƒæ˜¯ä¸ªå°å±±ã€‚éª‘è½¦å‡ºäº†å¶åŸï¼Œè‡ªç„¶ç¯å¢ƒæ˜¯è¿™æ ·å˜åŒ–çš„ï¼Œå¤§æ ‘å˜å°æ ‘ï¼Œå°æ ‘å˜ä½çŸ®çš„çŒæœ¨ï¼ŒçŒæœ¨å˜æˆé‡è‰ï¼Œæˆˆå£æ»©æ¸æ¸éœ²å‡ºäº†å®ƒçš„é¢ç›®ã€‚åœ¨æ–°è—çº¿ä¸Šï¼Œå¦‚æœä½ èƒ½çœ‹åˆ°é«˜é«˜çš„æ ‘ï¼Œé‚£è¿™ä¸ªåœ°æ–¹å°±æœ‰æ¯”è¾ƒä¸°å¯Œçš„æ°´ï¼Œæœ‰æ°´æºçš„åœ°æ–¹ä¸€èˆ¬å°±æœ‰äººçƒŸã€‚æ™šä¸Šï¼Œæˆ‘ä»¬åˆ°äº†é˜¿å…‹ç¾å…¶ç‰¹æ‘ï¼Œä¸€ä¸ªç»å¸¸åœç”µçš„å°æ‘å­ï¼Œæˆ‘å’Œæ—ºå“¥ä½åœ¨æ‘æ°‘å®¶é‡Œã€‚</p><p>é˜¿å…‹ç¾å…¶ç‰¹æ‘ï¼Œæ•…äº‹åœ¨è¿™é‡Œå‘ç”Ÿï¼Œè¿™æ˜¯ä¸ªæˆ‘é“­è®°ç€çš„æ‘å­ã€‚æ—©ä¸Šå‡ºå‘ï¼Œéª‘è½¦å‡ºå»æ²¡å¤šè¿œï¼Œæˆ‘å‘ç°æˆ‘çš„è½¦å­åè½®èŠ±é¼“æ–­äº†ã€‚æˆ‘ä»¬å†³å®šï¼šæ—ºå“¥ç»§ç»­å‰è¡Œï¼Œåˆ°ç‰©èµ„è¡¥ç»™æ›´æ–¹ä¾¿çš„åœ°æ–¹ç­‰æˆ‘ï¼›æˆ‘è¿”å›å»ä¿®ç†åè½®ã€‚æ–­èŠ±é¼“çš„ç¬¬ä¸€å¤©ï¼Œæˆ‘å¸ä¸‹è‡ªè¡Œè½¦çš„åè½®ï¼ŒèƒŒä¸Šå°åŒ…ï¼Œæ‘å¹²éƒ¨æ‰¾äº†è¾†è½¦æŠŠæˆ‘é€åˆ°äº†æŸ¯å…‹äºšä¹¡ï¼Œæˆ‘åœ¨ä¹¡é‡Œåå‡ºç§Ÿè½¦åˆ°äº†å¶åŸå¿ã€‚æˆ‘å·æ‡’æ²¡å»æ›´è¿œçš„å–€ä»€å¸‚ï¼Œåªæ˜¯åœ¨å¶åŸå¿æ‰¾äº†ä¸€ä¸ªä¸é è°±çš„ä¿®è½¦å¸ˆå‚…ç»™æˆ‘æ¢äº†ä¸ªèŠ±é¼“ï¼Œä¿®ç†å®Œå·²ç»å¿«å¤©é»‘äº†ï¼Œäºæ˜¯å¤œå®¿å¶åŸã€‚æ–­èŠ±é¼“çš„ç¬¬äºŒå¤©ï¼Œä¸€å¤§æ—©æˆ‘å°±åˆ°æ±½è½¦ç«™åè½¦ï¼Œä¸Šåˆåç‚¹è¿”å›é˜¿å…‹ç¾å…¶ç‰¹æ‘ï¼ŒæŠŠåè½®æ¢å¥½å†æ¬¡å‡ºå‘ï¼Œæ²¡ä¸Šæ¬¡éª‘å¾—è¿œï¼Œè½¦å­æ•…éšœï¼Œå‘ç°åè½®æ²¡ä¿®å¥½ã€‚æˆ‘è¦å†è¿”å›å¶åŸï¼Œè¿™æ¬¡æ²¡æœ‰è½¦é€æˆ‘äº†ï¼Œæˆ‘è¾¹èµ°è¾¹æ­è½¦ï¼Œä¸€ç™¾å…¬é‡Œçš„è·¯ï¼Œèµ°äº†åå‡ å…¬é‡Œï¼Œæ­äº†å››äº”è¾†è½¦åˆ°äº†å¶åŸã€‚åœ¨å¶åŸä¹°ç«è½¦ç¥¨ï¼Œåç«è½¦åˆ°å–€ä»€å¸‚ã€‚æ–­èŠ±é¼“çš„ç¬¬ä¸‰å¤©ï¼Œä¸€å¤§æ—©æˆ‘åˆ°äº†å–€ä»€ï¼Œå‰å¾€æ·å®‰ç‰¹åº—ï¼Œä¹°äº†ä¸ªåè½®ã€‚ä¹°ç«è½¦ç¥¨è¿”å›å¶åŸï¼Œè¾¹èµ°è¾¹æ­è½¦ï¼Œæ™šä¸Šåç‚¹è¿”å›åˆ°é˜¿å…‹ç¾å…¶ç‰¹æ‘ã€‚</p><p>æ–­èŠ±é¼“çš„ç¬¬ä¸‰å¤©ï¼Œæˆ‘å‡ ä¹æƒ³æ”¾å¼ƒäº†ã€‚é«˜å©·å©·åŒå­¦æ°å¥½å‘å¾®ä¿¡æ…°é—®æˆ‘ï¼Œæ˜¯æˆ‘è‰°éš¾æ—¥å­é‡Œçš„ä¸€ç¼•é˜³å…‰ï¼è¿”å›é˜¿å…‹ç¾å…¶ç‰¹æ‘æ—¶ï¼Œæˆ‘æ­äº†ä¸€è¾†å¤§å¡è½¦ï¼Œå¸æœºå¸ˆå‚…æ˜¯å±±è¥¿çš„ï¼Œä¸€è·¯ä¸Šé™ªå¸ˆå‚…èŠå¤©ã€‚å¸ˆå‚…è¯´ï¼Œæµ·æ‹”é«˜ï¼Œæ°§æ°”å°‘ï¼Œè·¯éš¾èµ°ï¼Œåœ¨æ–°è—çº¿ä¸Šå¼€å¤§å¡è½¦å°±æ˜¯åœ¨ç©å‘½ã€‚æ–°è—çº¿ä¸Šå¸¸å¯ä»¥çœ‹åˆ°ç¿»å€’åœ¨è·¯è¾¹çš„å¤§å¡è½¦ã€‚æœ‰çš„å¸æœºå¸¦ç€è€å©†å‡ºæ¥å¼€å¤§å¡è½¦æ‹‰è´§ï¼Œå‡ºäº†äº‹ï¼Œå°±å‰©ä¸ªå­©å­è·Ÿç€çˆ·çˆ·å¥¶å¥¶ã€‚æ–°è—çº¿ä¸Šæœ‰å„æ ·çš„äººï¼Œè¸©å•è½¦çš„ï¼Œéª‘æ‘©æ‰˜çš„ï¼Œè‡ªé©¾æ¸¸çš„ï¼Œæ¥è°‹ç”Ÿçš„ï¼Œå¼€å¡è½¦ï¼Œæ‘†æ°´æœæ‘Šï¼Œå¼€æ—…åº—ã€‚</p><p>æˆ‘æ­è½¦èµ°äº†ä¸€ç™¾å¤šå…¬é‡Œï¼Œåœ¨ä¸‰åé‡Œè¥æˆ¿è¿½ä¸Šäº†æ—ºå“¥ã€‚åœ¨çº¢æŸ³æ»©æˆ‘ä»¬é‡åˆ°äº†ä¸¤ä¸ªæ–°ä¼™ä¼´ï¼Œå´é”¡è´¤å’Œé‚“ç¿±ï¼Œåˆ†åˆ«å¤§ä¸€å’Œå¤§äºŒã€‚ä»–ä»¬ä¿©éƒ½èµ°è¿‡å·è—çº¿ï¼Œä½“åŠ›å¥½ï¼Œå¹²ç»ƒï¼ŒçœŸä¸æ„§è‹±é›„å‡ºå°‘å¹´ï¼åŠ å…¥æ–°çš„é˜Ÿå‹åï¼Œæˆ‘è¿˜æ˜¯é˜Ÿé‡Œä½“åŠ›æœ€å·®çš„é‚£ä¸ªäººã€‚çº¢æŸ³æ»©åä¸‰ç™¾å…¬é‡Œè¢«ç§°ä¸ºæ— äººåŒºï¼ŒäººçƒŸæå°‘ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§è¡Œç¨‹èµ¶åˆ°ä½å®¿åœ°ç‚¹ï¼Œä¸ç„¶åªèƒ½éœ²å®¿è’é‡ã€‚å‡ºå‘å‰çš„é‚£ä¸ªæ™šä¸Šï¼Œæœ‰ä¸ªéª‘å‹æ»”æ»”ä¸ç»åœ°è°ˆè®ºè¿™æ®µè·¯ï¼šâ€œå»å¹´æœ‰ä¸¤ä¸ªéª‘å‹ï¼Œæ²¡åˆ°è¾¾ä½å®¿ç‚¹ï¼Œéœ²è¥åœ¨ä¸€ä¸ªæ²¡æœ‰é—¨çš„å•æ‰€é‡Œï¼Œè¢«ç‹¼å•ƒå¾—åªå‰©ä¸€æ¡è…¿äº†ã€‚â€å¬äº†è¿™ä¸çŸ¥çœŸå‡çš„è¯ï¼Œæˆ‘å¦‚ä¸´å¤§æ•Œï¼Œè¿å¤œæŠŠé©¼åŒ…æ”¶æ‹¾å¥½ï¼Œç»™è½¦æ‰“æ»¡æ°”ã€‚ç¬¬äºŒå¤©æ—©æ—©åœ°å°±èµ·åºŠäº†ï¼Œæ—©é¥­ä¸°ç››è€Œç¾å‘³ï¼Œé¦™ç”œçš„ç‰ç±³ç³Šï¼Œæ¦¨èœã€æ‹é»„ç“œã€èŠ±ç”Ÿç±³ä¸‰æ ·å°èœï¼Œçƒ­ä¹æ¾è½¯çš„é¦’å¤´ï¼Œæ¯äººä¸€ä¸ªè’¸é¸¡è›‹ï¼Œåƒæ˜¯ä¸Šåˆ‘åœºå‰çš„ç››å®´ã€‚<br> <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/16.jpg" alt title>                </div>                <div class="image-caption"></div>            </figure><br>ä¸‰å¤©åï¼Œæˆ‘ä»¬ç»ˆäºç©¿è¿‡äº†æ— äººåŒºï¼Œåé¢çš„è·¯å°±å¥½èµ°äº†ã€‚æ— é™é£å…‰åœ¨é™©å³°ï¼Œæˆ‘ä»¬å‡ ä¸ªäººåœ¨æ— äººåŒºè¿œè¿œåœ°çœ‹åˆ°äº†è—ç¾šç¾Šæˆ–æ˜¯é»„ç¾Šï¼Œçœ‹ä¸æ¸…å¥¹çš„æ ·å­ä¸æ¯«ä¸å½±å“æˆ‘è§åˆ°å¥¹æ—¶çš„æ¿€åŠ¨å’ŒæƒŠå–œã€‚æ–°è—çº¿è¾½é˜”ä¿Šç¾ï¼Œå¤§å¤§å°å°çš„æ¹–æ³Šåƒæ˜¯ç¾ç‰ç‚¹ç¼€å…¶é—´ï¼Œè¿œè¿œè¿‘è¿‘çš„é›ªå±±åœ¨é˜³å…‰ç…§è€€ä¸‹åº¦è¿‡å²æœˆï¼Œèµ·èµ·ä¼ä¼çš„è·¯å»¶ä¼¸å‘è¿œæ–¹æ²¡æœ‰å°½å¤´ã€‚æ–°è—çº¿ä¸Šæœ‰æ—¶å¯ä»¥çœ‹åˆ°é•¿é•¿çš„å†›è½¦è½¦é˜Ÿé©¶è¿‡ï¼Œåƒæ˜¯å£«å…µçªå‡»é‡Œçš„æ ·å­ï¼Œä¸ç¦æ„Ÿå¹ä¸€å¥ï¼šâ€œå¥½ç”·å„¿å°±æ˜¯è¦å½“å…µã€‚â€</p><p>åœ¨è¥¿è—è¨å˜å¿ï¼Œæˆ‘å’Œä»–ä»¬ä»¨åˆ†é“æ‰¬é•³ï¼Œä»–ä»¬ä»¨å‰å¾€ç å³°ï¼Œæˆ‘è½¬å‘å‰éš†å£å²¸å»å°¼æ³Šå°”ã€‚å‡ºè¨å˜å¿åï¼Œæœ‰å…­ä¸ƒåå…¬é‡Œçš„è·¯è¿˜åœ¨ä¿®ï¼Œå¤§éƒ¨åˆ†æ˜¯çƒ‚æ³¥è·¯ã€‚é‡åˆ°å¤§æ°´å‘ï¼Œæˆ‘å°±è„±ä¸‹é‹æŒ‚åœ¨è½¦æŠŠä¸Šï¼Œæ¨ç€è½¦è¶Ÿè¿‡å»ã€‚å®åœ¨éª‘ä¸åŠ¨äº†ï¼Œæˆ‘æ”¾å¼ƒäº†ä¸€å®šè¦å…¨ç¨‹éª‘å®Œçš„å¿µå¤´ï¼Œå¿ƒå®‰ç†å¾—åœ°æ¨ç€è½¦å‰è¿›ã€‚å°±è¿™æ ·éª‘äº†ä¸€æ•´å¤©åä¸ªå°æ—¶ï¼Œåªå‰è¿›äº†äº”åå…¬é‡Œã€‚ä¸‹åˆèµ·äº†å¾ˆå¤§çš„é€†é£ï¼Œé‡åˆ°ä¸€ä¸ªå¯¹é¢æ¥çš„éª‘å‹ï¼Œé¢‡æœ‰æƒºæƒºç›¸æƒœä¹‹æ„Ÿã€‚ä»–è¯´å‰é¢æœ‰æ¡æ²³æ‹¦ä½äº†è·¯ï¼Œæ‰“ç®—åŸè·¯è¿”å›ã€‚å¤©è‰²æ¸æ™šï¼Œæˆ‘å†å¾€å‰åªèƒ½éœ²å®¿è’é‡ï¼Œäºæ˜¯å€Ÿå®¿åœ¨ä¿®è·¯çš„é¡¹ç›®éƒ¨ã€‚å…­ä¸ƒä¸ªè¥¿å®‰çš„çˆ·ä»¬æ”¶ç•™æˆ‘ä½äº†ä¸€å®¿ï¼Œè¿˜ç”¨é«˜å‹é”…ç…®äº†é¢ã€‚æœ‰ä½åšé¥­çš„é˜¿å§¨èŠå¤©æ€»æ˜¯ç¬‘ä¸åœï¼Œè®©è¿™åº§åœ¨å¤§é£ä¸­æ‘‡æ‘†ä¸åœçš„å¸ç¯·é‡Œå……æ»¡äº†æ¸©æš–ã€‚</p><p>ä»å‰éš†é•‡åˆ°å‰éš†å£å²¸çš„ä¸€ç™¾å…¬é‡Œè·¯ï¼Œæµ·æ‹”é™¡é™ï¼Œå…¨æ˜¯ä¸‹å¡ï¼Œè€Œä¸”æ™¯è‰²æ¸ç¾ï¼Œä»¿ä½›ç½®èº«äºç”»ä¸­ï¼Œç©ºæ°”ä¸­æœ‰æ·¡æ·¡çš„æœ¨é¦™å‘³ã€‚ç‹¬è‡ªæ¬£èµè¿™ç¾æ™¯ï¼Œä¸ç¦æƒ³å¿µèµ·æˆ‘çš„é˜Ÿå‹æ¥ã€‚æ¨ç€è‡ªè¡Œè½¦ï¼Œè¿‡äº†æµ·å…³ï¼Œå°±è¸å‡ºäº†å›½é—¨ï¼Œéª‘è¡Œåœ¨å°¼æ³Šå°”ï¼å†ç¿»è¿‡ä¸¤åº§å±±ï¼Œæˆ‘å°±è¦åˆ°åŠ å¾·æ»¡éƒ½äº†ã€‚å°¼æ³Šå°”å¢ƒå†…çš„è·¯æœ‰ä¸€å¤§åŠæ˜¯çƒ‚è·¯ï¼Œä½†æ™¯è‰²å¾ˆä¸é”™ï¼Œå¸¸æœ‰æ³‰æ°´ä»å±±ä¸Šæµåˆ°è·¯ä¸Šæ¥ï¼Œåæ¥æˆ‘å¹²è„†è¸©æ°´ç©ï¼Œè®©æ³‰æ°´å†²å»æˆ‘é‹ä¸Šçš„æ³¥æ²™ã€‚è¿™æ®µè·¯å¤ªçƒ‚äº†ï¼Œéå¸¸ä¸æ¨èéª‘è½¦å»å°¼æ³Šå°”ã€‚åœ¨å°¼æ³Šå°”å¢ƒå†…éª‘è¡Œäº†ä¸¤å¤©ï¼Œ8æœˆ22æ—¥æˆ‘ç»ˆäºæŠµè¾¾äº†åŠ å¾·æ»¡éƒ½ï¼æ´—ä¸ªæ¾¡ï¼Œæ¢èº«å¹²å‡€è¡£æœï¼Œå–æ‰è‡ªè¡Œè½¦ï¼Œå»æœå·´å¹¿åœºå–é…¸å¥¶ï¼Œå»çœ‹é»„æ˜é‡Œçš„æ¢¦èŠ±å›­ï¼Œçœ‹çŒ´å­åœ¨åŸå¸‚é‡Œæ¸¸è¡ã€‚</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/17.jpg" alt="å°¼æ³Šå°”çš„å°å­©å­" title>                </div>                <div class="image-caption">å°¼æ³Šå°”çš„å°å­©å­</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/18.jpg" alt="ä¿¯ç°åŠ å¾·æ»¡éƒ½" title>                </div>                <div class="image-caption">ä¿¯ç°åŠ å¾·æ»¡éƒ½</div>            </figure><p>ç†æ€§åœ°æ¥è¯´ï¼Œæ—ºå“¥çš„é˜ŸåŒ»çŸ¥è¯†ã€ä¿®è½¦æŠ€æœ¯å’Œä½“åŠ›éƒ½èƒœè¿‡æˆ‘ï¼ˆé™¤äº†å¸…ï¼Œæˆ‘çœŸæ˜¯ä¸€æ— æ˜¯å¤„å•Šï¼ï¼‰ï¼Œå¦‚æœæ²¡æœ‰æ—ºå“¥çš„å¸®åŠ©ï¼Œæˆ‘å¾ˆéš¾èµ°å®Œè¿™æ¡çº¿ã€‚æ–°è—çº¿è¿™ä¸€è·¯ä¸Šï¼Œæ²¡æ€ä¹ˆå†™æ—¥è®°ï¼Œå€’æ˜¯è·Ÿæ—ºå“¥æ–—äº†å¾ˆå¤šç›˜åœ°ä¸»ï¼Œç»™ä¸€äº›æœ‹å‹å†™äº†å¥½å¤šæ˜ä¿¡ç‰‡ï¼Œç›–åˆ°äº†å‡ ä¸ªé‚®æˆ³ã€‚</p><p>éª‘è½¦æœ‰ä»€ä¹ˆæ„ä¹‰å‘¢ï¼Ÿå½“è°ˆåˆ°å°¼æ³Šå°”ï¼Œæˆ‘å¯¹è‡ªå·±è¯´ï¼šâ€œå˜¿ï¼Œè¿™ä¸ªåœ°æ–¹æˆ‘éª‘è½¦å»è¿‡å“¦ï¼â€æ›¾ç»åˆ°è¾¾å°±æ˜¯æˆ‘çš„æ„ä¹‰ã€‚</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;18å¹´çš„å¤å¤©ï¼Œçƒ­çƒˆçš„é˜³å…‰é€è¿‡æµ“å¯†çš„å¶å­ç…§åœ¨çª—å°çš„ç›†æ ½ä¸Šï¼Œæœ‰ç€ä¸ä¸çš„é£ã€‚å°±åœ¨è¿™ç¾ä¸½çš„å­£èŠ‚é‡Œï¼Œæˆ‘ä»¬æ¯•ä¸šäº†ã€‚æ¯•ä¸šåçš„æš‘å‡ï¼Œæˆ‘ç»ˆäºåšåˆ°äº†æˆ‘æƒ³åšçš„ä¸€ä»¶äº‹ï¼Œéª‘è½¦å»é‚£å°å°çš„å°¼æ³Šå°”ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="ç”Ÿæ´»è®°å½•" scheme="http://yoursite.com/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="æ–°è—çº¿" scheme="http://yoursite.com/tags/%E6%96%B0%E8%97%8F%E7%BA%BF/"/>
    
      <category term="éª‘è½¦" scheme="http://yoursite.com/tags/%E9%AA%91%E8%BD%A6/"/>
    
  </entry>
  
  <entry>
    <title>sublimeæ’ä»¶</title>
    <link href="http://yoursite.com/2019/03/11/sublime%E6%8F%92%E4%BB%B6/"/>
    <id>http://yoursite.com/2019/03/11/sublimeæ’ä»¶/</id>
    <published>2019-03-11T11:41:12.000Z</published>
    <updated>2019-03-11T13:04:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>è®°å½•sublimeçš„ä¸€äº›æ’ä»¶ã€‚</p><a id="more"></a> <h2 id="OmniMarkupPreviewer"><a href="#OmniMarkupPreviewer" class="headerlink" title="OmniMarkupPreviewer"></a>OmniMarkupPreviewer</h2><p><strong>ä½œç”¨ï¼š</strong>æ’ä»¶OmniMarkupPrevieweræ”¯æŒå°†markdownè¯­è¨€æ¸²æŸ“ä¸ºhtmlå¹¶ä¸”åœ¨æµè§ˆå™¨ä¸Šå®æ—¶é¢„è§ˆï¼Œä¹Ÿå°±æ˜¯å°†markdownå†…å®¹å®æ—¶æ˜¾ç¤ºä¸ºç½‘é¡µï¼Œæ•ˆæœä¹‹å¥½ä»¤äººæƒŠå¹ã€‚</p><h3 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h3><p>å¯ä»¥ä½¿ç”¨<code>Package Control</code>çš„<code>Insatll Package</code>æ¥å®‰è£…ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ä»<a href="https://github.com/timonwong/OmniMarkupPreviewer" target="_blank" rel="noopener">OmniMarkupPreviewerçš„githubä¸»é¡µ</a>ä¸‹è½½å‹ç¼©åŒ…ï¼Œè§£å‹åˆ°ç›®å½•<code>\Sublime Text 3\Packages\</code>ä¸‹ã€‚</p><ol><li>å¿«æ·é”®<code>Ctrl + shift + p</code>æ‰“å¼€<code>Package Control</code></li><li>è¾“å…¥<code>install</code>é€‰æ‹©<code>Package Control: Install Package</code></li><li>ä»åˆ—è¡¨ä¸­é€‰æ‹©<code>OmniMarkupPreviewer</code>å®‰è£…ã€‚</li></ol><h3 id="ä½¿ç”¨æ–¹æ³•ï¼š"><a href="#ä½¿ç”¨æ–¹æ³•ï¼š" class="headerlink" title="ä½¿ç”¨æ–¹æ³•ï¼š"></a>ä½¿ç”¨æ–¹æ³•ï¼š</h3><p>å¯¹äºwindowå’ŒLinuxï¼š</p><ul><li><code>Ctrl+Alt+O</code> åœ¨æµè§ˆå™¨ä¸­é¢„è§ˆ</li><li><code>Ctrl+Alt+X</code> è¾“å‡ºä¸ºhtmlæ–‡ä»¶</li><li><code>Ctrl+Alt+C</code> å¤åˆ¶ä¸ºHTMLæ–‡ä»¶</li></ul><h3 id="æ’ä»¶é…ç½®"><a href="#æ’ä»¶é…ç½®" class="headerlink" title="æ’ä»¶é…ç½®"></a>æ’ä»¶é…ç½®</h3><p>ä¿®æ”¹æ’ä»¶çš„é…ç½®ï¼Œç‚¹å‡»èœå•æ çš„<code>Preferences - Packages Settings - OmniMarkdownPreviwer - Setting-User</code>ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;server_host&quot;: &quot;127.0.0.1&quot;,  //é»˜è®¤ä¸ºlocalhost,ä¿®æ”¹ä¸ºä½ ç”µè„‘çš„ipï¼Œå¯ä»¥å®ç°è¿œç¨‹è®¿é—®ã€‚ä¹Ÿå°±æ˜¯ä»å…¶ä»–ç”µè„‘é¢„è§ˆç½‘é¡µæ•ˆæœ</span><br><span class="line">    &quot;server_port&quot;: 51004,</span><br><span class="line">    &quot;refresh_on_modified&quot;: true,</span><br><span class="line">    &quot;refresh_on_modified_delay&quot;: 500,</span><br><span class="line">    &quot;refresh_on_saved&quot;: true,</span><br><span class="line">    &quot;browser_command&quot;: [],</span><br><span class="line">    &quot;html_template_name&quot;: &quot;github&quot;,</span><br><span class="line">    &quot;ajax_polling_interval&quot;: 500,</span><br><span class="line">    &quot;ignored_renderers&quot;: [&quot;LiterateHaskellRenderer&quot;],</span><br><span class="line">    &quot;mathjax_enabled&quot;: true,  //æ¸²æŸ“æ•°å­¦å…¬å¼è¦ç”¨åˆ°MathJaxåº“ï¼Œå°†å€¼è®¾ä¸ºtrue,mathjaxä¼šåœ¨åç«¯è‡ªåŠ¨ä¸‹è½½ã€‚</span><br><span class="line">    &quot;export_options&quot; : &#123;</span><br><span class="line">        &quot;template_name&quot;: &quot;github-export&quot;,</span><br><span class="line">        &quot;target_folder&quot;: &quot;.&quot;,</span><br><span class="line">        &quot;timestamp_format&quot; : &quot;_%y%m%d%H%M%S&quot;,</span><br><span class="line">        &quot;copy_to_clipboard&quot;: false,</span><br><span class="line">        &quot;open_after_exporting&quot;: false</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;renderer_options-MarkdownRenderer&quot;: &#123;</span><br><span class="line">        &quot;extensions&quot;: [&quot;tables&quot;, &quot;fenced_code&quot;, &quot;codehilite&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="é‡åˆ°çš„é”™è¯¯"><a href="#é‡åˆ°çš„é”™è¯¯" class="headerlink" title="é‡åˆ°çš„é”™è¯¯"></a>é‡åˆ°çš„é”™è¯¯</h3><p>é¢„è§ˆæ–‡æœ¬æ—¶æŠ¥é”™ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Error: 404 Not Found</span><br><span class="line">Sorry, the requested URL &apos;http://127.0.0.1:51004/view/593&apos; caused an error:</span><br><span class="line"></span><br><span class="line">&apos;buffer_id(593) is not valid (closed or unsupported file format)&apos;</span><br><span class="line"></span><br><span class="line">**NOTE:** If you run multiple instances of Sublime Text, you may want to adjust</span><br><span class="line">the `server_port` option in order to get this plugin work again.</span><br></pre></td></tr></table></figure><p>è§£å†³åŠæ³•æ˜¯ä¿®æ”¹é…ç½®æ–‡ä»¶<code>Sublime Text &gt; Preferences &gt; Package Settings &gt; OmniMarkupPreviewer &gt; Settings - User</code>ç²˜è´´ä¸‹é¢çš„ä»£ç ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;renderer_options-MarkdownRenderer&quot;: &#123;</span><br><span class="line">        &quot;extensions&quot;: [&quot;tables&quot;, &quot;fenced_code&quot;, &quot;codehilite&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h3><ul><li><a href="https://github.com/timonwong/OmniMarkupPreviewer" target="_blank" rel="noopener">OmniMarkupPreviewerçš„githubä¸»é¡µ</a></li><li><a href="https://blog.csdn.net/qq_30490125/article/details/53230408" target="_blank" rel="noopener">è¿‘ä¹å®Œç¾çš„Markdownå†™ä½œä½“éªŒ - SublimeText3 + OmniMarkupPreviewer</a></li></ul><h2 id="OmniMarkupPreviewer-MathJax"><a href="#OmniMarkupPreviewer-MathJax" class="headerlink" title="OmniMarkupPreviewer + MathJax"></a>OmniMarkupPreviewer + MathJax</h2><p>OmniMarkupPreviewerxæ¸²æŸ“markdownå†…å®¹ä¸ºç½‘é¡µï¼ŒMathJaxå¯¹LATEXç¼–è¾‘çš„æ•°å­¦å…¬å¼è¿›è¡Œæ¸²æŸ“ã€‚</p><h3 id="ä¸‹è½½mathjax"><a href="#ä¸‹è½½mathjax" class="headerlink" title="ä¸‹è½½mathjax"></a>ä¸‹è½½mathjax</h3><ol><li>ä¸‹è½½<a href="https://link.jianshu.com/?t=https://github.com/downloads/timonwong/OmniMarkupPreviewer/mathjax.zip" target="_blank" rel="noopener">mathjax</a>ï¼Œè§£å‹åˆ°ç›®å½•<code>Sublime Text 3\Packages\OmniMarkupPreviewer\public</code>ä¸‹ã€‚</li><li>åœ¨ç›®å½•<code>Sublime Text3\Packages\OmniMarkupPreviewer\</code>åˆ›å»ºç©ºæ–‡ä»¶<code>MATHJAX.DOWNLOADED</code>ã€‚è¿™æ ·å°±å®‰è£…å¥½äº†ã€‚</li></ol><h3 id="éªŒè¯"><a href="#éªŒè¯" class="headerlink" title="éªŒè¯"></a>éªŒè¯</h3><p>æ–°å»ºmarkdownæ–‡ä»¶è¾“å…¥å†…å®¹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">This expression </span><br><span class="line">$\sqrt&#123;3x-1&#125;+(1+x)^2$ is an example of a $\LaTeX$ inline equation.he Lorenz Equations:</span><br><span class="line">$$\begin&#123;aligned&#125;\dot&#123;x&#125; &amp; = \sigma(y-x) \\\dot&#123;y&#125; &amp; = \rho x - y - xz \\\dot&#123;z&#125; &amp; = -\beta z + xy\end&#123;aligned&#125;$$</span><br></pre></td></tr></table></figure><p>åœ¨sublimeä¸­ç”¨<code>Ctrl+Alt+O</code>é¢„è§ˆï¼Œæ˜¾ç¤ºæ•ˆæœå¦‚ä¸‹ï¼š</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/13.png" alt title>                </div>                <div class="image-caption"></div>            </figure><h3 id="å‚è€ƒé“¾æ¥-1"><a href="#å‚è€ƒé“¾æ¥-1" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h3><ul><li><a href="https://www.jianshu.com/p/23b02c1708ae" target="_blank" rel="noopener">ä½¿ç”¨Markdownçš„æ—¶å€™éœ€è¦æ’å…¥LaTeXå…¬å¼æ–¹æ³•</a></li></ul><p>å…³äºLATEX:</p><ul><li><a href="https://liam.page/2014/09/08/latex-introduction/" target="_blank" rel="noopener">ä¸€ä»½å…¶å®å¾ˆçŸ­çš„ LaTeX å…¥é—¨æ–‡æ¡£</a></li><li><a href="https://www.kancloud.cn/thinkphp/latex/41806" target="_blank" rel="noopener">ä¸€ä»½å…¶å®å¾ˆçŸ­çš„ LaTeX å…¥é—¨æ–‡æ¡£</a></li><li><a href="http://mohu.org/info/symbols/symbols.htm" target="_blank" rel="noopener">å¸¸ç”¨æ•°å­¦ç¬¦å·çš„ LaTeX è¡¨ç¤ºæ–¹æ³•</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;è®°å½•sublimeçš„ä¸€äº›æ’ä»¶ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="æŠ€æœ¯èµ„æ–™" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E8%B5%84%E6%96%99/"/>
    
    
      <category term="sublime" scheme="http://yoursite.com/tags/sublime/"/>
    
  </entry>
  
  <entry>
    <title>ç†µã€äº¤å‰ç†µä¸KLæ•£åº¦</title>
    <link href="http://yoursite.com/2019/03/11/%E7%86%B5%E3%80%81%E4%BA%A4%E5%8F%89%E7%86%B5%E4%B8%8EKL%E6%95%A3%E5%BA%A6/"/>
    <id>http://yoursite.com/2019/03/11/ç†µã€äº¤å‰ç†µä¸KLæ•£åº¦/</id>
    <published>2019-03-11T06:31:33.000Z</published>
    <updated>2019-07-22T00:57:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>ä»‹ç»äº¤å‰ç†µå’ŒKLæ•£åº¦ã€‚</p><a id="more"></a> <h2 id="ä»ä¿¡æ¯é‡åˆ°ä¿¡æºç†µ"><a href="#ä»ä¿¡æ¯é‡åˆ°ä¿¡æºç†µ" class="headerlink" title="ä»ä¿¡æ¯é‡åˆ°ä¿¡æºç†µ"></a>ä»ä¿¡æ¯é‡åˆ°ä¿¡æºç†µ</h2><ol><li>ä¿¡æ¯é‡æ˜¯é€šä¿¡ä¸“ä¸šçš„åè¯ã€‚ä¸€ä¸ªå˜é‡çš„ä¸»è¦ç‰¹å¾å°±æ˜¯ä¸ç¡®å®šæ€§ï¼Œä¹Ÿå°±æ˜¯å‘ç”Ÿçš„æ¦‚ç‡ã€‚ä¿¡æ¯é‡ç”¨æ¥è¡¡é‡ä¸ç¡®å®šæ€§çš„å¤§å°ã€‚ä¸€ä¸ªäº‹æƒ…å‘ç”Ÿçš„æ¦‚ç‡è¶Šå°ï¼Œä½¿äººè¶Šæ„Ÿåˆ°æ„å¤–ï¼Œåˆ™è¿™ä»¶äº‹çš„ä¿¡æ¯é‡è¶Šå¤§ï¼›åä¹‹ï¼Œæ¦‚ç‡è¶Šå¤§ï¼Œè¶Šä¸æ„å¤–ï¼Œä¿¡æ¯é‡è¶Šå°ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œæœ‰ä¸€æ¶æ³¢éŸ³747é£æœºå¤±äº‹ï¼Œå‘ç”Ÿçš„æ¦‚ç‡å¾ˆå°ï¼Œè®©äººå¾ˆæ„å¤–ï¼Œå¸¦ç»™äººçš„ä¿¡æ¯é‡å¾ˆå¤§ã€‚<br> ä¿¡æ¯é‡å‡½æ•°åº”æ»¡è¶³ä¸¤ä¸ªç‰¹æ€§ï¼š1ï¼‰éšç€æ¦‚ç‡çš„å¢å¤§è€Œå‡å°ï¼Œå³æ˜¯æ¦‚ç‡çš„å‡å‡½æ•°ï¼›2ï¼‰ä¿¡æ¯é‡å‡½æ•°æ»¡è¶³å¯åŠ æ€§ï¼Œå³ä¸¤ä¸ªç»Ÿè®¡ç‹¬ç«‹çš„æ¶ˆæ¯æä¾›çš„ä¿¡æ¯é‡ç­‰äºä»–ä»¬åˆ†åˆ«æä¾›çš„ä¿¡æ¯é‡ä¹‹å’Œã€‚åŒæ—¶æ»¡è¶³é€’å‡æ€§å’Œå¯åŠ æ€§çš„å‡½æ•°æ˜¯å¯¹æ•°å‡½æ•°ï¼Œå³<br> $$ I[p(x_i)] = log \frac{1}{p(x_i)} = -log p(x_i)$$</li><li>ä¿¡æºç†µå®šä¹‰ä¸ºä¿¡æºè¾“å‡ºçš„å¹³å‡ä¿¡æ¯é‡ï¼Œå³ä¿¡æ¯é‡çš„æ•°å­¦æœŸæœ›ã€‚$$ H(X) = E(I[p(x_i)]) = E(-log p(x_i)) = - \sum_{i=1}^{n}p(x_i)log p(x_i)$$ä¿¡æºå®é™…ä¸Šæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œä¿¡æºç†µå¯ä»¥è§£é‡Šä¸ºè¡¨ç¤ºè¿™ä¸ªæ¦‚ç‡åˆ†å¸ƒè‡³å°‘éœ€è¦çš„ä¿¡æ¯é‡ã€‚</li></ol><h2 id="äº¤å‰ç†µ"><a href="#äº¤å‰ç†µ" class="headerlink" title="äº¤å‰ç†µ"></a>äº¤å‰ç†µ</h2><p>å¯¹äºä¸€ä¸ªéšæœºäº‹ä»¶ï¼ŒçœŸå®æ¦‚ç‡åˆ†å¸ƒæ˜¯$p(x_i)$ æ˜¯æœªçŸ¥çš„ï¼Œä»æ•°æ®ä¸­å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒä¸º$q(x_i)$ã€‚æˆ‘ä»¬ç”¨æ¦‚ç‡åˆ†å¸ƒ$q(x_i)$æ¥è¿‘ä¼¼å’Œé€¼è¿‘çœŸå®çš„æ¦‚ç‡åˆ†å¸ƒ$p(x_i)$ ã€‚äº¤å‰ç†µå®šä¹‰ä¸ºï¼š$$H(p,q) = \sum_{i=1}^{n}p(x_i) I[q(x_i)] =- \sum_{i=1}^{n}p(x_i)log(x_i) $$äº¤å‰ç†µ$H(p,q)$æ˜¯ç”¨æ¦‚ç‡åˆ†å¸ƒ$q(x_i)$æ¥è¿‘ä¼¼çœŸå®æ¦‚ç‡åˆ†å¸ƒ$p(x_i)$éœ€è¦çš„ä¿¡æ¯é‡ã€‚ä¸Šé¢æˆ‘ä»¬è¯´è¿‡ï¼Œä¿¡æºç†µ$H(X)$æ˜¯è¡¨ç¤ºçœŸå®æ¦‚ç‡åˆ†å¸ƒ$p(x_i)$éœ€è¦çš„æœ€å°ä¿¡æ¯é‡ã€‚å¯ä»¥å¾—åˆ°ç»“è®ºï¼š$$H(p,q) \ge H(p)$$ç”±å‰å¸ƒæ–¯ä¸ç­‰å¼å¯ä»¥è¯æ˜ï¼Œå½“ä¸”ä»…å½“åˆ†å¸ƒ$p(x_i)$ä¸$q(x_i)$å®Œå…¨ä¸€è‡´æ—¶ï¼Œç­‰å·æ‰æˆç«‹ã€‚è¿™ä¸ªä¸ç­‰å¼çš„æ„ä¹‰æ˜¯ï¼šç”¨æ¦‚ç‡åˆ†å¸ƒ$q(x_i)$æ¥è¿‘ä¼¼çœŸå®æ¦‚ç‡åˆ†å¸ƒ$p(x_i)$éœ€è¦çš„ä¿¡æ¯é‡ä¸€å®šå¤§äºç­‰äºæ¦‚ç‡åˆ†å¸ƒ$p(x_i)$æœ¬èº«çš„ä¿¡æºç†µã€‚äº¤å‰ç†µæ¯”ä¿¡æºç†µå¤šå‡ºæ¥çš„è¿™éƒ¨åˆ†ï¼Œå°±æ˜¯å†—ä½™ä¿¡æ¯é‡ï¼Œæˆ‘ä»¬ç§°ä¸ºKLæ•£åº¦ï¼ˆç›¸å¯¹ç†µï¼‰ã€‚<br>$$KL(p||q)= H(p,q) - H(p) \ge 0$$å®¹æ˜“çœ‹å‡ºäº¤å‰ç†µå¹¶ä¸æ˜¯ä¸€ä¸ªå¯¹ç§°é‡ï¼Œå³$ H(p,q) \not=H(q,p)$ã€‚åŒæ ·çš„,KLæ•£åº¦ä¹Ÿä¸æ˜¯ä¸€ä¸ªå¯¹ç§°é‡ï¼Œå³$KL(p||q) \not =KL(q||p) $<br>ç»™å®šæ¦‚ç‡åˆ†å¸ƒ$p(x_i)$,ä¿¡æºç†µ$H(p)$å°±æ˜¯å›ºå®šä¸å˜çš„ã€‚åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œäº¤å‰ç†µå¸¸ç”¨ä½œåˆ†ç±»é—®é¢˜çš„æŸå¤±å‡½æ•°ã€‚äº¤å‰ç†µåˆ»ç”»äº†é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ$q(x_i)$ä¸çœŸå®æ¦‚ç‡åˆ†å¸ƒ$p(x_i)$ä¹‹é—´çš„è·ç¦»ã€‚é€šè¿‡å‡å°äº¤å‰ç†µ$H(p,q)$,æˆ‘ä»¬å¯ä»¥ä½¿å¾—é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ$q(x_i)$ä¸æ–­é€¼è¿‘çœŸå®æ¦‚ç‡åˆ†å¸ƒ$p(x_i)$</p><h2 id="ç›¸å¯¹ç†µ"><a href="#ç›¸å¯¹ç†µ" class="headerlink" title="ç›¸å¯¹ç†µ"></a>ç›¸å¯¹ç†µ</h2><p>çœŸå®çš„æ¦‚ç‡åˆ†å¸ƒä¸º$p(x_i)$ï¼Œæˆ‘ä»¬ç”¨é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ$q(x_i)$å¯¹å®ƒè¿›è¡Œå»ºæ¨¡å’Œè¿‘ä¼¼ã€‚æˆ‘ä»¬éœ€è¦çš„å¹³å‡é™„åŠ é‡ï¼Œä¹Ÿå°±æ˜¯å†—ä½™é‡æ˜¯ï¼š<br>$$KL(p,q) = H(p,q) - H(q) = -\sum_{i=1}^{n}p(x_i)logq(x_i) - \biggl(-\sum_{i=1}^{n}p(x_i)logp(x_i)\biggr) = -\sum_{i=1}^{n}p(x_i)log{\frac{q(x_i)}{p(x_i)}}$$KLæ•£åº¦æœ‰ä»¥ä¸‹å‡ ä¸ªç‰¹æ€§ï¼š</p><ul><li>KLæ•£åº¦ä¸æ˜¯ä¸€ä¸ªå¯¹ç§°é‡ï¼Œå³$KL(p||q) \not =KL(q||p) $</li><li>$KL(p||q)\ge 0$ï¼Œå½“ä¸”ä»…å½“åˆ†å¸ƒ$p(x_i)$ä¸$q(x_i)$å®Œå…¨ä¸€è‡´æ—¶ï¼Œç­‰å·æ‰æˆç«‹ã€‚</li><li>KLæ•£åº¦å¯ä»¥çœ‹åšä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´ä¸ç›¸ä¼¼ç¨‹åº¦çš„åº¦é‡ã€‚KLæ•£åº¦è¶Šå°ï¼Œä¸¤ä¸ªåˆ†å¸ƒçš„ä¸ç›¸ä¼¼ç¨‹åº¦è¶Šå°ï¼Œåˆ†å¸ƒ$q(x_i)$è¶Šé€‚åˆæ¥è¿‘ä¼¼$p(x_i)$ã€‚</li></ul><h2 id="tensorflowç”¨äº¤å‰ç†µåšæŸå¤±å‡½æ•°"><a href="#tensorflowç”¨äº¤å‰ç†µåšæŸå¤±å‡½æ•°" class="headerlink" title="tensorflowç”¨äº¤å‰ç†µåšæŸå¤±å‡½æ•°"></a>tensorflowç”¨äº¤å‰ç†µåšæŸå¤±å‡½æ•°</h2><p>åœ¨æœºå™¨å­¦ä¹ ä¸­äº¤å‰ç†µå¸¸å¸¸ç”¨ä½œåˆ†ç±»é—®é¢˜çš„æŸå¤±å‡½æ•°ã€‚è¿™é‡Œæœ‰ä¸ªé—®é¢˜ï¼Œäº¤å‰ç†µç”¨äºæ¦‚ç‡åˆ†å¸ƒï¼Œä½†ç¥ç»ç½‘ç»œçš„è¾“å‡ºå¹¶ä¸ä¸€å®šæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚<br>æ¦‚ç‡åˆ†å¸ƒåº”æ»¡è¶³2ä¸ªæ¡ä»¶:<br>1) $0 \le p(X =x) \le 1$<br>2) $\sum_{x}{} p(X=x) = 1$<br>å¦‚ä½•æŠŠç¥ç»ç½‘ç»œçš„è¾“å‡ºå˜æˆæ¦‚ç‡åˆ†å¸ƒå‘¢ï¼Ÿè¿™é‡Œå°±è¦ç”¨åˆ°softmaxå›å½’ã€‚å‡è®¾è¾“å‡ºå±‚çš„è¾“å‡ºä¸º$y_0,y_1,y_2 \dots y_n$,åˆ™softmaxå‡½æ•°çš„å½¢å¼ä¸ºï¼š$$softmax(y_i) = \frac{exp(y_i)}{\sum_{j}exp(y_j)}$$ç”±äºäº¤å‰ç†µä¸€èˆ¬ä¼šä¸softmaxå›å½’ä¸€èµ·ä½¿ç”¨ï¼ŒTensorFlowå¯¹è¿™ä¸¤ä¸ªåŠŸèƒ½è¿›è¡Œäº†ç»Ÿä¸€ï¼Œå¯ä»¥ç›´æ¥ç”¨å‡½æ•°<a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3.html" target="_blank" rel="noopener">tf.nn.softmax_cross_entropy_with_logits</a>æ¥è®¡ç®—softmaxåçš„äº¤å‰ç†µå‡½æ•°ã€‚å¯¹äºåªæœ‰ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆçš„åˆ†ç±»é—®é¢˜ï¼Œå¯ä»¥ç”¨å‡½æ•°<a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3.html" target="_blank" rel="noopener">tf.nn.sparse_nn.softmax_cross_entropy_with_logits</a>æ¥åŠ é€Ÿè®¡ç®—è¿‡ç¨‹ã€‚</p><h2 id="pytorchä¸­äº¤å‰ç†µæŸå¤±å‡½æ•°çš„å®ç°"><a href="#pytorchä¸­äº¤å‰ç†µæŸå¤±å‡½æ•°çš„å®ç°" class="headerlink" title="pytorchä¸­äº¤å‰ç†µæŸå¤±å‡½æ•°çš„å®ç°"></a>pytorchä¸­äº¤å‰ç†µæŸå¤±å‡½æ•°çš„å®ç°</h2><p>åœ¨å¤šåˆ†ç±»é—®é¢˜ä¸­ï¼Œå®é™…æ¦‚ç‡åˆ†å¸ƒæ˜¯ $y = [y_0,y_1,â€¦,y_{C-1}]$,å…¶ä¸­Cä¸ºç±»åˆ«æ•°;yæ˜¯æ ·æœ¬æ ‡ç­¾çš„one-hotè¡¨ç¤ºï¼Œå½“æ ·æœ¬å±äºç¬¬$i$ç±»æ—¶$y_i=1$,å¦åˆ™$y_i=0$ã€‚é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒä¸º$p = [p_0,p_1,p_2,â€¦,p_{C-1}]$ã€‚$c$æ˜¯æ ·æœ¬æ ‡ç­¾ã€‚æ­¤æ—¶ï¼Œäº¤å‰ç†µæŸå¤±å‡½æ•°ä¸º$$loss = -\sum_{i=0}^{C-1}y_i log(p_i) = - y_c \cdot log(p_c) = - log(p_c)$$<br>æ¥ä¸‹æ¥ä»‹ç»pytorchä¸­å…·ä½“å®ç°è¿™ä¸ªæ•°å­¦å¼å­çš„å‡½æ•°ã€‚</p><h3 id="torch-nn-functional-log-softmax-ä¸class-torch-nn-NLLLoss"><a href="#torch-nn-functional-log-softmax-ä¸class-torch-nn-NLLLoss" class="headerlink" title="torch.nn.functional.log_softmax()ä¸class torch.nn.NLLLoss()"></a>torch.nn.functional.log_softmax()ä¸class torch.nn.NLLLoss()</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.log_softmax()</span><br></pre></td></tr></table></figure><ul><li>ä½œç”¨ï¼šå…ˆåšsoftmaxè¿ç®—ï¼Œå†åšlogè¿ç®—ã€‚åœ¨æ•°å­¦ä¸Šç­‰ä»·äº$log(softmax(x))$</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class torch.nn.NLLLoss(weight = None)</span><br></pre></td></tr></table></figure><ul><li>ä½œç”¨ï¼šè¿™æ˜¯neg log likelihood lossï¼ˆNLLLossï¼‰ï¼Œå³è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°ã€‚</li><li>å‚æ•°ï¼š   <ul><li>weight(tensor,optional): ä¸€ç»´tensorï¼Œé‡Œé¢çš„å€¼å¯¹åº”ç±»åˆ«çš„æƒé‡ã€‚å½“è®­ç»ƒé›†æ ·æœ¬åˆ†å¸ƒä¸å‡åŒ€æ—¶ï¼Œä½¿ç”¨è¿™ä¸ªå‚æ•°éå¸¸é‡è¦ã€‚æ‰‹åŠ¨æŒ‡å®šç±»åˆ«çš„æƒé‡ï¼Œé•¿åº¦åº”ä¸ºç±»åˆ«ä¸ªæ•°Cã€‚</li></ul></li><li>è¾“å…¥ï¼š<ul><li>input(N,C): Cæ˜¯ç±»åˆ«ä¸ªæ•°ã€‚ä¸º<code>log_probabilities</code>å½¢å¼ï¼Œå³æ¦‚ç‡åˆ†å¸ƒå†å–logã€‚å¯ä»¥åœ¨æœ€åä¸€å±‚åŠ <code>log_softmax</code>,è¿™å°±è¦ç”¨åˆ°å‡½æ•°<code>torch.nn.functional.log_softmax()</code></li><li>targets(N): æ˜¯ç±»åˆ«çš„ç´¢å¼•ï¼Œè€Œä¸æ˜¯ç±»åˆ«çš„one-hotè¡¨ç¤ºã€‚æ¯”å¦‚ï¼Œ5ä¸ªç±»åˆ«ä¸­çš„ç¬¬3ç±»ï¼Œtargetåº”ä¸º<code>2</code>,è€Œä¸æ˜¯<code>[0,0,1,0,0]</code></li></ul></li></ul><p>losså¯ä»¥è¡¨ç¤ºä¸ºï¼š$$loss(x,class) = -x[class]$$å¦‚æœæŒ‡å®šäº†weightï¼Œå¯ä»¥è¡¨ç¤ºä¸ºï¼š$$loss(x,class) = - weight[class]*x[class]$$<br>ä¸¾ä¸ªä¾‹å­:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">log_m = torch.nn.functional.log_softmax()</span><br><span class="line">loss_function = torch.nn.NLLLoss()</span><br><span class="line">inputs = torch.randn(3,5) #batch_size * num_classes = 3 * 5</span><br><span class="line">target = torch.LongTensor([1,0,4])</span><br><span class="line">loss = loss_function(log_m(inputs),target)  # inputsè¦å…ˆåšlog_softmaxï¼Œå†é€å…¥loss_function</span><br><span class="line">loss.backward()</span><br></pre></td></tr></table></figure><h3 id="class-torch-nn-CrossEntropyLoss-weight-None"><a href="#class-torch-nn-CrossEntropyLoss-weight-None" class="headerlink" title="class torch.nn.CrossEntropyLoss(weight = None)"></a>class torch.nn.CrossEntropyLoss(weight = None)</h3><ul><li>ä½œç”¨ï¼šå°†å‡½æ•°<code>log_softmax</code>å’Œ<code>NLLLoss</code>é›†æˆåˆ°ä¸€èµ·ã€‚åœ¨å¤šåˆ†ç±»é—®é¢˜ä¸­éå¸¸æœ‰ç”¨ã€‚</li><li>å‚æ•°ï¼š   <ul><li>weight(tensor,optional): ä¸€ç»´tensorï¼Œé‡Œé¢çš„å€¼å¯¹åº”ç±»åˆ«çš„æƒé‡ã€‚å½“è®­ç»ƒé›†æ ·æœ¬åˆ†å¸ƒä¸å‡åŒ€æ—¶ï¼Œä½¿ç”¨è¿™ä¸ªå‚æ•°éå¸¸é‡è¦ã€‚æ‰‹åŠ¨æŒ‡å®šç±»åˆ«çš„æƒé‡ï¼Œé•¿åº¦åº”ä¸ºç±»åˆ«ä¸ªæ•°Cã€‚</li></ul></li><li>è¾“å…¥ï¼š<ul><li>input(N,C): Cæ˜¯ç±»åˆ«ä¸ªæ•°ã€‚æ¯ä¸ªç±»åˆ«çš„åˆ†æ•°ï¼Œä¸ç”¨è¿‡softmaxå±‚ã€‚</li><li>targets(N): æ˜¯ç±»åˆ«çš„ç´¢å¼•ï¼Œè€Œä¸æ˜¯ç±»åˆ«çš„one-hotè¡¨ç¤ºã€‚æ¯”å¦‚ï¼Œ5ä¸ªç±»åˆ«ä¸­çš„ç¬¬3ç±»ï¼Œtargetåº”ä¸º<code>2</code>,è€Œä¸æ˜¯<code>[0,0,1,0,0]</code>ã€‚</li></ul></li></ul><p>losså¯ä»¥è¡¨ç¤ºä¸ºï¼š$$loss(x,class) = - \text{log}\frac{e^{x[class]}}{ \sum_{j=0}^{C-1}e^{x[j]}} = -x[class] + \text{log}(\sum_{j=0}^{C-1}e^{x[j]}) $$å½“æŒ‡å®šäº†weightæ—¶ï¼Œlossè®¡ç®—å…¬å¼ä¸ºï¼š $$ loss(x, class) = weights[class] \cdot (-x[class] + \text{log}(\sum_{j=0}^{C-1}e^{x[j]})) $$<br>å‚è§ï¼š</p><ul><li><a href="https://zhuanlan.zhihu.com/p/56638625" target="_blank" rel="noopener">PyTorchå­¦ä¹ ç¬”è®°â€”â€”å¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°</a></li><li><a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#loss-functions" target="_blank" rel="noopener">pytorchå®˜æ–¹æ‰‹å†Œ</a><h2 id="å‚è€ƒé“¾æ¥"><a href="#å‚è€ƒé“¾æ¥" class="headerlink" title="å‚è€ƒé“¾æ¥"></a>å‚è€ƒé“¾æ¥</h2></li><li><a href="https://wizyoung.github.io/%E4%BF%A1%E6%81%AF%E7%86%B5%EF%BC%8C%E7%9B%B8%E5%AF%B9%E7%86%B5%EF%BC%8C%E4%BA%A4%E5%8F%89%E7%86%B5%E7%9A%84%E7%90%86%E8%A7%A3/#more" target="_blank" rel="noopener">ä¿¡æ¯ç†µï¼Œç›¸å¯¹ç†µï¼Œäº¤å‰ç†µçš„ç†è§£</a></li><li><a href="https://sthsf.github.io/wiki/Algorithm/DeepLearning/Tensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Tensorflow%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86---%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3.html" target="_blank" rel="noopener">TensorflowåŸºç¡€çŸ¥è¯†â€”æŸå¤±å‡½æ•°è¯¦è§£</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ä»‹ç»äº¤å‰ç†µå’ŒKLæ•£åº¦ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¹ " scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="äº¤å‰ç†µ" scheme="http://yoursite.com/tags/%E4%BA%A4%E5%8F%89%E7%86%B5/"/>
    
      <category term="ç›¸å¯¹ç†µ" scheme="http://yoursite.com/tags/%E7%9B%B8%E5%AF%B9%E7%86%B5/"/>
    
  </entry>
  
  <entry>
    <title>pythonçš„ä¸€äº›å‡½æ•°</title>
    <link href="http://yoursite.com/2019/03/10/python%E7%9A%84%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0/"/>
    <id>http://yoursite.com/2019/03/10/pythonçš„ä¸€äº›å‡½æ•°/</id>
    <published>2019-03-10T08:12:51.000Z</published>
    <updated>2019-07-07T07:07:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>è®°å½•pythonçš„ä¸€äº›å‡½æ•°ï¼Œå®ç°æŸäº›åŠŸèƒ½ã€‚</p><a id="more"></a> <h2 id="æ±‚æœ€å¤§-å°å€¼çš„ç´¢å¼•"><a href="#æ±‚æœ€å¤§-å°å€¼çš„ç´¢å¼•" class="headerlink" title="æ±‚æœ€å¤§/å°å€¼çš„ç´¢å¼•"></a>æ±‚æœ€å¤§/å°å€¼çš„ç´¢å¼•</h2><h3 id="å¯¹äºlist"><a href="#å¯¹äºlist" class="headerlink" title="å¯¹äºlist"></a>å¯¹äºlist</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">a = range(100)</span><br><span class="line">np.random.shuffle(a)</span><br><span class="line">index_max = a.index(max(a)) #æ±‚æœ€å¤§å€¼çš„ç´¢å¼•</span><br><span class="line">index_min = a.index(min(a)) #æ±‚æœ€å°å€¼çš„ç´¢å¼•</span><br></pre></td></tr></table></figure><h3 id="å¯¹äºnumpyçš„æ•°ç»„ndarray"><a href="#å¯¹äºnumpyçš„æ•°ç»„ndarray" class="headerlink" title="å¯¹äºnumpyçš„æ•°ç»„ndarray"></a>å¯¹äºnumpyçš„æ•°ç»„ndarray</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = np.array(a)</span><br><span class="line">index_max = np.argmax(a) #æ±‚æœ€å¤§å€¼çš„ç´¢å¼•</span><br><span class="line">index_min = np.argmin(a) #æ±‚æœ€å°å€¼çš„ç´¢å¼•</span><br><span class="line"># å¯¹äºäºŒç»´çš„æ•°ç»„</span><br><span class="line">b = np.arange(100).reshape(10,-1)</span><br><span class="line">row_max_list = np.argmax(b,axis = 1) #æŒ‰è¡Œè®¡ç®—æœ€å¤§å€¼åœ¨è¡Œä¸­çš„ç´¢å¼•</span><br><span class="line">line_max_list = np.argmin(b,axis = 0) #æŒ‰åˆ—è®¡ç®—æœ€å°å€¼åœ¨åˆ—ä¸­çš„ç´¢å¼•</span><br></pre></td></tr></table></figure><h2 id="sortä¸sorted"><a href="#sortä¸sorted" class="headerlink" title="sortä¸sorted"></a>sortä¸sorted</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sorted(iterable,key,reverse)</span><br></pre></td></tr></table></figure><ul><li>iterable: å¯è¿­ä»£å¯¹è±¡</li><li>keyï¼šç”¨æ¥è¿›è¡Œæ¯”è¾ƒçš„å…ƒç´ ã€‚å¸¸ç”¨å‡½æ•°ï¼š lambda x:x[i]</li><li>reverseï¼šæ’åºè§„åˆ™ã€‚reverse=TrueæŒ‰é™åºæ’åˆ—ï¼Œreverse=FalseæŒ‰å‡åºæ’åˆ—ï¼ˆé»˜è®¤ï¼‰</li></ul><p>æ¯”è¾ƒsortä¸sorted:</p><ul><li>ä½œç”¨å¯¹è±¡:sort()åªèƒ½ä½œç”¨äºlist,sorted()å¯ä»¥ä½œç”¨äºæ‰€æœ‰å¯è¿­ä»£å¯¹è±¡ã€‚</li><li>è¿”å›å€¼ï¼šsort()æ²¡æœ‰è¿”å›å€¼ï¼›sorted()è¿”å›ä¸€ä¸ªæ–°çš„list</li></ul><h2 id="å­—å…¸çš„items-æ–¹æ³•"><a href="#å­—å…¸çš„items-æ–¹æ³•" class="headerlink" title="å­—å…¸çš„items()æ–¹æ³•"></a>å­—å…¸çš„items()æ–¹æ³•</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dict.items()</span><br></pre></td></tr></table></figure><p>è¿”å›å¯éå†çš„å…ƒç´ ä¸ºï¼ˆé”®ï¼Œå€¼ï¼‰å…ƒç»„çš„æ•°ç»„ã€‚</p><h2 id="æ¨¡å—"><a href="#æ¨¡å—" class="headerlink" title="æ¨¡å—"></a>æ¨¡å—</h2><h3 id="collectionsâ€“å®¹å™¨æ•°æ®ç±»å‹"><a href="#collectionsâ€“å®¹å™¨æ•°æ®ç±»å‹" class="headerlink" title="collectionsâ€“å®¹å™¨æ•°æ®ç±»å‹"></a>collectionsâ€“å®¹å™¨æ•°æ®ç±»å‹</h3><p><a href="https://docs.python.org/zh-cn/3/library/collections.html#collections.Counter" target="_blank" rel="noopener">collections</a>æ¨¡å—æ˜¯pythonå†…å»ºçš„ä¸€ä¸ªé›†åˆæ¨¡å—ï¼Œæä¾›äº†è®¸å¤šæœ‰ç”¨çš„é›†æˆç±»ã€‚æä¾›äº†<code>list</code>,<code>dict</code>,<code>set</code>,<code>tuple</code>çš„æ›¿ä»£é€‰æ‹©ï¼Œç›¸å½“äºè¿™å‡ ä¸ªæ•°æ®ç±»å‹çš„åŠ å¼ºç‰ˆã€‚</p><h4 id="collections-Counter-iterable"><a href="#collections-Counter-iterable" class="headerlink" title="collections.Counter(iterable)"></a>collections.Counter(iterable)</h4><p>Counteræ˜¯ä¸€ä¸ªè®¡æ•°å™¨ï¼Œç”¨äºè®¡æ•°å¯å“ˆå¸Œå¯¹è±¡ï¼Œç»Ÿè®¡å…ƒç´ å‡ºç°çš„ä¸ªæ•°ã€‚å®ƒæ˜¯ä¸€ä¸ªé›†åˆï¼Œ<code>å…ƒç´ -è®¡æ•°</code>åƒ<code>é”®-å€¼</code>å¯¹ä¸€æ ·å­˜å‚¨ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; import collections</span><br><span class="line"></span><br><span class="line">&gt;&gt; a = [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;a&quot;,&quot;b&quot;,&quot;a&quot;]</span><br><span class="line">&gt;&gt; counter = collections.Counter(a)</span><br><span class="line">&gt;&gt; print(counter)</span><br><span class="line">Counter(&#123;&apos;a&apos;: 3, &apos;b&apos;: 2, &apos;c&apos;: 1&#125;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;è®°å½•pythonçš„ä¸€äº›å‡½æ•°ï¼Œå®ç°æŸäº›åŠŸèƒ½ã€‚&lt;/p&gt;
    
    </summary>
    
      <category term="å­¦ä¹ ç¬”è®°" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
</feed>
